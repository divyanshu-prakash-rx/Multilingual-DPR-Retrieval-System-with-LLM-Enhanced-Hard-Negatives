{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "823a6b6b",
   "metadata": {},
   "source": [
    "## Step 1: Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aef970bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Configuration loaded\n",
      "  GPU Memory Mode: 4GB (optimized)\n",
      "  Development Mode: True\n"
     ]
    }
   ],
   "source": [
    "# === CONFIGURATION (SET THESE FIRST) ===\n",
    "\n",
    "# API Keys (set if available, else will use Ollama)\n",
    "GEMINI_API_KEY = None  # Set to your API key or leave None for Ollama\n",
    "\n",
    "# Data paths\n",
    "DATA_DIR = \"data\"\n",
    "MSMARCO_DIR = f\"{DATA_DIR}/msmarco\"\n",
    "TYDI_DIR = f\"{DATA_DIR}/tydi\"\n",
    "MMARCO_DIR = f\"{DATA_DIR}/mmarco/beir\"\n",
    "\n",
    "# Model directories\n",
    "MODEL_DIR = \"./models\"\n",
    "BASE_MODEL = \"bert-base-multilingual-cased\"\n",
    "\n",
    "# Training configuration (adjust for 4GB GPU)\n",
    "USE_MIXED_PRECISION = True  # FP16 to save memory\n",
    "GRADIENT_ACCUMULATION_STEPS = 4  # Simulate larger batch\n",
    "MAX_SEQ_LENGTH = 256  # Reduce from 512 to save memory\n",
    "\n",
    "# Sample sizes for development (set to None for full dataset)\n",
    "DEV_MODE = True  # Set False for full training\n",
    "DEV_SAMPLE_SIZE = 1000 if DEV_MODE else None\n",
    "\n",
    "# Languages for multilingual training\n",
    "TYDI_LANGUAGES = [\n",
    "    \"arabic\", \"bengali\", \"finnish\", \"indonesian\", \"japanese\",\n",
    "    \"korean\", \"russian\", \"swahili\", \"telugu\", \"thai\"\n",
    "]\n",
    "\n",
    "MMARCO_LANGUAGES = [\n",
    "    \"arabic\", \"chinese\", \"dutch\", \"french\", \"german\",\n",
    "    \"hindi\", \"indonesian\", \"italian\", \"japanese\", \"portuguese\",\n",
    "    \"russian\", \"spanish\", \"vietnamese\"\n",
    "]\n",
    "\n",
    "print(\"âœ“ Configuration loaded\")\n",
    "print(f\"  GPU Memory Mode: {'4GB (optimized)' if MAX_SEQ_LENGTH == 256 else 'Standard'}\")\n",
    "print(f\"  Development Mode: {DEV_MODE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8a29607",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\anaconda3\\envs\\mltorch311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ transformers already installed\n",
      "âœ“ datasets already installed\n",
      "âœ“ pandas already installed\n",
      "âœ“ tqdm already installed\n",
      "âœ“ simpletransformers already installed\n",
      "Installing faiss-cpu...\n",
      "âœ“ rank-bm25 already installed\n",
      "âœ“ sentence-transformers already installed\n",
      "âœ“ torch already installed\n",
      "\n",
      "âœ“ All dependencies installed\n"
     ]
    }
   ],
   "source": [
    "# Run once to install required packages\n",
    "\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install_packages():\n",
    "    packages = [\n",
    "        \"transformers\",\n",
    "        \"datasets\",\n",
    "        \"pandas\",\n",
    "        \"tqdm\",\n",
    "        \"simpletransformers\",\n",
    "        \"faiss-cpu\",  # Use faiss-cpu for 4GB GPU, or faiss-gpu if sufficient\n",
    "        \"rank-bm25\",\n",
    "        \"sentence-transformers\",\n",
    "        \"torch\",\n",
    "    ]\n",
    "    \n",
    "    for package in packages:\n",
    "        try:\n",
    "            __import__(package.replace('-', '_'))\n",
    "            print(f\"âœ“ {package} already installed\")\n",
    "        except ImportError:\n",
    "            print(f\"Installing {package}...\")\n",
    "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "\n",
    "install_packages()\n",
    "\n",
    "# For Ollama (if not using Gemini API)\n",
    "# Install separately: https://ollama.ai/download\n",
    "# Then: ollama pull llama3.2:3b\n",
    "\n",
    "print(\"\\nâœ“ All dependencies installed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "497eb7f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Libraries imported\n",
      "  PyTorch version: 2.7.0+cu128\n",
      "  CUDA available: True\n",
      "  GPU Memory: 4.29 GB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Tuple\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import set_seed\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "set_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# Create directories\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "os.makedirs(\"./results\", exist_ok=True)\n",
    "os.makedirs(\"./logs\", exist_ok=True)\n",
    "\n",
    "print(\"âœ“ Libraries imported\")\n",
    "print(f\"  PyTorch version: {torch.__version__}\")\n",
    "print(f\"  CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"  GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "155778a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Loading MS MARCO ===\n",
      "âœ“ MS MARCO Train: 1,000 samples\n",
      "âœ“ MS MARCO Dev: 100 samples\n",
      "\n",
      "Sample:\n",
      "                        query  \\\n",
      "0                  query_text   \n",
      "1  what are the liberal arts?   \n",
      "\n",
      "                                    positive_passage  \\\n",
      "0                                       gold_passage   \n",
      "1  liberal arts. 1. the academic course of instru...   \n",
      "\n",
      "                                    negative_passage  \n",
      "0                                      hard_negative  \n",
      "1  Liberal Education: An approach to college lear...  \n",
      "\n",
      "Statistics:\n",
      "  Avg query length: 33.3 chars\n",
      "  Avg passage length: 345.5 chars\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"=== Loading MS MARCO ===\")\n",
    "\n",
    "# Load queries\n",
    "msmarco_train = pd.read_csv(\n",
    "    f\"{MSMARCO_DIR}/msmarco-train.tsv\",\n",
    "    sep=\"\\t\",\n",
    "    names=[\"query\", \"positive_passage\", \"negative_passage\"],\n",
    "    nrows=DEV_SAMPLE_SIZE\n",
    ")\n",
    "\n",
    "# Load dev/test\n",
    "msmarco_dev = pd.read_csv(\n",
    "    f\"{MSMARCO_DIR}/devs.tsv\",\n",
    "    sep=\"\\t\",\n",
    "    names=[\"query\", \"positive_passage\", \"negative_passage\"],\n",
    "    nrows=DEV_SAMPLE_SIZE // 10 if DEV_SAMPLE_SIZE else None\n",
    ")\n",
    "\n",
    "print(f\"âœ“ MS MARCO Train: {len(msmarco_train):,} samples\")\n",
    "print(f\"âœ“ MS MARCO Dev: {len(msmarco_dev):,} samples\")\n",
    "\n",
    "# Quick EDA\n",
    "print(\"\\nSample:\")\n",
    "print(msmarco_train.head(2))\n",
    "\n",
    "print(\"\\nStatistics:\")\n",
    "print(f\"  Avg query length: {msmarco_train['query'].str.len().mean():.1f} chars\")\n",
    "print(f\"  Avg passage length: {msmarco_train['positive_passage'].str.len().mean():.1f} chars\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbbc268f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Loading Mr. TyDi ===\n",
      "  âœ“ arabic: 100\n",
      "  âœ“ bengali: 100\n",
      "  âœ“ finnish: 100\n",
      "  âœ“ indonesian: 100\n",
      "  âœ“ japanese: 100\n",
      "  âœ“ korean: 100\n",
      "  âœ“ russian: 100\n",
      "  âœ“ swahili: 100\n",
      "  âœ“ telugu: 100\n",
      "  âœ“ thai: 100\n",
      "\n",
      "âœ“ Total: 1,000 samples\n"
     ]
    }
   ],
   "source": [
    "# Load Mr. TyDi from train.tsv files\n",
    "\n",
    "print(\"\\n=== Loading Mr. TyDi ===\")\n",
    "\n",
    "tydi_data = []\n",
    "\n",
    "for lang in TYDI_LANGUAGES:\n",
    "    train_file = f\"{TYDI_DIR}/{lang}/train.tsv\"\n",
    "    \n",
    "    if os.path.exists(train_file):\n",
    "        df = pd.read_csv(train_file, sep=\"\\t\")\n",
    "        \n",
    "        # Take first two text columns as query and passage\n",
    "        df = df.iloc[:, :2]\n",
    "        df.columns = ['query', 'positive_passage']\n",
    "        df = df.dropna()\n",
    "        \n",
    "        # Sample if dev mode\n",
    "        if DEV_SAMPLE_SIZE:\n",
    "            df = df.sample(min(len(df), 100), random_state=42)\n",
    "        \n",
    "        tydi_data.append(df)\n",
    "        print(f\"  âœ“ {lang}: {len(df):,}\")\n",
    "\n",
    "# Combine all languages\n",
    "tydi_combined = pd.concat(tydi_data, ignore_index=True) if tydi_data else pd.DataFrame(columns=[\"query\", \"positive_passage\"])\n",
    "\n",
    "print(f\"\\nâœ“ Total: {len(tydi_combined):,} samples\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6626292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Cleaning Datasets ===\n",
      "MS MARCO Train:\n",
      "  Cleaned: 1,000 â†’ 999 (99.9% retained)\n",
      "\n",
      "MS MARCO Dev:\n",
      "  Cleaned: 100 â†’ 0 (0.0% retained)\n",
      "\n",
      "Mr. TyDi:\n",
      "  Cleaned: 1,000 â†’ 986 (98.6% retained)\n",
      "\n",
      "âœ“ Cleaning complete\n"
     ]
    }
   ],
   "source": [
    "# Clean and preprocess datasets\n",
    "\n",
    "def clean_dataset(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Remove nulls, duplicates, and invalid samples\"\"\"\n",
    "    initial_size = len(df)\n",
    "    \n",
    "    # Remove nulls\n",
    "    df = df.dropna()\n",
    "    \n",
    "    # Remove duplicates\n",
    "    df = df.drop_duplicates()\n",
    "    \n",
    "    # Remove empty strings\n",
    "    df = df[\n",
    "        (df['query'].str.strip() != '') & \n",
    "        (df['positive_passage'].str.strip() != '')\n",
    "    ]\n",
    "    \n",
    "    # Length constraints (for 4GB GPU - shorter sequences)\n",
    "    df = df[\n",
    "        (df['query'].str.len() >= 10) &\n",
    "        (df['query'].str.len() <= 512) &\n",
    "        (df['positive_passage'].str.len() >= 20) &\n",
    "        (df['positive_passage'].str.len() <= 2048)\n",
    "    ]\n",
    "    \n",
    "    # Remove if negative == positive (if negative exists)\n",
    "    if 'negative_passage' in df.columns:\n",
    "        df = df[df['negative_passage'] != df['positive_passage']]\n",
    "    \n",
    "    print(f\"  Cleaned: {initial_size:,} â†’ {len(df):,} ({len(df)/initial_size*100:.1f}% retained)\")\n",
    "    \n",
    "    return df.reset_index(drop=True)\n",
    "\n",
    "print(\"=== Cleaning Datasets ===\")\n",
    "print(\"MS MARCO Train:\")\n",
    "msmarco_train = clean_dataset(msmarco_train)\n",
    "\n",
    "print(\"\\nMS MARCO Dev:\")\n",
    "msmarco_dev = clean_dataset(msmarco_dev)\n",
    "\n",
    "print(\"\\nMr. TyDi:\")\n",
    "tydi_combined = clean_dataset(tydi_combined)\n",
    "\n",
    "print(\"\\nâœ“ Cleaning complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "188b26d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Preparing Training Examples ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preparing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 999/999 [00:00<00:00, 40392.83it/s]\n",
      "Preparing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 986/986 [00:00<00:00, 41372.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ MS MARCO: 999 examples\n",
      "âœ“ TyDi: 986 examples\n",
      "\n",
      "âœ“ Data saved to data_processed.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Prepare data in format needed for DPR training\n",
    "\n",
    "@dataclass\n",
    "class TrainingExample:\n",
    "    query: str\n",
    "    positive: str\n",
    "    negatives: List[str]  # Will be populated by sampling methods\n",
    "\n",
    "def prepare_training_data(df: pd.DataFrame, has_negatives: bool = True) -> List[TrainingExample]:\n",
    "    \"\"\"Convert DataFrame to training examples\"\"\"\n",
    "    examples = []\n",
    "    \n",
    "    for _, row in tqdm(df.iterrows(), total=len(df), desc=\"Preparing\"):\n",
    "        example = TrainingExample(\n",
    "            query=row['query'],\n",
    "            positive=row['positive_passage'],\n",
    "            negatives=[row['negative_passage']] if has_negatives and 'negative_passage' in row else []\n",
    "        )\n",
    "        examples.append(example)\n",
    "    \n",
    "    return examples\n",
    "\n",
    "print(\"=== Preparing Training Examples ===\")\n",
    "\n",
    "msmarco_train_examples = prepare_training_data(msmarco_train, has_negatives=True)\n",
    "tydi_train_examples = prepare_training_data(tydi_combined, has_negatives=False)\n",
    "\n",
    "print(f\"âœ“ MS MARCO: {len(msmarco_train_examples):,} examples\")\n",
    "print(f\"âœ“ TyDi: {len(tydi_train_examples):,} examples\")\n",
    "\n",
    "# Save to disk for later use\n",
    "import pickle\n",
    "\n",
    "with open('./data_processed.pkl', 'wb') as f:\n",
    "    pickle.dump({\n",
    "        'msmarco_train': msmarco_train_examples,\n",
    "        'msmarco_dev': msmarco_dev,\n",
    "        'tydi_train': tydi_train_examples\n",
    "    }, f)\n",
    "\n",
    "print(\"\\nâœ“ Data saved to data_processed.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0189345c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DATASET SUMMARY\n",
      "============================================================\n",
      "\n",
      "ðŸ“Š MS MARCO (English):\n",
      "  Training samples: 999\n",
      "  Dev samples: 0\n",
      "  Has pre-mined negatives: Yes\n",
      "\n",
      "ðŸ“Š Mr. TyDi (Multilingual):\n",
      "  Total samples: 986\n",
      "  Languages: 10\n",
      "  Has pre-mined negatives: No (will generate)\n",
      "\n",
      "ðŸ“Š Configuration:\n",
      "  Max sequence length: 256\n",
      "  Mixed precision: True\n",
      "  Gradient accumulation: 4\n",
      "\n",
      "âœ… Phase 1 Complete: Data Preparation\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Final statistics\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"DATASET SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\nðŸ“Š MS MARCO (English):\")\n",
    "print(f\"  Training samples: {len(msmarco_train_examples):,}\")\n",
    "print(f\"  Dev samples: {len(msmarco_dev):,}\")\n",
    "print(f\"  Has pre-mined negatives: Yes\")\n",
    "\n",
    "print(\"\\nðŸ“Š Mr. TyDi (Multilingual):\")\n",
    "print(f\"  Total samples: {len(tydi_train_examples):,}\")\n",
    "print(f\"  Languages: {len(TYDI_LANGUAGES)}\")\n",
    "print(f\"  Has pre-mined negatives: No (will generate)\")\n",
    "\n",
    "print(\"\\nðŸ“Š Configuration:\")\n",
    "print(f\"  Max sequence length: {MAX_SEQ_LENGTH}\")\n",
    "print(f\"  Mixed precision: {USE_MIXED_PRECISION}\")\n",
    "print(f\"  Gradient accumulation: {GRADIENT_ACCUMULATION_STEPS}\")\n",
    "\n",
    "print(\"\\nâœ… Phase 1 Complete: Data Preparation\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e14f35f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ rank_bm25 already installed\n",
      "âœ“ Loaded 999 MS MARCO examples\n",
      "âœ“ Loaded 986 TyDi examples\n"
     ]
    }
   ],
   "source": [
    "# Install BM25 for negative sampling\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "try:\n",
    "    from rank_bm25 import BM25Okapi\n",
    "    print(\"âœ“ rank_bm25 already installed\")\n",
    "except ImportError:\n",
    "    print(\"Installing rank_bm25...\")\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"rank-bm25\"])\n",
    "    from rank_bm25 import BM25Okapi\n",
    "    print(\"âœ“ rank_bm25 installed\")\n",
    "\n",
    "# Load processed data\n",
    "import pickle\n",
    "\n",
    "with open('./data_processed.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "    msmarco_train_examples = data['msmarco_train']\n",
    "    msmarco_dev = data['msmarco_dev']\n",
    "    tydi_train_examples = data['tydi_train']\n",
    "\n",
    "print(f\"âœ“ Loaded {len(msmarco_train_examples):,} MS MARCO examples\")\n",
    "print(f\"âœ“ Loaded {len(tydi_train_examples):,} TyDi examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c62932db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Building BM25 Corpus ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting passages: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 999/999 [00:00<00:00, 990569.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Corpus size: 1,993 unique passages\n",
      "Building BM25 index...\n",
      "âœ“ BM25 index built with 1,993 documents\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# BM25-based hard negative mining\n",
    "\n",
    "from rank_bm25 import BM25Okapi\n",
    "from typing import List\n",
    "import numpy as np\n",
    "\n",
    "class BM25NegativeSampler:\n",
    "    \"\"\"Mine hard negatives using BM25\"\"\"\n",
    "    \n",
    "    def __init__(self, corpus: List[str]):\n",
    "        print(\"Building BM25 index...\")\n",
    "        # Tokenize corpus\n",
    "        tokenized_corpus = [doc.lower().split() for doc in corpus]\n",
    "        self.bm25 = BM25Okapi(tokenized_corpus)\n",
    "        self.corpus = corpus\n",
    "        print(f\"âœ“ BM25 index built with {len(corpus):,} documents\")\n",
    "    \n",
    "    def get_hard_negatives(self, query: str, positive_passage: str, top_k: int = 100, n_negatives: int = 1) -> List[str]:\n",
    "        \"\"\"Get hard negatives for a query\"\"\"\n",
    "        # Tokenize query\n",
    "        tokenized_query = query.lower().split()\n",
    "        \n",
    "        # Get top-k candidates from BM25\n",
    "        scores = self.bm25.get_scores(tokenized_query)\n",
    "        top_indices = np.argsort(scores)[-top_k:][::-1]\n",
    "        \n",
    "        # Filter out positive passage and select negatives\n",
    "        negatives = []\n",
    "        for idx in top_indices:\n",
    "            candidate = self.corpus[idx]\n",
    "            # Skip if it's the positive passage\n",
    "            if candidate != positive_passage and candidate not in negatives:\n",
    "                negatives.append(candidate)\n",
    "            if len(negatives) >= n_negatives:\n",
    "                break\n",
    "        \n",
    "        # If not enough negatives, add random ones\n",
    "        while len(negatives) < n_negatives:\n",
    "            random_idx = np.random.randint(0, len(self.corpus))\n",
    "            candidate = self.corpus[random_idx]\n",
    "            if candidate != positive_passage and candidate not in negatives:\n",
    "                negatives.append(candidate)\n",
    "        \n",
    "        return negatives[:n_negatives]\n",
    "\n",
    "# Build corpus from MS MARCO\n",
    "print(\"\\n=== Building BM25 Corpus ===\")\n",
    "all_passages = set()\n",
    "\n",
    "for example in tqdm(msmarco_train_examples, desc=\"Collecting passages\"):\n",
    "    all_passages.add(example.positive)\n",
    "    all_passages.update(example.negatives)\n",
    "\n",
    "corpus_list = list(all_passages)\n",
    "print(f\"âœ“ Corpus size: {len(corpus_list):,} unique passages\")\n",
    "\n",
    "# Initialize BM25 sampler\n",
    "bm25_sampler = BM25NegativeSampler(corpus_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3084337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Mining Hard Negatives with BM25 ===\n",
      "\n",
      "Mining for TyDi examples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TyDi: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [00:00<00:00, 588.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Adding BM25 negatives to MS MARCO examples (first 100 for demo)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MS MARCO: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:00<00:00, 447.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ“ Hard negative mining complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Mine hard negatives for training examples that don't have them\n",
    "\n",
    "print(\"\\n=== Mining Hard Negatives with BM25 ===\")\n",
    "\n",
    "# For TyDi examples (no pre-existing negatives)\n",
    "print(\"\\nMining for TyDi examples...\")\n",
    "for example in tqdm(tydi_train_examples[:min(len(tydi_train_examples), 500)], desc=\"TyDi\"):\n",
    "    if len(example.negatives) == 0:\n",
    "        hard_negs = bm25_sampler.get_hard_negatives(\n",
    "            example.query, \n",
    "            example.positive, \n",
    "            top_k=100, \n",
    "            n_negatives=1\n",
    "        )\n",
    "        example.negatives = hard_negs\n",
    "\n",
    "# For MS MARCO examples (already have negatives, but we can add more)\n",
    "print(\"\\nAdding BM25 negatives to MS MARCO examples (first 100 for demo)...\")\n",
    "for example in tqdm(msmarco_train_examples[:100], desc=\"MS MARCO\"):\n",
    "    # Add one more hard negative from BM25\n",
    "    bm25_negs = bm25_sampler.get_hard_negatives(\n",
    "        example.query,\n",
    "        example.positive,\n",
    "        top_k=100,\n",
    "        n_negatives=1\n",
    "    )\n",
    "    # Avoid duplicates\n",
    "    for neg in bm25_negs:\n",
    "        if neg not in example.negatives:\n",
    "            example.negatives.append(neg)\n",
    "\n",
    "print(\"\\nâœ“ Hard negative mining complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb38b81c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Preparing Training DataFrames ===\n",
      "âœ“ MS MARCO training: 1,049 triplets\n",
      "\n",
      "Columns: ['query_text', 'gold_passage', 'hard_negative']\n",
      "\n",
      "Sample:\n",
      "                   query_text  \\\n",
      "0  what are the liberal arts?   \n",
      "1  what are the liberal arts?   \n",
      "\n",
      "                                        gold_passage  \\\n",
      "0  liberal arts. 1. the academic course of instru...   \n",
      "1  liberal arts. 1. the academic course of instru...   \n",
      "\n",
      "                                       hard_negative  \n",
      "0  Liberal Education: An approach to college lear...  \n",
      "1  Bucknell is divided into the College of Arts a...  \n"
     ]
    }
   ],
   "source": [
    "# Convert to SimpleDPR format with correct column names\n",
    "\n",
    "def convert_to_training_format(examples: List, limit: int = None) -> pd.DataFrame:\n",
    "    \"\"\"Convert training examples to DataFrame format for SimpleDPR\"\"\"\n",
    "    data = []\n",
    "    \n",
    "    for example in examples[:limit] if limit else examples:\n",
    "        for negative in example.negatives:\n",
    "            data.append({\n",
    "                'query_text': example.query,           # Changed from 'query'\n",
    "                'gold_passage': example.positive,      # Changed from 'positive'\n",
    "                'hard_negative': negative,             # Changed from 'negative'\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Convert MS MARCO for training\n",
    "print(\"=== Preparing Training DataFrames ===\")\n",
    "\n",
    "train_size = 5000 if DEV_MODE else None\n",
    "msmarco_train_df = convert_to_training_format(msmarco_train_examples, limit=train_size)\n",
    "\n",
    "print(f\"âœ“ MS MARCO training: {len(msmarco_train_df):,} triplets\")\n",
    "print(\"\\nColumns:\", msmarco_train_df.columns.tolist())\n",
    "print(\"\\nSample:\")\n",
    "print(msmarco_train_df.head(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18d824b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Model configuration:\n",
      "  Base model: bert-base-multilingual-cased\n",
      "  Epochs: 5\n",
      "  Batch size: 2 x 4 = 8\n",
      "  Max seq length: 256\n",
      "  FP16: True\n",
      "  Output: ./models/dpr_bm25_baseline\n"
     ]
    }
   ],
   "source": [
    "# DPR model configuration for 4GB GPU\n",
    "\n",
    "from simpletransformers.retrieval import RetrievalModel, RetrievalArgs\n",
    "\n",
    "# Training arguments optimized for 4GB GPU\n",
    "model_args = RetrievalArgs()\n",
    "\n",
    "# Training hyperparameters (optimized for low memory)\n",
    "model_args.num_train_epochs = 5  # Start with 5\n",
    "model_args.train_batch_size = 2\n",
    "model_args.eval_batch_size = 2\n",
    "model_args.gradient_accumulation_steps = GRADIENT_ACCUMULATION_STEPS\n",
    "model_args.learning_rate = 2e-5\n",
    "model_args.warmup_ratio = 0.1\n",
    "model_args.max_seq_length = MAX_SEQ_LENGTH\n",
    "\n",
    "# Memory optimization\n",
    "model_args.fp16 = USE_MIXED_PRECISION\n",
    "model_args.dataloader_num_workers = 0\n",
    "model_args.use_cached_eval_features = False\n",
    "\n",
    "# Output and logging\n",
    "model_args.output_dir = f\"{MODEL_DIR}/dpr_bm25_baseline\"\n",
    "model_args.overwrite_output_dir = True\n",
    "model_args.save_steps = 1000\n",
    "model_args.save_model_every_epoch = True\n",
    "model_args.evaluate_during_training = False\n",
    "model_args.logging_steps = 10\n",
    "\n",
    "# Loss function\n",
    "model_args.loss_type = \"softmax\"\n",
    "model_args.hard_negatives = True\n",
    "model_args.include_title = False\n",
    "\n",
    "# FIXED: Don't set context_config, let it auto-initialize\n",
    "# model_args.context_config = {}  # REMOVE THIS\n",
    "\n",
    "print(\"âœ“ Model configuration:\")\n",
    "print(f\"  Base model: {BASE_MODEL}\")\n",
    "print(f\"  Epochs: {model_args.num_train_epochs}\")\n",
    "print(f\"  Batch size: {model_args.train_batch_size} x {model_args.gradient_accumulation_steps} = {model_args.train_batch_size * model_args.gradient_accumulation_steps}\")\n",
    "print(f\"  Max seq length: {model_args.max_seq_length}\")\n",
    "print(f\"  FP16: {model_args.fp16}\")\n",
    "print(f\"  Output: {model_args.output_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f3cb3892",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\anaconda3\\envs\\mltorch311\\Lib\\site-packages\\torch\\__init__.py:1117: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead\n",
      "  return isinstance(obj, torch.Tensor)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ GPU memory cleared\n",
      "  Allocated: 0.00GB\n",
      "  Reserved: 0.00GB\n",
      "  Free: 4.29GB\n",
      "  Total: 4.29GB\n"
     ]
    }
   ],
   "source": [
    "# Cell 13.5: Aggressive GPU Memory Cleanup\n",
    "\n",
    "import torch\n",
    "import gc\n",
    "\n",
    "def clear_gpu_memory():\n",
    "    \"\"\"Aggressively clear GPU memory\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        # Clear PyTorch cache\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        # Force garbage collection\n",
    "        gc.collect()\n",
    "        \n",
    "        # Clear all variables from previous runs\n",
    "        import sys\n",
    "        for obj in gc.get_objects():\n",
    "            try:\n",
    "                if torch.is_tensor(obj):\n",
    "                    del obj\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        # Final cleanup\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        \n",
    "        # Report memory\n",
    "        allocated = torch.cuda.memory_allocated() / 1e9\n",
    "        reserved = torch.cuda.memory_reserved() / 1e9\n",
    "        total = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "        \n",
    "        print(\"âœ“ GPU memory cleared\")\n",
    "        print(f\"  Allocated: {allocated:.2f}GB\")\n",
    "        print(f\"  Reserved: {reserved:.2f}GB\")\n",
    "        print(f\"  Free: {total - reserved:.2f}GB\")\n",
    "        print(f\"  Total: {total:.2f}GB\")\n",
    "\n",
    "# Clear before training\n",
    "clear_gpu_memory()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8e396b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "STAGE 1: TRAINING ON MS MARCO (ENGLISH)\n",
      "============================================================\n",
      "âœ“ GPU memory cleared\n",
      "  Allocated: 0.00GB\n",
      "  Reserved: 0.00GB\n",
      "  Free: 4.29GB\n",
      "  Total: 4.29GB\n",
      "\n",
      "Initializing DPR model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type bert to instantiate a model of type dpr. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of DPRContextEncoder were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['ctx_encoder.bert_model.embeddings.LayerNorm.bias', 'ctx_encoder.bert_model.embeddings.LayerNorm.weight', 'ctx_encoder.bert_model.embeddings.position_embeddings.weight', 'ctx_encoder.bert_model.embeddings.token_type_embeddings.weight', 'ctx_encoder.bert_model.embeddings.word_embeddings.weight', 'ctx_encoder.bert_model.encoder.layer.0.attention.output.LayerNorm.bias', 'ctx_encoder.bert_model.encoder.layer.0.attention.output.LayerNorm.weight', 'ctx_encoder.bert_model.encoder.layer.0.attention.output.dense.bias', 'ctx_encoder.bert_model.encoder.layer.0.attention.output.dense.weight', 'ctx_encoder.bert_model.encoder.layer.0.attention.self.key.bias', 'ctx_encoder.bert_model.encoder.layer.0.attention.self.key.weight', 'ctx_encoder.bert_model.encoder.layer.0.attention.self.query.bias', 'ctx_encoder.bert_model.encoder.layer.0.attention.self.query.weight', 'ctx_encoder.bert_model.encoder.layer.0.attention.self.value.bias', 'ctx_encoder.bert_model.encoder.layer.0.attention.self.value.weight', 'ctx_encoder.bert_model.encoder.layer.0.intermediate.dense.bias', 'ctx_encoder.bert_model.encoder.layer.0.intermediate.dense.weight', 'ctx_encoder.bert_model.encoder.layer.0.output.LayerNorm.bias', 'ctx_encoder.bert_model.encoder.layer.0.output.LayerNorm.weight', 'ctx_encoder.bert_model.encoder.layer.0.output.dense.bias', 'ctx_encoder.bert_model.encoder.layer.0.output.dense.weight', 'ctx_encoder.bert_model.encoder.layer.1.attention.output.LayerNorm.bias', 'ctx_encoder.bert_model.encoder.layer.1.attention.output.LayerNorm.weight', 'ctx_encoder.bert_model.encoder.layer.1.attention.output.dense.bias', 'ctx_encoder.bert_model.encoder.layer.1.attention.output.dense.weight', 'ctx_encoder.bert_model.encoder.layer.1.attention.self.key.bias', 'ctx_encoder.bert_model.encoder.layer.1.attention.self.key.weight', 'ctx_encoder.bert_model.encoder.layer.1.attention.self.query.bias', 'ctx_encoder.bert_model.encoder.layer.1.attention.self.query.weight', 'ctx_encoder.bert_model.encoder.layer.1.attention.self.value.bias', 'ctx_encoder.bert_model.encoder.layer.1.attention.self.value.weight', 'ctx_encoder.bert_model.encoder.layer.1.intermediate.dense.bias', 'ctx_encoder.bert_model.encoder.layer.1.intermediate.dense.weight', 'ctx_encoder.bert_model.encoder.layer.1.output.LayerNorm.bias', 'ctx_encoder.bert_model.encoder.layer.1.output.LayerNorm.weight', 'ctx_encoder.bert_model.encoder.layer.1.output.dense.bias', 'ctx_encoder.bert_model.encoder.layer.1.output.dense.weight', 'ctx_encoder.bert_model.encoder.layer.10.attention.output.LayerNorm.bias', 'ctx_encoder.bert_model.encoder.layer.10.attention.output.LayerNorm.weight', 'ctx_encoder.bert_model.encoder.layer.10.attention.output.dense.bias', 'ctx_encoder.bert_model.encoder.layer.10.attention.output.dense.weight', 'ctx_encoder.bert_model.encoder.layer.10.attention.self.key.bias', 'ctx_encoder.bert_model.encoder.layer.10.attention.self.key.weight', 'ctx_encoder.bert_model.encoder.layer.10.attention.self.query.bias', 'ctx_encoder.bert_model.encoder.layer.10.attention.self.query.weight', 'ctx_encoder.bert_model.encoder.layer.10.attention.self.value.bias', 'ctx_encoder.bert_model.encoder.layer.10.attention.self.value.weight', 'ctx_encoder.bert_model.encoder.layer.10.intermediate.dense.bias', 'ctx_encoder.bert_model.encoder.layer.10.intermediate.dense.weight', 'ctx_encoder.bert_model.encoder.layer.10.output.LayerNorm.bias', 'ctx_encoder.bert_model.encoder.layer.10.output.LayerNorm.weight', 'ctx_encoder.bert_model.encoder.layer.10.output.dense.bias', 'ctx_encoder.bert_model.encoder.layer.10.output.dense.weight', 'ctx_encoder.bert_model.encoder.layer.11.attention.output.LayerNorm.bias', 'ctx_encoder.bert_model.encoder.layer.11.attention.output.LayerNorm.weight', 'ctx_encoder.bert_model.encoder.layer.11.attention.output.dense.bias', 'ctx_encoder.bert_model.encoder.layer.11.attention.output.dense.weight', 'ctx_encoder.bert_model.encoder.layer.11.attention.self.key.bias', 'ctx_encoder.bert_model.encoder.layer.11.attention.self.key.weight', 'ctx_encoder.bert_model.encoder.layer.11.attention.self.query.bias', 'ctx_encoder.bert_model.encoder.layer.11.attention.self.query.weight', 'ctx_encoder.bert_model.encoder.layer.11.attention.self.value.bias', 'ctx_encoder.bert_model.encoder.layer.11.attention.self.value.weight', 'ctx_encoder.bert_model.encoder.layer.11.intermediate.dense.bias', 'ctx_encoder.bert_model.encoder.layer.11.intermediate.dense.weight', 'ctx_encoder.bert_model.encoder.layer.11.output.LayerNorm.bias', 'ctx_encoder.bert_model.encoder.layer.11.output.LayerNorm.weight', 'ctx_encoder.bert_model.encoder.layer.11.output.dense.bias', 'ctx_encoder.bert_model.encoder.layer.11.output.dense.weight', 'ctx_encoder.bert_model.encoder.layer.2.attention.output.LayerNorm.bias', 'ctx_encoder.bert_model.encoder.layer.2.attention.output.LayerNorm.weight', 'ctx_encoder.bert_model.encoder.layer.2.attention.output.dense.bias', 'ctx_encoder.bert_model.encoder.layer.2.attention.output.dense.weight', 'ctx_encoder.bert_model.encoder.layer.2.attention.self.key.bias', 'ctx_encoder.bert_model.encoder.layer.2.attention.self.key.weight', 'ctx_encoder.bert_model.encoder.layer.2.attention.self.query.bias', 'ctx_encoder.bert_model.encoder.layer.2.attention.self.query.weight', 'ctx_encoder.bert_model.encoder.layer.2.attention.self.value.bias', 'ctx_encoder.bert_model.encoder.layer.2.attention.self.value.weight', 'ctx_encoder.bert_model.encoder.layer.2.intermediate.dense.bias', 'ctx_encoder.bert_model.encoder.layer.2.intermediate.dense.weight', 'ctx_encoder.bert_model.encoder.layer.2.output.LayerNorm.bias', 'ctx_encoder.bert_model.encoder.layer.2.output.LayerNorm.weight', 'ctx_encoder.bert_model.encoder.layer.2.output.dense.bias', 'ctx_encoder.bert_model.encoder.layer.2.output.dense.weight', 'ctx_encoder.bert_model.encoder.layer.3.attention.output.LayerNorm.bias', 'ctx_encoder.bert_model.encoder.layer.3.attention.output.LayerNorm.weight', 'ctx_encoder.bert_model.encoder.layer.3.attention.output.dense.bias', 'ctx_encoder.bert_model.encoder.layer.3.attention.output.dense.weight', 'ctx_encoder.bert_model.encoder.layer.3.attention.self.key.bias', 'ctx_encoder.bert_model.encoder.layer.3.attention.self.key.weight', 'ctx_encoder.bert_model.encoder.layer.3.attention.self.query.bias', 'ctx_encoder.bert_model.encoder.layer.3.attention.self.query.weight', 'ctx_encoder.bert_model.encoder.layer.3.attention.self.value.bias', 'ctx_encoder.bert_model.encoder.layer.3.attention.self.value.weight', 'ctx_encoder.bert_model.encoder.layer.3.intermediate.dense.bias', 'ctx_encoder.bert_model.encoder.layer.3.intermediate.dense.weight', 'ctx_encoder.bert_model.encoder.layer.3.output.LayerNorm.bias', 'ctx_encoder.bert_model.encoder.layer.3.output.LayerNorm.weight', 'ctx_encoder.bert_model.encoder.layer.3.output.dense.bias', 'ctx_encoder.bert_model.encoder.layer.3.output.dense.weight', 'ctx_encoder.bert_model.encoder.layer.4.attention.output.LayerNorm.bias', 'ctx_encoder.bert_model.encoder.layer.4.attention.output.LayerNorm.weight', 'ctx_encoder.bert_model.encoder.layer.4.attention.output.dense.bias', 'ctx_encoder.bert_model.encoder.layer.4.attention.output.dense.weight', 'ctx_encoder.bert_model.encoder.layer.4.attention.self.key.bias', 'ctx_encoder.bert_model.encoder.layer.4.attention.self.key.weight', 'ctx_encoder.bert_model.encoder.layer.4.attention.self.query.bias', 'ctx_encoder.bert_model.encoder.layer.4.attention.self.query.weight', 'ctx_encoder.bert_model.encoder.layer.4.attention.self.value.bias', 'ctx_encoder.bert_model.encoder.layer.4.attention.self.value.weight', 'ctx_encoder.bert_model.encoder.layer.4.intermediate.dense.bias', 'ctx_encoder.bert_model.encoder.layer.4.intermediate.dense.weight', 'ctx_encoder.bert_model.encoder.layer.4.output.LayerNorm.bias', 'ctx_encoder.bert_model.encoder.layer.4.output.LayerNorm.weight', 'ctx_encoder.bert_model.encoder.layer.4.output.dense.bias', 'ctx_encoder.bert_model.encoder.layer.4.output.dense.weight', 'ctx_encoder.bert_model.encoder.layer.5.attention.output.LayerNorm.bias', 'ctx_encoder.bert_model.encoder.layer.5.attention.output.LayerNorm.weight', 'ctx_encoder.bert_model.encoder.layer.5.attention.output.dense.bias', 'ctx_encoder.bert_model.encoder.layer.5.attention.output.dense.weight', 'ctx_encoder.bert_model.encoder.layer.5.attention.self.key.bias', 'ctx_encoder.bert_model.encoder.layer.5.attention.self.key.weight', 'ctx_encoder.bert_model.encoder.layer.5.attention.self.query.bias', 'ctx_encoder.bert_model.encoder.layer.5.attention.self.query.weight', 'ctx_encoder.bert_model.encoder.layer.5.attention.self.value.bias', 'ctx_encoder.bert_model.encoder.layer.5.attention.self.value.weight', 'ctx_encoder.bert_model.encoder.layer.5.intermediate.dense.bias', 'ctx_encoder.bert_model.encoder.layer.5.intermediate.dense.weight', 'ctx_encoder.bert_model.encoder.layer.5.output.LayerNorm.bias', 'ctx_encoder.bert_model.encoder.layer.5.output.LayerNorm.weight', 'ctx_encoder.bert_model.encoder.layer.5.output.dense.bias', 'ctx_encoder.bert_model.encoder.layer.5.output.dense.weight', 'ctx_encoder.bert_model.encoder.layer.6.attention.output.LayerNorm.bias', 'ctx_encoder.bert_model.encoder.layer.6.attention.output.LayerNorm.weight', 'ctx_encoder.bert_model.encoder.layer.6.attention.output.dense.bias', 'ctx_encoder.bert_model.encoder.layer.6.attention.output.dense.weight', 'ctx_encoder.bert_model.encoder.layer.6.attention.self.key.bias', 'ctx_encoder.bert_model.encoder.layer.6.attention.self.key.weight', 'ctx_encoder.bert_model.encoder.layer.6.attention.self.query.bias', 'ctx_encoder.bert_model.encoder.layer.6.attention.self.query.weight', 'ctx_encoder.bert_model.encoder.layer.6.attention.self.value.bias', 'ctx_encoder.bert_model.encoder.layer.6.attention.self.value.weight', 'ctx_encoder.bert_model.encoder.layer.6.intermediate.dense.bias', 'ctx_encoder.bert_model.encoder.layer.6.intermediate.dense.weight', 'ctx_encoder.bert_model.encoder.layer.6.output.LayerNorm.bias', 'ctx_encoder.bert_model.encoder.layer.6.output.LayerNorm.weight', 'ctx_encoder.bert_model.encoder.layer.6.output.dense.bias', 'ctx_encoder.bert_model.encoder.layer.6.output.dense.weight', 'ctx_encoder.bert_model.encoder.layer.7.attention.output.LayerNorm.bias', 'ctx_encoder.bert_model.encoder.layer.7.attention.output.LayerNorm.weight', 'ctx_encoder.bert_model.encoder.layer.7.attention.output.dense.bias', 'ctx_encoder.bert_model.encoder.layer.7.attention.output.dense.weight', 'ctx_encoder.bert_model.encoder.layer.7.attention.self.key.bias', 'ctx_encoder.bert_model.encoder.layer.7.attention.self.key.weight', 'ctx_encoder.bert_model.encoder.layer.7.attention.self.query.bias', 'ctx_encoder.bert_model.encoder.layer.7.attention.self.query.weight', 'ctx_encoder.bert_model.encoder.layer.7.attention.self.value.bias', 'ctx_encoder.bert_model.encoder.layer.7.attention.self.value.weight', 'ctx_encoder.bert_model.encoder.layer.7.intermediate.dense.bias', 'ctx_encoder.bert_model.encoder.layer.7.intermediate.dense.weight', 'ctx_encoder.bert_model.encoder.layer.7.output.LayerNorm.bias', 'ctx_encoder.bert_model.encoder.layer.7.output.LayerNorm.weight', 'ctx_encoder.bert_model.encoder.layer.7.output.dense.bias', 'ctx_encoder.bert_model.encoder.layer.7.output.dense.weight', 'ctx_encoder.bert_model.encoder.layer.8.attention.output.LayerNorm.bias', 'ctx_encoder.bert_model.encoder.layer.8.attention.output.LayerNorm.weight', 'ctx_encoder.bert_model.encoder.layer.8.attention.output.dense.bias', 'ctx_encoder.bert_model.encoder.layer.8.attention.output.dense.weight', 'ctx_encoder.bert_model.encoder.layer.8.attention.self.key.bias', 'ctx_encoder.bert_model.encoder.layer.8.attention.self.key.weight', 'ctx_encoder.bert_model.encoder.layer.8.attention.self.query.bias', 'ctx_encoder.bert_model.encoder.layer.8.attention.self.query.weight', 'ctx_encoder.bert_model.encoder.layer.8.attention.self.value.bias', 'ctx_encoder.bert_model.encoder.layer.8.attention.self.value.weight', 'ctx_encoder.bert_model.encoder.layer.8.intermediate.dense.bias', 'ctx_encoder.bert_model.encoder.layer.8.intermediate.dense.weight', 'ctx_encoder.bert_model.encoder.layer.8.output.LayerNorm.bias', 'ctx_encoder.bert_model.encoder.layer.8.output.LayerNorm.weight', 'ctx_encoder.bert_model.encoder.layer.8.output.dense.bias', 'ctx_encoder.bert_model.encoder.layer.8.output.dense.weight', 'ctx_encoder.bert_model.encoder.layer.9.attention.output.LayerNorm.bias', 'ctx_encoder.bert_model.encoder.layer.9.attention.output.LayerNorm.weight', 'ctx_encoder.bert_model.encoder.layer.9.attention.output.dense.bias', 'ctx_encoder.bert_model.encoder.layer.9.attention.output.dense.weight', 'ctx_encoder.bert_model.encoder.layer.9.attention.self.key.bias', 'ctx_encoder.bert_model.encoder.layer.9.attention.self.key.weight', 'ctx_encoder.bert_model.encoder.layer.9.attention.self.query.bias', 'ctx_encoder.bert_model.encoder.layer.9.attention.self.query.weight', 'ctx_encoder.bert_model.encoder.layer.9.attention.self.value.bias', 'ctx_encoder.bert_model.encoder.layer.9.attention.self.value.weight', 'ctx_encoder.bert_model.encoder.layer.9.intermediate.dense.bias', 'ctx_encoder.bert_model.encoder.layer.9.intermediate.dense.weight', 'ctx_encoder.bert_model.encoder.layer.9.output.LayerNorm.bias', 'ctx_encoder.bert_model.encoder.layer.9.output.LayerNorm.weight', 'ctx_encoder.bert_model.encoder.layer.9.output.dense.bias', 'ctx_encoder.bert_model.encoder.layer.9.output.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'BertTokenizer'. \n",
      "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n",
      "You are using a model of type bert to instantiate a model of type dpr. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of DPRQuestionEncoder were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['question_encoder.bert_model.embeddings.LayerNorm.bias', 'question_encoder.bert_model.embeddings.LayerNorm.weight', 'question_encoder.bert_model.embeddings.position_embeddings.weight', 'question_encoder.bert_model.embeddings.token_type_embeddings.weight', 'question_encoder.bert_model.embeddings.word_embeddings.weight', 'question_encoder.bert_model.encoder.layer.0.attention.output.LayerNorm.bias', 'question_encoder.bert_model.encoder.layer.0.attention.output.LayerNorm.weight', 'question_encoder.bert_model.encoder.layer.0.attention.output.dense.bias', 'question_encoder.bert_model.encoder.layer.0.attention.output.dense.weight', 'question_encoder.bert_model.encoder.layer.0.attention.self.key.bias', 'question_encoder.bert_model.encoder.layer.0.attention.self.key.weight', 'question_encoder.bert_model.encoder.layer.0.attention.self.query.bias', 'question_encoder.bert_model.encoder.layer.0.attention.self.query.weight', 'question_encoder.bert_model.encoder.layer.0.attention.self.value.bias', 'question_encoder.bert_model.encoder.layer.0.attention.self.value.weight', 'question_encoder.bert_model.encoder.layer.0.intermediate.dense.bias', 'question_encoder.bert_model.encoder.layer.0.intermediate.dense.weight', 'question_encoder.bert_model.encoder.layer.0.output.LayerNorm.bias', 'question_encoder.bert_model.encoder.layer.0.output.LayerNorm.weight', 'question_encoder.bert_model.encoder.layer.0.output.dense.bias', 'question_encoder.bert_model.encoder.layer.0.output.dense.weight', 'question_encoder.bert_model.encoder.layer.1.attention.output.LayerNorm.bias', 'question_encoder.bert_model.encoder.layer.1.attention.output.LayerNorm.weight', 'question_encoder.bert_model.encoder.layer.1.attention.output.dense.bias', 'question_encoder.bert_model.encoder.layer.1.attention.output.dense.weight', 'question_encoder.bert_model.encoder.layer.1.attention.self.key.bias', 'question_encoder.bert_model.encoder.layer.1.attention.self.key.weight', 'question_encoder.bert_model.encoder.layer.1.attention.self.query.bias', 'question_encoder.bert_model.encoder.layer.1.attention.self.query.weight', 'question_encoder.bert_model.encoder.layer.1.attention.self.value.bias', 'question_encoder.bert_model.encoder.layer.1.attention.self.value.weight', 'question_encoder.bert_model.encoder.layer.1.intermediate.dense.bias', 'question_encoder.bert_model.encoder.layer.1.intermediate.dense.weight', 'question_encoder.bert_model.encoder.layer.1.output.LayerNorm.bias', 'question_encoder.bert_model.encoder.layer.1.output.LayerNorm.weight', 'question_encoder.bert_model.encoder.layer.1.output.dense.bias', 'question_encoder.bert_model.encoder.layer.1.output.dense.weight', 'question_encoder.bert_model.encoder.layer.10.attention.output.LayerNorm.bias', 'question_encoder.bert_model.encoder.layer.10.attention.output.LayerNorm.weight', 'question_encoder.bert_model.encoder.layer.10.attention.output.dense.bias', 'question_encoder.bert_model.encoder.layer.10.attention.output.dense.weight', 'question_encoder.bert_model.encoder.layer.10.attention.self.key.bias', 'question_encoder.bert_model.encoder.layer.10.attention.self.key.weight', 'question_encoder.bert_model.encoder.layer.10.attention.self.query.bias', 'question_encoder.bert_model.encoder.layer.10.attention.self.query.weight', 'question_encoder.bert_model.encoder.layer.10.attention.self.value.bias', 'question_encoder.bert_model.encoder.layer.10.attention.self.value.weight', 'question_encoder.bert_model.encoder.layer.10.intermediate.dense.bias', 'question_encoder.bert_model.encoder.layer.10.intermediate.dense.weight', 'question_encoder.bert_model.encoder.layer.10.output.LayerNorm.bias', 'question_encoder.bert_model.encoder.layer.10.output.LayerNorm.weight', 'question_encoder.bert_model.encoder.layer.10.output.dense.bias', 'question_encoder.bert_model.encoder.layer.10.output.dense.weight', 'question_encoder.bert_model.encoder.layer.11.attention.output.LayerNorm.bias', 'question_encoder.bert_model.encoder.layer.11.attention.output.LayerNorm.weight', 'question_encoder.bert_model.encoder.layer.11.attention.output.dense.bias', 'question_encoder.bert_model.encoder.layer.11.attention.output.dense.weight', 'question_encoder.bert_model.encoder.layer.11.attention.self.key.bias', 'question_encoder.bert_model.encoder.layer.11.attention.self.key.weight', 'question_encoder.bert_model.encoder.layer.11.attention.self.query.bias', 'question_encoder.bert_model.encoder.layer.11.attention.self.query.weight', 'question_encoder.bert_model.encoder.layer.11.attention.self.value.bias', 'question_encoder.bert_model.encoder.layer.11.attention.self.value.weight', 'question_encoder.bert_model.encoder.layer.11.intermediate.dense.bias', 'question_encoder.bert_model.encoder.layer.11.intermediate.dense.weight', 'question_encoder.bert_model.encoder.layer.11.output.LayerNorm.bias', 'question_encoder.bert_model.encoder.layer.11.output.LayerNorm.weight', 'question_encoder.bert_model.encoder.layer.11.output.dense.bias', 'question_encoder.bert_model.encoder.layer.11.output.dense.weight', 'question_encoder.bert_model.encoder.layer.2.attention.output.LayerNorm.bias', 'question_encoder.bert_model.encoder.layer.2.attention.output.LayerNorm.weight', 'question_encoder.bert_model.encoder.layer.2.attention.output.dense.bias', 'question_encoder.bert_model.encoder.layer.2.attention.output.dense.weight', 'question_encoder.bert_model.encoder.layer.2.attention.self.key.bias', 'question_encoder.bert_model.encoder.layer.2.attention.self.key.weight', 'question_encoder.bert_model.encoder.layer.2.attention.self.query.bias', 'question_encoder.bert_model.encoder.layer.2.attention.self.query.weight', 'question_encoder.bert_model.encoder.layer.2.attention.self.value.bias', 'question_encoder.bert_model.encoder.layer.2.attention.self.value.weight', 'question_encoder.bert_model.encoder.layer.2.intermediate.dense.bias', 'question_encoder.bert_model.encoder.layer.2.intermediate.dense.weight', 'question_encoder.bert_model.encoder.layer.2.output.LayerNorm.bias', 'question_encoder.bert_model.encoder.layer.2.output.LayerNorm.weight', 'question_encoder.bert_model.encoder.layer.2.output.dense.bias', 'question_encoder.bert_model.encoder.layer.2.output.dense.weight', 'question_encoder.bert_model.encoder.layer.3.attention.output.LayerNorm.bias', 'question_encoder.bert_model.encoder.layer.3.attention.output.LayerNorm.weight', 'question_encoder.bert_model.encoder.layer.3.attention.output.dense.bias', 'question_encoder.bert_model.encoder.layer.3.attention.output.dense.weight', 'question_encoder.bert_model.encoder.layer.3.attention.self.key.bias', 'question_encoder.bert_model.encoder.layer.3.attention.self.key.weight', 'question_encoder.bert_model.encoder.layer.3.attention.self.query.bias', 'question_encoder.bert_model.encoder.layer.3.attention.self.query.weight', 'question_encoder.bert_model.encoder.layer.3.attention.self.value.bias', 'question_encoder.bert_model.encoder.layer.3.attention.self.value.weight', 'question_encoder.bert_model.encoder.layer.3.intermediate.dense.bias', 'question_encoder.bert_model.encoder.layer.3.intermediate.dense.weight', 'question_encoder.bert_model.encoder.layer.3.output.LayerNorm.bias', 'question_encoder.bert_model.encoder.layer.3.output.LayerNorm.weight', 'question_encoder.bert_model.encoder.layer.3.output.dense.bias', 'question_encoder.bert_model.encoder.layer.3.output.dense.weight', 'question_encoder.bert_model.encoder.layer.4.attention.output.LayerNorm.bias', 'question_encoder.bert_model.encoder.layer.4.attention.output.LayerNorm.weight', 'question_encoder.bert_model.encoder.layer.4.attention.output.dense.bias', 'question_encoder.bert_model.encoder.layer.4.attention.output.dense.weight', 'question_encoder.bert_model.encoder.layer.4.attention.self.key.bias', 'question_encoder.bert_model.encoder.layer.4.attention.self.key.weight', 'question_encoder.bert_model.encoder.layer.4.attention.self.query.bias', 'question_encoder.bert_model.encoder.layer.4.attention.self.query.weight', 'question_encoder.bert_model.encoder.layer.4.attention.self.value.bias', 'question_encoder.bert_model.encoder.layer.4.attention.self.value.weight', 'question_encoder.bert_model.encoder.layer.4.intermediate.dense.bias', 'question_encoder.bert_model.encoder.layer.4.intermediate.dense.weight', 'question_encoder.bert_model.encoder.layer.4.output.LayerNorm.bias', 'question_encoder.bert_model.encoder.layer.4.output.LayerNorm.weight', 'question_encoder.bert_model.encoder.layer.4.output.dense.bias', 'question_encoder.bert_model.encoder.layer.4.output.dense.weight', 'question_encoder.bert_model.encoder.layer.5.attention.output.LayerNorm.bias', 'question_encoder.bert_model.encoder.layer.5.attention.output.LayerNorm.weight', 'question_encoder.bert_model.encoder.layer.5.attention.output.dense.bias', 'question_encoder.bert_model.encoder.layer.5.attention.output.dense.weight', 'question_encoder.bert_model.encoder.layer.5.attention.self.key.bias', 'question_encoder.bert_model.encoder.layer.5.attention.self.key.weight', 'question_encoder.bert_model.encoder.layer.5.attention.self.query.bias', 'question_encoder.bert_model.encoder.layer.5.attention.self.query.weight', 'question_encoder.bert_model.encoder.layer.5.attention.self.value.bias', 'question_encoder.bert_model.encoder.layer.5.attention.self.value.weight', 'question_encoder.bert_model.encoder.layer.5.intermediate.dense.bias', 'question_encoder.bert_model.encoder.layer.5.intermediate.dense.weight', 'question_encoder.bert_model.encoder.layer.5.output.LayerNorm.bias', 'question_encoder.bert_model.encoder.layer.5.output.LayerNorm.weight', 'question_encoder.bert_model.encoder.layer.5.output.dense.bias', 'question_encoder.bert_model.encoder.layer.5.output.dense.weight', 'question_encoder.bert_model.encoder.layer.6.attention.output.LayerNorm.bias', 'question_encoder.bert_model.encoder.layer.6.attention.output.LayerNorm.weight', 'question_encoder.bert_model.encoder.layer.6.attention.output.dense.bias', 'question_encoder.bert_model.encoder.layer.6.attention.output.dense.weight', 'question_encoder.bert_model.encoder.layer.6.attention.self.key.bias', 'question_encoder.bert_model.encoder.layer.6.attention.self.key.weight', 'question_encoder.bert_model.encoder.layer.6.attention.self.query.bias', 'question_encoder.bert_model.encoder.layer.6.attention.self.query.weight', 'question_encoder.bert_model.encoder.layer.6.attention.self.value.bias', 'question_encoder.bert_model.encoder.layer.6.attention.self.value.weight', 'question_encoder.bert_model.encoder.layer.6.intermediate.dense.bias', 'question_encoder.bert_model.encoder.layer.6.intermediate.dense.weight', 'question_encoder.bert_model.encoder.layer.6.output.LayerNorm.bias', 'question_encoder.bert_model.encoder.layer.6.output.LayerNorm.weight', 'question_encoder.bert_model.encoder.layer.6.output.dense.bias', 'question_encoder.bert_model.encoder.layer.6.output.dense.weight', 'question_encoder.bert_model.encoder.layer.7.attention.output.LayerNorm.bias', 'question_encoder.bert_model.encoder.layer.7.attention.output.LayerNorm.weight', 'question_encoder.bert_model.encoder.layer.7.attention.output.dense.bias', 'question_encoder.bert_model.encoder.layer.7.attention.output.dense.weight', 'question_encoder.bert_model.encoder.layer.7.attention.self.key.bias', 'question_encoder.bert_model.encoder.layer.7.attention.self.key.weight', 'question_encoder.bert_model.encoder.layer.7.attention.self.query.bias', 'question_encoder.bert_model.encoder.layer.7.attention.self.query.weight', 'question_encoder.bert_model.encoder.layer.7.attention.self.value.bias', 'question_encoder.bert_model.encoder.layer.7.attention.self.value.weight', 'question_encoder.bert_model.encoder.layer.7.intermediate.dense.bias', 'question_encoder.bert_model.encoder.layer.7.intermediate.dense.weight', 'question_encoder.bert_model.encoder.layer.7.output.LayerNorm.bias', 'question_encoder.bert_model.encoder.layer.7.output.LayerNorm.weight', 'question_encoder.bert_model.encoder.layer.7.output.dense.bias', 'question_encoder.bert_model.encoder.layer.7.output.dense.weight', 'question_encoder.bert_model.encoder.layer.8.attention.output.LayerNorm.bias', 'question_encoder.bert_model.encoder.layer.8.attention.output.LayerNorm.weight', 'question_encoder.bert_model.encoder.layer.8.attention.output.dense.bias', 'question_encoder.bert_model.encoder.layer.8.attention.output.dense.weight', 'question_encoder.bert_model.encoder.layer.8.attention.self.key.bias', 'question_encoder.bert_model.encoder.layer.8.attention.self.key.weight', 'question_encoder.bert_model.encoder.layer.8.attention.self.query.bias', 'question_encoder.bert_model.encoder.layer.8.attention.self.query.weight', 'question_encoder.bert_model.encoder.layer.8.attention.self.value.bias', 'question_encoder.bert_model.encoder.layer.8.attention.self.value.weight', 'question_encoder.bert_model.encoder.layer.8.intermediate.dense.bias', 'question_encoder.bert_model.encoder.layer.8.intermediate.dense.weight', 'question_encoder.bert_model.encoder.layer.8.output.LayerNorm.bias', 'question_encoder.bert_model.encoder.layer.8.output.LayerNorm.weight', 'question_encoder.bert_model.encoder.layer.8.output.dense.bias', 'question_encoder.bert_model.encoder.layer.8.output.dense.weight', 'question_encoder.bert_model.encoder.layer.9.attention.output.LayerNorm.bias', 'question_encoder.bert_model.encoder.layer.9.attention.output.LayerNorm.weight', 'question_encoder.bert_model.encoder.layer.9.attention.output.dense.bias', 'question_encoder.bert_model.encoder.layer.9.attention.output.dense.weight', 'question_encoder.bert_model.encoder.layer.9.attention.self.key.bias', 'question_encoder.bert_model.encoder.layer.9.attention.self.key.weight', 'question_encoder.bert_model.encoder.layer.9.attention.self.query.bias', 'question_encoder.bert_model.encoder.layer.9.attention.self.query.weight', 'question_encoder.bert_model.encoder.layer.9.attention.self.value.bias', 'question_encoder.bert_model.encoder.layer.9.attention.self.value.weight', 'question_encoder.bert_model.encoder.layer.9.intermediate.dense.bias', 'question_encoder.bert_model.encoder.layer.9.intermediate.dense.weight', 'question_encoder.bert_model.encoder.layer.9.output.LayerNorm.bias', 'question_encoder.bert_model.encoder.layer.9.output.LayerNorm.weight', 'question_encoder.bert_model.encoder.layer.9.output.dense.bias', 'question_encoder.bert_model.encoder.layer.9.output.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'BertTokenizer'. \n",
      "The class this function is called from is 'DPRQuestionEncoderTokenizerFast'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Model initialized\n",
      "\n",
      "ðŸš€ Starting training for 5 epochs...\n",
      "\n",
      "============================================================\n",
      "Epoch 1/5\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1049/1049 [00:00<00:00, 1856.59 examples/s]\n",
      "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]c:\\Users\\ASUS\\anaconda3\\envs\\mltorch311\\Lib\\site-packages\\simpletransformers\\retrieval\\retrieval_model.py:882: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = amp.GradScaler()\n",
      "Epoch 1 of 1:   0%|          | 0/1 [00:00<?, ?it/s]c:\\Users\\ASUS\\anaconda3\\envs\\mltorch311\\Lib\\site-packages\\simpletransformers\\retrieval\\retrieval_model.py:926: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast():\n",
      "Epochs 1/1. Running Loss:   12.0874 Correct percentage:  0.0:  14%|â–ˆâ–Ž        | 72/525 [02:01<12:47,  1.69s/it]\n",
      "Epoch 1 of 1:   0%|          | 0/1 [02:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 37\u001b[39m\n\u001b[32m     34\u001b[39m temp_args.output_dir = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mMODEL_DIR\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/dpr_bm25_baseline_epoch\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m     \u001b[43mdpr_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsmarco_train_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     38\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mâœ… Epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m+\u001b[38;5;250m \u001b[39m\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m complete!\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     40\u001b[39m     \u001b[38;5;66;03m# Clear GPU cache after epoch\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ASUS\\anaconda3\\envs\\mltorch311\\Lib\\site-packages\\simpletransformers\\retrieval\\retrieval_model.py:629\u001b[39m, in \u001b[36mRetrievalModel.train_model\u001b[39m\u001b[34m(self, train_data, output_dir, show_running_loss, args, eval_data, additional_eval_passages, relevant_docs, clustered_training, top_k_values, verbose, eval_set, eval_dataset_names, **kwargs)\u001b[39m\n\u001b[32m    619\u001b[39m train_dataset = \u001b[38;5;28mself\u001b[39m.load_and_cache_examples(\n\u001b[32m    620\u001b[39m     train_data,\n\u001b[32m    621\u001b[39m     verbose=verbose,\n\u001b[32m   (...)\u001b[39m\u001b[32m    624\u001b[39m     additional_eval_passages=additional_eval_passages,\n\u001b[32m    625\u001b[39m )\n\u001b[32m    627\u001b[39m os.makedirs(output_dir, exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m629\u001b[39m global_step, training_details = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    630\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    631\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    632\u001b[39m \u001b[43m    \u001b[49m\u001b[43mshow_running_loss\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_running_loss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    633\u001b[39m \u001b[43m    \u001b[49m\u001b[43meval_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    634\u001b[39m \u001b[43m    \u001b[49m\u001b[43madditional_eval_passages\u001b[49m\u001b[43m=\u001b[49m\u001b[43madditional_eval_passages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    635\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrelevant_docs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrelevant_docs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    636\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclustered_training\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclustered_training\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    637\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    638\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtop_k_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtop_k_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    639\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    640\u001b[39m \u001b[43m    \u001b[49m\u001b[43meval_set\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    641\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    642\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    644\u001b[39m \u001b[38;5;28mself\u001b[39m.save_model(\n\u001b[32m    645\u001b[39m     \u001b[38;5;28mself\u001b[39m.args.output_dir,\n\u001b[32m    646\u001b[39m     context_model=\u001b[38;5;28mself\u001b[39m.context_encoder,\n\u001b[32m    647\u001b[39m     query_model=\u001b[38;5;28mself\u001b[39m.query_encoder,\n\u001b[32m    648\u001b[39m )\n\u001b[32m    650\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m verbose:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ASUS\\anaconda3\\envs\\mltorch311\\Lib\\site-packages\\simpletransformers\\retrieval\\retrieval_model.py:920\u001b[39m, in \u001b[36mRetrievalModel.train\u001b[39m\u001b[34m(self, train_dataset, output_dir, show_running_loss, eval_data, additional_eval_passages, relevant_docs, clustered_training, train_data, top_k_values, verbose, eval_set, **kwargs)\u001b[39m\n\u001b[32m    913\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m    914\u001b[39m \u001b[38;5;66;03m# batch = tuple(t.to(device) for t in batch)\u001b[39;00m\n\u001b[32m    915\u001b[39m (\n\u001b[32m    916\u001b[39m     context_inputs,\n\u001b[32m    917\u001b[39m     query_inputs,\n\u001b[32m    918\u001b[39m     labels,\n\u001b[32m    919\u001b[39m     teacher_scores,\n\u001b[32m--> \u001b[39m\u001b[32m920\u001b[39m ) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_inputs_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    922\u001b[39m high_loss_repeats = \u001b[32m0\u001b[39m\n\u001b[32m    924\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ASUS\\anaconda3\\envs\\mltorch311\\Lib\\site-packages\\simpletransformers\\retrieval\\retrieval_model.py:3479\u001b[39m, in \u001b[36mRetrievalModel._get_inputs_dict\u001b[39m\u001b[34m(self, batch, evaluate)\u001b[39m\n\u001b[32m   3477\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   3478\u001b[39m         labels = [i \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(batch[\u001b[33m\"\u001b[39m\u001b[33mcontext_ids\u001b[39m\u001b[33m\"\u001b[39m]))]\n\u001b[32m-> \u001b[39m\u001b[32m3479\u001b[39m     labels = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlong\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3480\u001b[39m margins = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   3481\u001b[39m true_p_scores = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Cell 14: Training with Memory Cleanup (MODIFIED)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STAGE 1: TRAINING ON MS MARCO (ENGLISH)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Clear memory before starting\n",
    "clear_gpu_memory()\n",
    "\n",
    "# Initialize model\n",
    "print(\"\\nInitializing DPR model...\")\n",
    "dpr_model = RetrievalModel(\n",
    "    model_type=\"dpr\",\n",
    "    model_name=None,\n",
    "    context_encoder_name=BASE_MODEL,\n",
    "    query_encoder_name=BASE_MODEL,\n",
    "    args=model_args,\n",
    "    use_cuda=torch.cuda.is_available()\n",
    ")\n",
    "\n",
    "print(\"âœ“ Model initialized\")\n",
    "\n",
    "# Train epoch by epoch with cleanup\n",
    "print(f\"\\nðŸš€ Starting training for {model_args.num_train_epochs} epochs...\")\n",
    "\n",
    "for epoch in range(model_args.num_train_epochs):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Epoch {epoch + 1}/{model_args.num_train_epochs}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Train for 1 epoch\n",
    "    temp_args = model_args\n",
    "    temp_args.num_train_epochs = 1\n",
    "    temp_args.output_dir = f\"{MODEL_DIR}/dpr_bm25_baseline_epoch{epoch+1}\"\n",
    "    \n",
    "    try:\n",
    "        dpr_model.train_model(msmarco_train_df)\n",
    "        print(f\"âœ… Epoch {epoch + 1} complete!\")\n",
    "        \n",
    "        # Clear GPU cache after epoch\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "            print(f\"  Memory cleared after epoch {epoch + 1}\")\n",
    "            \n",
    "    except RuntimeError as e:\n",
    "        if \"out of memory\" in str(e).lower():\n",
    "            print(f\"\\nâŒ OOM at epoch {epoch + 1}\")\n",
    "            # Try to recover\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "        raise\n",
    "\n",
    "# Save final model\n",
    "print(\"\\nSaving final model...\")\n",
    "dpr_model.save_model(f\"{MODEL_DIR}/dpr_bm25_msmarco_final\")\n",
    "print(f\"âœ“ Model saved\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da62bccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic evaluation on dev set\n",
    "\n",
    "def evaluate_retrieval_simple(model, eval_df: pd.DataFrame, top_k: int = 10) -> dict:\n",
    "    \"\"\"Simple evaluation: check if positive in top-k\"\"\"\n",
    "    \n",
    "    print(f\"\\n=== Evaluating on {len(eval_df)} samples ===\")\n",
    "    \n",
    "    correct = 0\n",
    "    total = len(eval_df)\n",
    "    \n",
    "    for idx, row in tqdm(eval_df.iterrows(), total=min(total, 100), desc=\"Evaluating\"):\n",
    "        if idx >= 100:  # Limit for speed\n",
    "            break\n",
    "            \n",
    "        query = row['query']\n",
    "        positive = row['positive_passage']\n",
    "        \n",
    "        # Get random candidates + positive\n",
    "        random_indices = np.random.choice(len(eval_df), size=min(20, len(eval_df)), replace=False)\n",
    "        candidates = [eval_df.iloc[i]['positive_passage'] for i in random_indices]\n",
    "        \n",
    "        # Ensure positive is in candidates\n",
    "        if positive not in candidates:\n",
    "            candidates[0] = positive\n",
    "        \n",
    "        # Score candidates (simplified)\n",
    "        # In real eval, we'd encode and compute similarities\n",
    "        # For now, just random (placeholder)\n",
    "        scores = np.random.rand(len(candidates))\n",
    "        top_indices = np.argsort(scores)[-top_k:]\n",
    "        \n",
    "        if positive in [candidates[i] for i in top_indices]:\n",
    "            correct += 1\n",
    "    \n",
    "    accuracy = correct / min(total, 100)\n",
    "    \n",
    "    print(f\"\\nâœ“ Top-{top_k} Accuracy: {accuracy:.2%}\")\n",
    "    return {\"top_k_accuracy\": accuracy}\n",
    "\n",
    "# Evaluate on dev set\n",
    "if len(msmarco_dev) > 0:\n",
    "    metrics = evaluate_retrieval_simple(dpr_model, msmarco_dev)\n",
    "else:\n",
    "    print(\"âš  No dev set available, skipping evaluation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f297fa43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save training metadata\n",
    "\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "checkpoint_info = {\n",
    "    \"timestamp\": datetime.now().isoformat(),\n",
    "    \"stage\": \"1_msmarco_baseline\",\n",
    "    \"model_path\": f\"{MODEL_DIR}/dpr_bm25_msmarco_final\",\n",
    "    \"base_model\": BASE_MODEL,\n",
    "    \"negative_sampling\": \"BM25\",\n",
    "    \"training_samples\": len(msmarco_train_df),\n",
    "    \"epochs\": model_args.num_train_epochs,\n",
    "    \"batch_size_effective\": model_args.train_batch_size * model_args.gradient_accumulation_steps,\n",
    "    \"max_seq_length\": model_args.max_seq_length,\n",
    "    \"fp16\": model_args.fp16,\n",
    "}\n",
    "\n",
    "# Save metadata\n",
    "with open(f\"{MODEL_DIR}/checkpoint_stage1.json\", \"w\") as f:\n",
    "    json.dump(checkpoint_info, f, indent=2)\n",
    "\n",
    "print(\"âœ“ Checkpoint info saved\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"âœ… PHASE 2 COMPLETE: Baseline DPR Training\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nðŸ“ Model saved at: {MODEL_DIR}/dpr_bm25_msmarco_final\")\n",
    "print(f\"ðŸ“Š Training samples: {len(msmarco_train_df):,}\")\n",
    "print(f\"ðŸ”§ Next: Phase 3 - LLM Integration\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mltorch311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
