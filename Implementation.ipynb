{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "823a6b6b",
   "metadata": {},
   "source": [
    "## Step 1: Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f520316d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Nov  4 11:06:22 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 576.83                 Driver Version: 576.83         CUDA Version: 12.9     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3060      WDDM  |   00000000:01:00.0 Off |                  N/A |\n",
      "| 36%   35C    P8             15W /  170W |    1610MiB /  12288MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A           35564      C   ...onda3\\envs\\mltorch\\python.exe      N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aef970bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Configuration loaded for 12GB GPU\n",
      "  Batch size: 8, Max seq: 384\n",
      "  Gradient accumulation: 2\n",
      "  Development Mode: True (1000)\n"
     ]
    }
   ],
   "source": [
    "# === CONFIGURATION (12GB GPU OPTIMIZED) ===\n",
    "\n",
    "# API Keys (set if available, else will use Ollama)\n",
    "GEMINI_API_KEY = None  # Set to your API key or leave None for Ollama\n",
    "\n",
    "# Data paths\n",
    "DATA_DIR = \"data\"\n",
    "MSMARCO_DIR = f\"{DATA_DIR}/msmarco\"\n",
    "TYDI_DIR = f\"{DATA_DIR}/tydi\"\n",
    "MMARCO_DIR = f\"{DATA_DIR}/mmarco\"\n",
    "\n",
    "# Model directories\n",
    "MODEL_DIR = \"./models\"\n",
    "BASE_MODEL = \"bert-base-multilingual-cased\"\n",
    "\n",
    "# Training configuration for 12GB GPU\n",
    "USE_MIXED_PRECISION = True   \n",
    "GRADIENT_ACCUMULATION_STEPS = 2  \n",
    "MAX_SEQ_LENGTH = 384         \n",
    "TRAIN_BATCH_SIZE = 8    \n",
    "\n",
    "# Sample sizes for development \n",
    "DEV_MODE = True             \n",
    "DEV_SAMPLE_SIZE = 1000 if DEV_MODE else None \n",
    "\n",
    "# Languages for multilingual training\n",
    "TYDI_LANGUAGES = [\n",
    "        \"swahili\",\n",
    "        \"bengali\",\n",
    "        \"telugu\",\n",
    "        \"thai\",\n",
    "        \"arabic\",\n",
    "        \"finnish\",\n",
    "        \"indonesian\",\n",
    "        \"japanese\",\n",
    "        \"korean\"\n",
    "]\n",
    "# , \"indonesian\", \"japanese\",\n",
    "#     \"korean\", \"russian\", \"swahili\", \"telugu\", \"thai\"\n",
    "\n",
    "MMARCO_LANGUAGES = [\n",
    "    \"arabic\", \"chinese\", \"dutch\", \"french\", \"german\",\n",
    "    \"hindi\", \"indonesian\", \"italian\", \"japanese\", \"portuguese\",\n",
    "    \"russian\", \"spanish\", \"vietnamese\"\n",
    "]\n",
    "\n",
    "print(\"âœ“ Configuration loaded for 12GB GPU\")\n",
    "print(f\"  Batch size: {TRAIN_BATCH_SIZE}, Max seq: {MAX_SEQ_LENGTH}\")\n",
    "print(f\"  Gradient accumulation: {GRADIENT_ACCUMULATION_STEPS}\")\n",
    "print(f\"  Development Mode: {DEV_MODE} ({DEV_SAMPLE_SIZE if DEV_MODE else 'FULL'})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d8a29607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ transformers already installed\n",
      "âœ“ datasets already installed\n",
      "âœ“ pandas already installed\n",
      "âœ“ tqdm already installed\n",
      "âœ“ simpletransformers already installed\n",
      "Installing faiss-cpu...\n",
      "âœ“ rank-bm25 already installed\n",
      "âœ“ sentence-transformers already installed\n",
      "âœ“ torch already installed\n",
      "\n",
      "âœ“ All dependencies installed\n"
     ]
    }
   ],
   "source": [
    "# Run once to install required packages\n",
    "\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install_packages():\n",
    "    packages = [\n",
    "        \"transformers\",\n",
    "        \"datasets\",\n",
    "        \"pandas\",\n",
    "        \"tqdm\",\n",
    "        \"simpletransformers\",\n",
    "        \"faiss-cpu\",  # Use faiss-cpu for 4GB GPU, or faiss-gpu if sufficient\n",
    "        \"rank-bm25\",\n",
    "        \"sentence-transformers\",\n",
    "        \"torch\",\n",
    "    ]\n",
    "    \n",
    "    for package in packages:\n",
    "        try:\n",
    "            __import__(package.replace('-', '_'))\n",
    "            print(f\"âœ“ {package} already installed\")\n",
    "        except ImportError:\n",
    "            print(f\"Installing {package}...\")\n",
    "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "\n",
    "install_packages()\n",
    "\n",
    "# For Ollama (if not using Gemini API)\n",
    "# Install separately: https://ollama.ai/download\n",
    "# Then: ollama pull llama3.2:3b\n",
    "print(\"\\nâœ“ All dependencies installed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "497eb7f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Libraries imported\n",
      "  PyTorch version: 2.5.1\n",
      "  CUDA available: True\n",
      "  GPU Memory: 12.88 GB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Tuple\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import torch\n",
    "\n",
    "from datasets import load_dataset\n",
    "from transformers import set_seed\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "set_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# Create directories\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "os.makedirs(\"./results\", exist_ok=True)\n",
    "os.makedirs(\"./logs\", exist_ok=True)\n",
    "\n",
    "print(\"âœ“ Libraries imported\")\n",
    "print(f\"  PyTorch version: {torch.__version__}\")\n",
    "print(f\"  CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"  GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "155778a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Loading MS MARCO Training Data ===\n",
      "âœ“ MS MARCO Train: 1,000 samples\n",
      "Columns: ['query_text', 'gold_passage', 'hard_negative']\n",
      "\n",
      "Sample:\n",
      "                                          query_text  \\\n",
      "0                         what are the liberal arts?   \n",
      "1  what is the mechanism of action of fibrinolyti...   \n",
      "\n",
      "                                        gold_passage  \\\n",
      "0  liberal arts. 1. the academic course of instru...   \n",
      "1  BailliÃƒÂ¨re's Clinical Haematology. 6 Mechanism...   \n",
      "\n",
      "                                       hard_negative  \n",
      "0  Liberal Education: An approach to college lear...  \n",
      "1  Be able to diagram the coagulation and fibrino...  \n",
      "\n",
      "Statistics:\n",
      "  Avg query length: 33.3 chars\n",
      "  Avg passage length: 345.9 chars\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "print(\"=== Loading MS MARCO Training Data ===\")\n",
    "\n",
    "# Load training data\n",
    "msmarco_train = pd.read_csv(\n",
    "    f\"{MSMARCO_DIR}/msmarco-train.tsv\",\n",
    "    sep=\"\\t\",\n",
    "    nrows=DEV_SAMPLE_SIZE if DEV_MODE else None\n",
    ")\n",
    "\n",
    "# CRITICAL: Rename columns to match BEIR format requirements\n",
    "msmarco_train = msmarco_train.rename(columns={\n",
    "    \"query\": \"query_text\",\n",
    "    \"positive_passage\": \"gold_passage\",\n",
    "    \"negative_passage\": \"hard_negative\"\n",
    "})\n",
    "\n",
    "print(f\"âœ“ MS MARCO Train: {len(msmarco_train):,} samples\")\n",
    "print(\"Columns:\", msmarco_train.columns.tolist())\n",
    "print(\"\\nSample:\")\n",
    "print(msmarco_train.head(2))\n",
    "\n",
    "# Statistics\n",
    "print(\"\\nStatistics:\")\n",
    "print(f\"  Avg query length: {msmarco_train['query_text'].str.len().mean():.1f} chars\")\n",
    "print(f\"  Avg passage length: {msmarco_train['gold_passage'].str.len().mean():.1f} chars\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fbbc268f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Loading Mr. TyDi (BEIR Format) ===\n",
      "  âœ“ swahili: 200\n",
      "  âœ“ bengali: 111\n",
      "  âœ“ telugu: 200\n",
      "  âœ“ thai: 200\n",
      "  âœ“ arabic: 200\n",
      "  âœ“ finnish: 200\n",
      "  âœ“ indonesian: 200\n",
      "  âœ“ japanese: 200\n",
      "  âœ“ korean: 200\n",
      "\n",
      "âœ“ Total Mr. TyDi: 1,711 samples\n",
      "Columns: ['query_text', 'gold_passage']\n",
      "\n",
      "Sample:\n",
      "                                          query_text  \\\n",
      "0                 Remmy Ongala alifariki mwaka gani?   \n",
      "1  Je, Doris May Lessing alishinda tuzo la nini k...   \n",
      "\n",
      "                                        gold_passage  \n",
      "0  Remmy Ongala (10 Februari 1947 - 12 Desemba 20...  \n",
      "1  Doris May Lessing (amezaliwa 22 Oktoba 1919) a...  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "print(\"\\n=== Loading Mr. TyDi (BEIR Format) ===\")\n",
    "\n",
    "tydi_data = []\n",
    "\n",
    "for lang in TYDI_LANGUAGES:\n",
    "    base_dir = f\"{TYDI_DIR}/{lang}\"\n",
    "    queries_file = os.path.join(base_dir, \"queries.jsonl\")\n",
    "    corpus_file = os.path.join(base_dir, \"corpus.jsonl\")\n",
    "    qrels_file = os.path.join(base_dir, \"qrels/test.tsv\")\n",
    "\n",
    "    # Check required files\n",
    "    if (os.path.exists(queries_file) and \n",
    "        os.path.exists(corpus_file) and \n",
    "        os.path.exists(qrels_file)):\n",
    "        \n",
    "        queries_df = pd.read_json(queries_file, lines=True)\n",
    "        corpus_df = pd.read_json(corpus_file, lines=True)\n",
    "        qrels_df = pd.read_csv(qrels_file, sep='\\t')\n",
    "\n",
    "        # Merge queries and corpus with qrels\n",
    "        merged = qrels_df.merge(\n",
    "            queries_df.rename(columns={\"_id\": \"query-id\"}),\n",
    "            on=\"query-id\"\n",
    "        ).merge(\n",
    "            corpus_df.rename(columns={\"_id\": \"corpus-id\", \"text\": \"gold_passage\"}),  # Changed here\n",
    "            on=\"corpus-id\"\n",
    "        )\n",
    "\n",
    "        # CRITICAL: Rename to BEIR format columns\n",
    "        df = merged[['text', 'gold_passage']].rename(columns={'text': 'query_text'})  # Changed here\n",
    "        df = df.dropna()\n",
    "\n",
    "        # Sample if dev mode\n",
    "        if DEV_SAMPLE_SIZE:\n",
    "            df = df.sample(min(len(df), 200), random_state=42)\n",
    "        \n",
    "        tydi_data.append(df)\n",
    "        print(f\"  âœ“ {lang}: {len(df):,}\")\n",
    "    else:\n",
    "        print(f\"  âš  Missing files for {lang}\")\n",
    "\n",
    "# Combine all languages\n",
    "tydi_combined = pd.concat(tydi_data, ignore_index=True) if tydi_data else pd.DataFrame(columns=[\"query_text\", \"gold_passage\"])\n",
    "\n",
    "print(f\"\\nâœ“ Total Mr. TyDi: {len(tydi_combined):,} samples\")\n",
    "print(\"Columns:\", tydi_combined.columns.tolist())\n",
    "print(\"\\nSample:\")\n",
    "print(tydi_combined.head(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e6626292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Cleaning Datasets ===\n",
      "MS MARCO Train:\n",
      "  Cleaned: 1,000 â†’ 1,000 (100.0% retained)\n",
      "\n",
      "Mr. TyDi:\n",
      "  Cleaned: 1,711 â†’ 1,688 (98.7% retained)\n",
      "\n",
      "âœ“ Cleaning complete\n",
      "\n",
      "Final counts:\n",
      "  MS MARCO: 1,000\n",
      "  Mr. TyDi: 1,688\n"
     ]
    }
   ],
   "source": [
    "def clean_dataset(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Remove nulls, duplicates, and invalid samples\"\"\"\n",
    "    initial_size = len(df)\n",
    "    \n",
    "    # Remove nulls\n",
    "    df = df.dropna()\n",
    "    \n",
    "    # Remove duplicates\n",
    "    df = df.drop_duplicates()\n",
    "    \n",
    "    # Remove empty strings\n",
    "    df = df[\n",
    "        (df['query_text'].str.strip() != '') & \n",
    "        (df['gold_passage'].str.strip() != '')\n",
    "    ]\n",
    "    \n",
    "    # Length constraints (for 12GB GPU)\n",
    "    df = df[\n",
    "        (df['query_text'].str.len() >= 10) &\n",
    "        (df['query_text'].str.len() <= 512) &\n",
    "        (df['gold_passage'].str.len() >= 20) &\n",
    "        (df['gold_passage'].str.len() <= 2048)\n",
    "    ]\n",
    "    \n",
    "    # Remove if negative == positive\n",
    "    if 'hard_negative' in df.columns:\n",
    "        df = df[df['hard_negative'] != df['gold_passage']]\n",
    "    \n",
    "    print(f\"  Cleaned: {initial_size:,} â†’ {len(df):,} ({len(df)/initial_size*100:.1f}% retained)\")\n",
    "    \n",
    "    return df.reset_index(drop=True)\n",
    "\n",
    "print(\"=== Cleaning Datasets ===\")\n",
    "\n",
    "print(\"MS MARCO Train:\")\n",
    "msmarco_train = clean_dataset(msmarco_train)\n",
    "\n",
    "print(\"\\nMr. TyDi:\")\n",
    "tydi_combined = clean_dataset(tydi_combined)\n",
    "\n",
    "print(\"\\nâœ“ Cleaning complete\")\n",
    "print(f\"\\nFinal counts:\")\n",
    "print(f\"  MS MARCO: {len(msmarco_train):,}\")\n",
    "print(f\"  Mr. TyDi: {len(tydi_combined):,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "188b26d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Preparing Training Examples ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preparing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:00<00:00, 30303.26it/s]\n",
      "Preparing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1688/1688 [00:00<00:00, 36695.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ MS MARCO: 1,000 examples\n",
      "âœ“ TyDi: 1,688 examples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ“ Data saved to ./data/data_processed.pkl\n"
     ]
    }
   ],
   "source": [
    "# Prepare data in format needed for DPR training\n",
    "\n",
    "@dataclass\n",
    "class TrainingExample:\n",
    "    query: str\n",
    "    positive: str\n",
    "    negatives: List[str]  # Will be populated by sampling methods\n",
    "\n",
    "def prepare_training_data(df: pd.DataFrame, has_negatives: bool = True) -> List[TrainingExample]:\n",
    "    \"\"\"Convert DataFrame to training examples\"\"\"\n",
    "    examples = []\n",
    "    \n",
    "    for _, row in tqdm(df.iterrows(), total=len(df), desc=\"Preparing\"):\n",
    "        example = TrainingExample(\n",
    "            query=row['query_text'],\n",
    "            positive=row['gold_passage'],\n",
    "            negatives=[row['negative_passage']] if has_negatives and 'negative_passage' in row else []\n",
    "        )\n",
    "        examples.append(example)\n",
    "    \n",
    "    return examples\n",
    "\n",
    "print(\"=== Preparing Training Examples ===\")\n",
    "\n",
    "msmarco_train_examples = prepare_training_data(msmarco_train, has_negatives=True)\n",
    "tydi_train_examples = prepare_training_data(tydi_combined, has_negatives=False)\n",
    "\n",
    "print(f\"âœ“ MS MARCO: {len(msmarco_train_examples):,} examples\")\n",
    "print(f\"âœ“ TyDi: {len(tydi_train_examples):,} examples\")\n",
    "\n",
    "# Save to disk for later use\n",
    "import pickle\n",
    "\n",
    "with open('./data/data_processed.pkl', 'wb') as f:\n",
    "    pickle.dump({\n",
    "        'msmarco_train': msmarco_train_examples,\n",
    "        'tydi_train': tydi_train_examples\n",
    "    }, f)\n",
    "\n",
    "print(\"\\nâœ“ Data saved to ./data/data_processed.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0189345c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DATASET SUMMARY\n",
      "============================================================\n",
      "\n",
      "ðŸ“Š MS MARCO (English):\n",
      "  Training samples: 1,000\n",
      "  Has pre-mined negatives: Yes\n",
      "\n",
      "ðŸ“Š Mr. TyDi (Multilingual):\n",
      "  Total samples: 1,688\n",
      "  Languages: 9\n",
      "  Has pre-mined negatives: No (will generate)\n",
      "\n",
      "ðŸ“Š Configuration:\n",
      "  Max sequence length: 384\n",
      "  Mixed precision: True\n",
      "  Gradient accumulation: 2\n",
      "\n",
      "âœ… Phase 1 Complete: Data Preparation\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Final statistics\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"DATASET SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\nðŸ“Š MS MARCO (English):\")\n",
    "print(f\"  Training samples: {len(msmarco_train_examples):,}\")\n",
    "print(f\"  Has pre-mined negatives: Yes\")\n",
    "\n",
    "print(\"\\nðŸ“Š Mr. TyDi (Multilingual):\")\n",
    "print(f\"  Total samples: {len(tydi_train_examples):,}\")\n",
    "print(f\"  Languages: {len(TYDI_LANGUAGES)}\")\n",
    "print(f\"  Has pre-mined negatives: No (will generate)\")\n",
    "\n",
    "print(\"\\nðŸ“Š Configuration:\")\n",
    "print(f\"  Max sequence length: {MAX_SEQ_LENGTH}\")\n",
    "print(f\"  Mixed precision: {USE_MIXED_PRECISION}\")\n",
    "print(f\"  Gradient accumulation: {GRADIENT_ACCUMULATION_STEPS}\")\n",
    "\n",
    "print(\"\\nâœ… Phase 1 Complete: Data Preparation\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa57e21",
   "metadata": {},
   "source": [
    "## Phase 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e14f35f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ rank_bm25 already installed\n",
      "âœ“ Loaded 1,000 MS MARCO examples\n",
      "âœ“ Loaded 1,688 TyDi examples\n"
     ]
    }
   ],
   "source": [
    "# Install BM25 for negative sampling\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "try:\n",
    "    from rank_bm25 import BM25Okapi\n",
    "    print(\"âœ“ rank_bm25 already installed\")\n",
    "except ImportError:\n",
    "    print(\"Installing rank_bm25...\")\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"rank-bm25\"])\n",
    "    from rank_bm25 import BM25Okapi\n",
    "    print(\"âœ“ rank_bm25 installed\")\n",
    "\n",
    "# Load processed data\n",
    "import pickle\n",
    "\n",
    "with open('./data/data_processed.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "    msmarco_train_examples = data['msmarco_train']\n",
    "    tydi_train_examples = data['tydi_train']\n",
    "\n",
    "print(f\"âœ“ Loaded {len(msmarco_train_examples):,} MS MARCO examples\")\n",
    "print(f\"âœ“ Loaded {len(tydi_train_examples):,} TyDi examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c62932db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Building BM25 Corpus ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting passages: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:00<00:00, 992264.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Corpus size: 1,000 unique passages\n",
      "Building BM25 index...\n",
      "âœ“ BM25 index built with 1,000 documents\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# BM25-based hard negative mining\n",
    "\n",
    "from rank_bm25 import BM25Okapi\n",
    "from typing import List\n",
    "import numpy as np\n",
    "\n",
    "class BM25NegativeSampler:\n",
    "    \"\"\"Mine hard negatives using BM25\"\"\"\n",
    "    \n",
    "    def __init__(self, corpus: List[str]):\n",
    "        print(\"Building BM25 index...\")\n",
    "        # Tokenize corpus\n",
    "        tokenized_corpus = [doc.lower().split() for doc in corpus]\n",
    "        self.bm25 = BM25Okapi(tokenized_corpus)\n",
    "        self.corpus = corpus\n",
    "        print(f\"âœ“ BM25 index built with {len(corpus):,} documents\")\n",
    "    \n",
    "    def get_hard_negatives(self, query: str, positive_passage: str, top_k: int = 100, n_negatives: int = 1) -> List[str]:\n",
    "        \"\"\"Get hard negatives for a query\"\"\"\n",
    "        # Tokenize query\n",
    "        tokenized_query = query.lower().split()\n",
    "        \n",
    "        # Get top-k candidates from BM25\n",
    "        scores = self.bm25.get_scores(tokenized_query)\n",
    "        top_indices = np.argsort(scores)[-top_k:][::-1]\n",
    "        \n",
    "        # Filter out positive passage and select negatives\n",
    "        negatives = []\n",
    "        for idx in top_indices:\n",
    "            candidate = self.corpus[idx]\n",
    "            # Skip if it's the positive passage\n",
    "            if candidate != positive_passage and candidate not in negatives:\n",
    "                negatives.append(candidate)\n",
    "            if len(negatives) >= n_negatives:\n",
    "                break\n",
    "        \n",
    "        # If not enough negatives, add random ones\n",
    "        while len(negatives) < n_negatives:\n",
    "            random_idx = np.random.randint(0, len(self.corpus))\n",
    "            candidate = self.corpus[random_idx]\n",
    "            if candidate != positive_passage and candidate not in negatives:\n",
    "                negatives.append(candidate)\n",
    "        \n",
    "        return negatives[:n_negatives]\n",
    "\n",
    "# Build corpus from MS MARCO\n",
    "print(\"\\n=== Building BM25 Corpus ===\")\n",
    "all_passages = set()\n",
    "\n",
    "for example in tqdm(msmarco_train_examples, desc=\"Collecting passages\"):\n",
    "    all_passages.add(example.positive)\n",
    "    all_passages.update(example.negatives)\n",
    "\n",
    "corpus_list = list(all_passages)\n",
    "print(f\"âœ“ Corpus size: {len(corpus_list):,} unique passages\")\n",
    "\n",
    "# Initialize BM25 sampler\n",
    "bm25_sampler = BM25NegativeSampler(corpus_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a3084337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Mining Hard Negatives with BM25 ===\n",
      "\n",
      "Mining for TyDi training examples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TyDi: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1688/1688 [00:00<00:00, 1708.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mining for MS MARCO training examples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MS MARCO: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:00<00:00, 1171.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hard negative mining complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Mining Hard Negatives with BM25 ===\")\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Mine for TyDi TRAINING data (all samples)\n",
    "print(f\"\\nMining for TyDi training examples...\")\n",
    "for example in tqdm(tydi_train_examples, desc=\"TyDi\"):\n",
    "    if len(example.negatives) == 0:\n",
    "        hard_negs = bm25_sampler.get_hard_negatives(\n",
    "            example.query, \n",
    "            example.positive, \n",
    "            top_k=100, \n",
    "            n_negatives=1\n",
    "        )\n",
    "        example.negatives = hard_negs\n",
    "\n",
    "# Mine for MS MARCO TRAINING data (all samples)\n",
    "print(f\"\\nMining for MS MARCO training examples...\")\n",
    "for example in tqdm(msmarco_train_examples, desc=\"MS MARCO\"):\n",
    "    bm25_negs = bm25_sampler.get_hard_negatives(\n",
    "        example.query,\n",
    "        example.positive,\n",
    "        top_k=100,\n",
    "        n_negatives=1\n",
    "    )\n",
    "    for neg in bm25_negs:\n",
    "        if neg not in example.negatives:\n",
    "            example.negatives.append(neg)\n",
    "\n",
    "print(\"\\nHard negative mining complete\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bb38b81c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing Training DataFrames\n",
      "âœ“ MS MARCO training: 1,000 triplets\n",
      "Columns: ['query_text', 'gold_passage', 'hard_negative']\n",
      "\n",
      "Sample:\n",
      "                                          query_text  \\\n",
      "0                         what are the liberal arts?   \n",
      "1  what is the mechanism of action of fibrinolyti...   \n",
      "\n",
      "                                        gold_passage  \\\n",
      "0  liberal arts. 1. the academic course of instru...   \n",
      "1  BailliÃƒÂ¨re's Clinical Haematology. 6 Mechanism...   \n",
      "\n",
      "                                       hard_negative  \n",
      "0  What Are Hormones, And What Do They Do? Hormon...  \n",
      "1  Here is the video of claw mechanism animation....  \n"
     ]
    }
   ],
   "source": [
    "def convert_to_training_format(examples: List, limit: int = None) -> pd.DataFrame:\n",
    "    \"\"\"Convert training examples to DataFrame for SimpleDPR\"\"\"\n",
    "    data = []\n",
    "    \n",
    "    for example in (examples[:limit] if limit else examples):\n",
    "        for negative in example.negatives:\n",
    "            data.append({\n",
    "                \"query_text\": example.query,\n",
    "                \"gold_passage\": example.positive,\n",
    "                \"hard_negative\": negative\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "print(\"Preparing Training DataFrames\")\n",
    "\n",
    "train_size = 5000 if DEV_MODE else None\n",
    "msmarco_train_df = convert_to_training_format(msmarco_train_examples, limit=train_size)\n",
    "\n",
    "print(f\"âœ“ MS MARCO training: {len(msmarco_train_df):,} triplets\")\n",
    "print(\"Columns:\", msmarco_train_df.columns.tolist())\n",
    "print(\"\\nSample:\")\n",
    "print(msmarco_train_df.head(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7886b7fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Preparing TyDi Training Data ===\n",
      "âœ“ Loaded 1,688 TyDi examples\n",
      "\n",
      "Mining hard negatives for TyDi with BM25...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building corpus: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1688/1688 [00:00<00:00, 1688122.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ TyDi corpus: 1,606 passages\n",
      "Building BM25 index...\n",
      "âœ“ BM25 index built with 1,606 documents\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mining negatives: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1688/1688 [00:01<00:00, 907.25it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Hard negatives mined for TyDi\n",
      "\n",
      "============================================================\n",
      "âœ“ TyDi training dataframe: 1,688 samples\n",
      "============================================================\n",
      "Columns: ['query_text', 'gold_passage', 'hard_negative']\n",
      "Data quality: 0 null values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Prepare Mr. TyDi multilingual data for fine-tuning\n",
    "\n",
    "print(\"\\n=== Preparing TyDi Training Data ===\")\n",
    "\n",
    "# Reload TyDi data (use DATA_DIR variable)\n",
    "tydi_data_path = f\"{DATA_DIR}/data_processed.pkl\"\n",
    "with open(tydi_data_path, 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "    tydi_train_examples = data['tydi_train']\n",
    "\n",
    "print(f\"âœ“ Loaded {len(tydi_train_examples):,} TyDi examples\")\n",
    "\n",
    "# TyDi examples don't have negatives yet - mine them with BM25\n",
    "print(\"\\nMining hard negatives for TyDi with BM25...\")\n",
    "\n",
    "# Build corpus from TyDi data\n",
    "tydi_corpus = set()\n",
    "for example in tqdm(tydi_train_examples, desc=\"Building corpus\"):\n",
    "    tydi_corpus.add(example.positive)\n",
    "\n",
    "tydi_corpus_list = list(tydi_corpus)\n",
    "print(f\"âœ“ TyDi corpus: {len(tydi_corpus_list):,} passages\")\n",
    "\n",
    "# Build BM25 index for TyDi (REUSE Phase 2 class)\n",
    "tydi_bm25_sampler = BM25NegativeSampler(tydi_corpus_list)\n",
    "\n",
    "# Mine negatives for each example\n",
    "for example in tqdm(tydi_train_examples, desc=\"Mining negatives\"):\n",
    "    if len(example.negatives) == 0:\n",
    "        hard_negs = tydi_bm25_sampler.get_hard_negatives(\n",
    "            example.query,\n",
    "            example.positive,\n",
    "            top_k=100,\n",
    "            n_negatives=1\n",
    "        )\n",
    "        example.negatives = hard_negs\n",
    "\n",
    "print(\"âœ“ Hard negatives mined for TyDi\")\n",
    "\n",
    "# Convert to training format\n",
    "def convert_tydi_to_df(examples, limit=None):\n",
    "    data = []\n",
    "    examples_to_process = examples[:limit] if limit else examples  # FIX 1: Proper assignment\n",
    "    for example in examples_to_process:\n",
    "        for negative in example.negatives:\n",
    "            data.append({\n",
    "                'query_text': example.query,\n",
    "                'gold_passage': example.positive,\n",
    "                'hard_negative': negative\n",
    "            })\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Prepare TyDi training dataframe\n",
    "TYDI_TRAIN_SIZE = 2000 if DEV_MODE else None\n",
    "tydi_train_df = convert_tydi_to_df(tydi_train_examples, limit=TYDI_TRAIN_SIZE)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"âœ“ TyDi training dataframe: {len(tydi_train_df):,} samples\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Columns: {tydi_train_df.columns.tolist()}\")\n",
    "print(f\"Data quality: {tydi_train_df.isnull().sum().sum()} null values\")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "96fee901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "SAVING TRAINING DATASETS\n",
      "============================================================\n",
      "\n",
      "1. Saving MS MARCO training data...\n",
      "  âœ“ 1,000 samples saved\n",
      "\n",
      "2. Saving TyDi training data...\n",
      "  âœ“ 1,688 samples saved\n",
      "\n",
      "============================================================\n",
      "SUMMARY\n",
      "============================================================\n",
      "\n",
      "MS MARCO: 1,000 samples\n",
      "TyDi: 1,688 samples\n",
      "Total: 2,688 samples\n",
      "\n",
      "Location: data\\training_data\n",
      "\n",
      "âœ… DATASETS SAVED\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SAVING TRAINING DATASETS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Setup directories\n",
    "TRAINING_DATA_DIR = os.path.join(DATA_DIR, \"training_data\")\n",
    "os.makedirs(TRAINING_DATA_DIR, exist_ok=True)\n",
    "\n",
    "# ============================================================\n",
    "# Save MS MARCO\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n1. Saving MS MARCO training data...\")\n",
    "\n",
    "msmarco_dir = os.path.join(TRAINING_DATA_DIR, \"msmarco\")\n",
    "os.makedirs(msmarco_dir, exist_ok=True)\n",
    "\n",
    "msmarco_train_df.to_csv(os.path.join(msmarco_dir, \"train.csv\"), index=False)\n",
    "with open(os.path.join(msmarco_dir, \"train.pkl\"), 'wb') as f:\n",
    "    pickle.dump(msmarco_train_df, f)\n",
    "\n",
    "print(f\"  âœ“ {len(msmarco_train_df):,} samples saved\")\n",
    "\n",
    "# ============================================================\n",
    "# Save TyDi\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n2. Saving TyDi training data...\")\n",
    "\n",
    "tydi_dir = os.path.join(TRAINING_DATA_DIR, \"tydi\")\n",
    "os.makedirs(tydi_dir, exist_ok=True)\n",
    "\n",
    "tydi_train_df.to_csv(os.path.join(tydi_dir, \"train.csv\"), index=False)\n",
    "with open(os.path.join(tydi_dir, \"train.pkl\"), 'wb') as f:\n",
    "    pickle.dump(tydi_train_df, f)\n",
    "\n",
    "print(f\"  âœ“ {len(tydi_train_df):,} samples saved\")\n",
    "\n",
    "# ============================================================\n",
    "# Summary\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nMS MARCO: {len(msmarco_train_df):,} samples\")\n",
    "print(f\"TyDi: {len(tydi_train_df):,} samples\")\n",
    "print(f\"Total: {len(msmarco_train_df) + len(tydi_train_df):,} samples\")\n",
    "print(f\"\\nLocation: {TRAINING_DATA_DIR}\")\n",
    "print(\"\\nâœ… DATASETS SAVED\")\n",
    "print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9449ab70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import pickle\n",
    "# import pandas as pd\n",
    "\n",
    "# print(\"\\n\" + \"=\"*60)\n",
    "# print(\"LOADING TRAINING DATASETS\")\n",
    "# print(\"=\"*60)\n",
    "\n",
    "# TRAINING_DATA_DIR = os.path.join(DATA_DIR, \"training_data\")\n",
    "\n",
    "# # ============================================================\n",
    "# # Load MS MARCO\n",
    "# # ============================================================\n",
    "\n",
    "# print(\"\\n1. Loading MS MARCO...\")\n",
    "\n",
    "# msmarco_pkl = os.path.join(TRAINING_DATA_DIR, \"msmarco\", \"train.pkl\")\n",
    "\n",
    "# with open(msmarco_pkl, 'rb') as f:\n",
    "#     msmarco_train_df = pickle.load(f)\n",
    "\n",
    "# print(f\"  âœ“ Loaded {len(msmarco_train_df):,} samples\")\n",
    "# print(f\"  Columns: {msmarco_train_df.columns.tolist()}\")\n",
    "\n",
    "# # ============================================================\n",
    "# # Load TyDi\n",
    "# # ============================================================\n",
    "\n",
    "# print(\"\\n2. Loading TyDi...\")\n",
    "\n",
    "# tydi_pkl = os.path.join(TRAINING_DATA_DIR, \"tydi\", \"train.pkl\")\n",
    "\n",
    "# with open(tydi_pkl, 'rb') as f:\n",
    "#     tydi_train_df = pickle.load(f)\n",
    "\n",
    "# print(f\"  âœ“ Loaded {len(tydi_train_df):,} samples\")\n",
    "# print(f\"  Columns: {tydi_train_df.columns.tolist()}\")\n",
    "\n",
    "# # ============================================================\n",
    "# # Summary\n",
    "# # ============================================================\n",
    "\n",
    "# print(\"\\n\" + \"=\"*60)\n",
    "# print(\"SUMMARY\")\n",
    "# print(\"=\"*60)\n",
    "# print(f\"\\nMS MARCO: {len(msmarco_train_df):,} samples\")\n",
    "# print(f\"TyDi: {len(tydi_train_df):,} samples\")\n",
    "# print(f\"Total: {len(msmarco_train_df) + len(tydi_train_df):,} samples\")\n",
    "# print(\"\\nâœ… DATASETS LOADED\")\n",
    "# print(\"=\"*60)\n",
    "\n",
    "# # Verify data quality\n",
    "# print(f\"\\nData Quality:\")\n",
    "# print(f\"  MS MARCO nulls: {msmarco_train_df.isnull().sum().sum()}\")\n",
    "# print(f\"  TyDi nulls: {tydi_train_df.isnull().sum().sum()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "18d824b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Configuring DPR Model ===\n",
      "âœ“ Model configuration complete\n",
      "  Data format: beir\n",
      "  Hard negatives: True\n",
      "  Evaluation during training: False\n",
      "  Epochs: 5\n",
      "  Batch size: 8\n",
      "  Learning rate: 1e-06\n"
     ]
    }
   ],
   "source": [
    "from simpletransformers.retrieval import RetrievalModel, RetrievalArgs\n",
    "import logging\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "transformers_logger = logging.getLogger(\"transformers\")\n",
    "transformers_logger.setLevel(logging.WARNING)\n",
    "\n",
    "print(\"=== Configuring DPR Model ===\")\n",
    "\n",
    "model_args = RetrievalArgs()\n",
    "\n",
    "# CRITICAL: Data format must be 'beir'\n",
    "model_args.data_format = \"beir\"\n",
    "\n",
    "# Data processing\n",
    "model_args.reprocess_input_data = True\n",
    "model_args.overwrite_output_dir = True\n",
    "model_args.use_cached_eval_features = False\n",
    "model_args.use_hf_datasets = True\n",
    "\n",
    "# Model architecture\n",
    "model_args.include_title = False  # MS MARCO doesn't use titles\n",
    "model_args.max_seq_length = 256   # Research paper setting\n",
    "\n",
    "# Training hyperparameters (from research paper)\n",
    "model_args.num_train_epochs = 5   # Use 40 for full training\n",
    "model_args.train_batch_size = 8\n",
    "model_args.learning_rate = 1e-6\n",
    "model_args.warmup_steps = 5000\n",
    "model_args.save_steps = 300000\n",
    "\n",
    "# CRITICAL: Hard negatives enabled for Phase 1\n",
    "model_args.hard_negatives = True\n",
    "\n",
    "# CRITICAL: Evaluation disabled during Phase 1 pretraining\n",
    "model_args.evaluate_during_training = False\n",
    "model_args.save_model_every_epoch = False\n",
    "\n",
    "# Hardware optimization\n",
    "model_args.n_gpu = 1\n",
    "model_args.fp16 = USE_MIXED_PRECISION\n",
    "model_args.dataloader_num_workers = 4\n",
    "\n",
    "# ANCE disabled for Phase 1\n",
    "model_args.ance_training = False\n",
    "\n",
    "# Output directory\n",
    "model_args.output_dir = f\"{MODEL_DIR}/dpr_bm25_baseline_epoch5\"\n",
    "\n",
    "print(\"âœ“ Model configuration complete\")\n",
    "print(f\"  Data format: {model_args.data_format}\")\n",
    "print(f\"  Hard negatives: {model_args.hard_negatives}\")\n",
    "print(f\"  Evaluation during training: {model_args.evaluate_during_training}\")\n",
    "print(f\"  Epochs: {model_args.num_train_epochs}\")\n",
    "print(f\"  Batch size: {model_args.train_batch_size}\")\n",
    "print(f\"  Learning rate: {model_args.learning_rate}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f3cb3892",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\TL1\\anaconda3\\envs\\mltorch\\lib\\site-packages\\torch\\__init__.py:1021: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead\n",
      "  return isinstance(obj, torch.Tensor)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ GPU memory cleared\n"
     ]
    }
   ],
   "source": [
    "# Cell 13.5: Aggressive GPU Memory Cleanup\n",
    "\n",
    "import torch\n",
    "import gc\n",
    "\n",
    "def clear_gpu_memory():\n",
    "    \"\"\"Aggressively clear GPU memory\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        # Clear PyTorch cache\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        # Force garbage collection\n",
    "        gc.collect()\n",
    "        \n",
    "        # Clear all variables from previous runs\n",
    "        import sys\n",
    "        for obj in gc.get_objects():\n",
    "            try:\n",
    "                if torch.is_tensor(obj):\n",
    "                    del obj\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        # Final cleanup\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        \n",
    "        print(\"âœ“ GPU memory cleared\")\n",
    "\n",
    "# Clear before training\n",
    "clear_gpu_memory()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8e396b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "PHASE 1: TRAINING DPR WITH BM25 NEGATIVES\n",
      "============================================================\n",
      "âœ“ GPU memory cleared\n",
      "\n",
      "Training Configuration:\n",
      "  Dataset: MS MARCO\n",
      "  Training samples: 1,000\n",
      "  Epochs: 5\n",
      "  Batch size: 8\n",
      "  Learning rate: 1e-06\n",
      "  Max sequence length: 256\n",
      "  Hard negatives: True\n",
      "  Data format: beir\n",
      "  Evaluation during training: False\n",
      "  Save model every epoch: False\n",
      "\n",
      "Initializing DPR model with: bert-base-multilingual-cased\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\TL1\\anaconda3\\envs\\mltorch\\lib\\site-packages\\huggingface_hub\\file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ DPR model initialized with bert-base-multilingual-cased\n",
      "âœ“ Device: cuda\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:00<00:00, 3945.32 examples/s]\n",
      "INFO:simpletransformers.retrieval.retrieval_model: Training started\n",
      "Epoch:   0%|          | 0/5 [00:00<?, ?it/s]c:\\Users\\TL1\\anaconda3\\envs\\mltorch\\lib\\site-packages\\simpletransformers\\retrieval\\retrieval_model.py:503: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = amp.GradScaler()\n",
      "Epoch 1 of 5:   0%|          | 0/5 [00:00<?, ?it/s]c:\\Users\\TL1\\anaconda3\\envs\\mltorch\\lib\\site-packages\\simpletransformers\\retrieval\\retrieval_model.py:534: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast():\n",
      "c:\\Users\\TL1\\anaconda3\\envs\\mltorch\\lib\\site-packages\\simpletransformers\\retrieval\\retrieval_model.py:1659: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  (max_idxs == torch.tensor(labels)).sum().cpu().detach().numpy().item()\n",
      "c:\\Users\\TL1\\anaconda3\\envs\\mltorch\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:224: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n",
      "Epochs 0/5. Running Loss:   39.2969 Correct count: 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 125/125 [01:16<00:00,  1.63it/s]\n",
      "Epochs 1/5. Running Loss:   26.9551 Correct count: 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 125/125 [01:12<00:00,  1.72it/s]\n",
      "Epochs 2/5. Running Loss:   29.2667 Correct count: 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 125/125 [01:12<00:00,  1.73it/s]\n",
      "Epochs 3/5. Running Loss:    8.7522 Correct count: 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 125/125 [01:13<00:00,  1.71it/s]\n",
      "Epochs 4/5. Running Loss:    4.0064 Correct count: 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 125/125 [01:14<00:00,  1.68it/s]\n",
      "Epoch 5 of 5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [06:09<00:00, 73.84s/it]\n",
      "INFO:simpletransformers.retrieval.retrieval_model:Saving model into ./models/dpr_bm25_baseline_epoch5\n",
      "INFO:simpletransformers.retrieval.retrieval_model: Training of None model complete. Saved to ./models/dpr_bm25_baseline_epoch5.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "âœ… PHASE 1 TRAINING COMPLETE!\n",
      "============================================================\n",
      "Total training time: 6.2 minutes\n",
      "Model saved to: ./models/dpr_bm25_baseline_epoch5\n",
      "âœ“ GPU memory cleared\n",
      "\n",
      "============================================================\n",
      "PHASE 1 COMPLETE - Ready for Phase 2\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import set_start_method\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"PHASE 1: TRAINING DPR WITH BM25 NEGATIVES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Clear GPU memory\n",
    "clear_gpu_memory()\n",
    "\n",
    "# Set multiprocessing method\n",
    "try:\n",
    "    set_start_method(\"spawn\")\n",
    "except RuntimeError:\n",
    "    pass  # Already set\n",
    "\n",
    "print(f\"\\nTraining Configuration:\")\n",
    "print(f\"  Dataset: MS MARCO\")\n",
    "print(f\"  Training samples: {len(msmarco_train_df):,}\")\n",
    "print(f\"  Epochs: {model_args.num_train_epochs}\")\n",
    "print(f\"  Batch size: {model_args.train_batch_size}\")\n",
    "print(f\"  Learning rate: {model_args.learning_rate}\")\n",
    "print(f\"  Max sequence length: {model_args.max_seq_length}\")\n",
    "print(f\"  Hard negatives: {model_args.hard_negatives}\")\n",
    "print(f\"  Data format: {model_args.data_format}\")\n",
    "print(f\"  Evaluation during training: {model_args.evaluate_during_training}\")\n",
    "print(f\"  Save model every epoch: {model_args.save_model_every_epoch}\")\n",
    "print()\n",
    "# Initialize DPR model from scratch using YOUR base model\n",
    "print(f\"Initializing DPR model with: {BASE_MODEL}\")\n",
    "\n",
    "dpr_model = RetrievalModel(\n",
    "    model_type=\"custom\",\n",
    "    model_name=None,  # No pretrained checkpoint\n",
    "    context_encoder_name=BASE_MODEL,  # bert-base-multilingual-cased\n",
    "    query_encoder_name=BASE_MODEL,    # bert-base-multilingual-cased\n",
    "    args=model_args,  # Your modelargs from Cell 15\n",
    "    use_cuda=torch.cuda.is_available()\n",
    ")\n",
    "\n",
    "print(f\"âœ“ DPR model initialized with {BASE_MODEL}\")\n",
    "print(f\"âœ“ Device: {'cuda' if torch.cuda.is_available() else 'cpu'}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "try:\n",
    "    # Train for ALL epochs in one call\n",
    "    # SimpleDPR handles the epoch loop internally\n",
    "    dpr_model.train_model(\n",
    "        msmarco_train_df,\n",
    "        eval_set=\"dev\"  # Placeholder, not used since evaluation is disabled\n",
    "    )\n",
    "    \n",
    "    training_time = time.time() - start_time\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"âœ… PHASE 1 TRAINING COMPLETE!\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Total training time: {training_time/60:.1f} minutes\")\n",
    "    print(f\"Model saved to: {model_args.output_dir}\")\n",
    "    \n",
    "    # Clear GPU memory\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        print(\"âœ“ GPU memory cleared\")\n",
    "    \n",
    "except RuntimeError as e:\n",
    "    if \"out of memory\" in str(e).lower():\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"âŒ OUT OF MEMORY ERROR\")\n",
    "        print(\"=\"*60)\n",
    "        print(\"\\nTry reducing:\")\n",
    "        print(f\"  - train_batch_size (currently: {model_args.train_batch_size})\")\n",
    "        print(f\"  - max_seq_length (currently: {model_args.max_seq_length})\")\n",
    "        print(f\"  - gradient_accumulation_steps (increase to compensate for smaller batch)\")\n",
    "        \n",
    "        # Clean up\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "    raise\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\nâŒ Training failed with error:\")\n",
    "    print(f\"   {type(e).__name__}: {str(e)}\")\n",
    "    raise\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PHASE 1 COMPLETE - Ready for Phase 2\")\n",
    "print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029d0c7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "CREATING BEIR FORMAT DEV/TEST DATASETS\n",
      "============================================================\n",
      "\n",
      "âœ“ Loading cached evaluation dataset...\n",
      "âœ“ Loaded: 7,437 query-passage pairs\n",
      "\n",
      "Evaluation dataset:\n",
      "  Size: 7,437\n",
      "  Columns: ['query_text', 'gold_passage']\n",
      "  Sample query: how many years did william bradford serve as governor of ply...\n",
      "  Sample passage: http://en.wikipedia.org/wiki/William_Bradford_(Plymouth_Colo...\n",
      "\n",
      "============================================================\n",
      "EVALUATION DATASET READY\n",
      "============================================================\n",
      "\n",
      "âœ“ Total evaluation data: 7,437 query-passage pairs\n",
      "âœ“ Test subset (first 50): 300 samples\n",
      "âœ“ Variable 'msmarco_dev' is now available for evaluation\n",
      "âœ“ Models can now be evaluated on actual MS MARCO dev set\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CREATING BEIR FORMAT DEV/TEST DATASETS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "import os\n",
    "\n",
    "# Check if already created\n",
    "eval_data_path = f\"{DATA_DIR}/msmarco_dev_beir.tsv\"\n",
    "\n",
    "if os.path.exists(eval_data_path) and os.path.getsize(eval_data_path) > 100:\n",
    "    print(f\"\\nâœ“ Loading cached evaluation dataset...\")\n",
    "    msmarco_dev = pd.read_csv(eval_data_path, sep=\"\\t\")\n",
    "    print(f\"âœ“ Loaded: {len(msmarco_dev):,} query-passage pairs\")\n",
    "else:\n",
    "    print(\"\\nCreating evaluation dataset from MS MARCO files...\")\n",
    "    \n",
    "    # Load queries with string dtype for IDs\n",
    "    print(\"Loading queries...\")\n",
    "    queries_df = pd.read_csv(\n",
    "        f\"{MSMARCO_DIR}/queries.tsv\", \n",
    "        sep=\"\\t\", \n",
    "        names=['query_id', 'title', 'query_text'],\n",
    "        dtype={'query_id': str},\n",
    "        low_memory=False\n",
    "    )\n",
    "    print(f\"âœ“ Queries: {len(queries_df):,}\")\n",
    "    queries_df['query_id'] = queries_df['query_id'].astype(str)\n",
    "    \n",
    "    # Load corpus with string dtype for IDs\n",
    "    print(\"Loading corpus...\")\n",
    "    corpus_df = pd.read_csv(\n",
    "        f\"{MSMARCO_DIR}/corpus.tsv\", \n",
    "        sep=\"\\t\", \n",
    "        names=['corpus_id', 'title', 'passage'],\n",
    "        dtype={'corpus_id': str},\n",
    "        low_memory=False\n",
    "    )\n",
    "    print(f\"âœ“ Corpus: {len(corpus_df):,}\")\n",
    "    corpus_df['corpus_id'] = corpus_df['corpus_id'].astype(str)\n",
    "    \n",
    "    # Load qrels with string dtype for IDs\n",
    "    print(\"Loading qrels...\")\n",
    "    qrels_df = pd.read_csv(\n",
    "        f\"{MSMARCO_DIR}/devs.tsv\", \n",
    "        sep=\"\\t\", \n",
    "        names=['query_id', 'corpus_id', 'score'],\n",
    "        dtype={'query_id': str, 'corpus_id': str}\n",
    "    )\n",
    "    print(f\"âœ“ Qrels (Dev): {len(qrels_df):,}\")\n",
    "    qrels_df['query_id'] = qrels_df['query_id'].astype(str)\n",
    "    qrels_df['corpus_id'] = qrels_df['corpus_id'].astype(str)\n",
    "    \n",
    "    print(\"\\nMerging into BEIR format...\")\n",
    "    \n",
    "    # Merge qrels + queries\n",
    "    print(\"  Merging qrels with queries...\")\n",
    "    msmarco_dev = qrels_df.merge(\n",
    "        queries_df[['query_id', 'query_text']],\n",
    "        on='query_id',\n",
    "        how='left'\n",
    "    )\n",
    "    print(f\"    After merge: {len(msmarco_dev):,}\")\n",
    "    \n",
    "    # Merge with corpus\n",
    "    print(\"  Merging with corpus...\")\n",
    "    msmarco_dev = msmarco_dev.merge(\n",
    "        corpus_df[['corpus_id', 'passage']].rename(columns={'passage': 'gold_passage'}),\n",
    "        on='corpus_id',\n",
    "        how='left'\n",
    "    )\n",
    "    print(f\"    After merge: {len(msmarco_dev):,}\")\n",
    "    \n",
    "    # Keep only required columns\n",
    "    msmarco_dev = msmarco_dev[['query_text', 'gold_passage']].drop_duplicates().dropna()\n",
    "    \n",
    "    print(f\"\\nâœ“ Created: {len(msmarco_dev):,} query-passage pairs\")\n",
    "    \n",
    "    if len(msmarco_dev) > 0:\n",
    "        msmarco_dev.to_csv(eval_data_path, sep=\"\\t\", index=False)\n",
    "        print(f\"âœ“ Saved to {eval_data_path}\")\n",
    "    else:\n",
    "        print(\"âŒ Merge failed - no data!\")\n",
    "\n",
    "\n",
    "print(f\"\\nEvaluation dataset:\")\n",
    "print(f\"  Size: {len(msmarco_dev):,}\")\n",
    "\n",
    "if len(msmarco_dev) > 0:\n",
    "    print(f\"  Columns: {msmarco_dev.columns.tolist()}\")\n",
    "    print(f\"  Sample query: {msmarco_dev.iloc[0]['query_text'][:60]}...\")\n",
    "    print(f\"  Sample passage: {msmarco_dev.iloc[0]['gold_passage'][:60]}...\")\n",
    "    \n",
    "    # Use for evaluation\n",
    "    test_data = msmarco_dev.head(300).copy()\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"EVALUATION DATASET READY\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"\\nâœ“ Total evaluation data: {len(msmarco_dev):,} query-passage pairs\")\n",
    "    print(f\"âœ“ Test subset (first 300): {len(test_data):,} samples\")\n",
    "    print(f\"âœ“ Variable 'msmarco_dev' is now available for evaluation\")\n",
    "    print(\"âœ“ Models can now be evaluated on actual MS MARCO dev set\")\n",
    "else:\n",
    "    print(\"âŒ No evaluation data - skipping evaluation\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f7bff515",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Evaluation Function\n",
    "# ============================================================\n",
    "\n",
    "def evaluate_dpr_model(model, eval_df, model_name, device, top_k=10, max_samples=None):\n",
    "    \"\"\"\n",
    "    Evaluate DPR model on retrieval task\n",
    "    \n",
    "    Args:\n",
    "        model: RetrievalModel instance\n",
    "        eval_df: DataFrame with columns ['query_text', 'gold_passage']\n",
    "        model_name: Name for logging\n",
    "        device: torch device\n",
    "        top_k: Recall cutoff (default 10)\n",
    "        max_samples: Limit samples for speed (None = use all)\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with metrics\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Evaluating: {model_name}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    # Limit samples if specified\n",
    "    if max_samples:\n",
    "        eval_subset = eval_df.head(max_samples).copy()\n",
    "        print(f\"Using {len(eval_subset)} samples (limited from {len(eval_df)})\")\n",
    "    else:\n",
    "        eval_subset = eval_df.copy()\n",
    "        print(f\"Using all {len(eval_subset)} samples\")\n",
    "    \n",
    "    mrr_scores = []\n",
    "    ndcg_scores = []\n",
    "    recall_1 = []\n",
    "    recall_5 = []\n",
    "    recall_10 = []\n",
    "    \n",
    "    # Get all passages as corpus\n",
    "    all_passages = eval_subset['gold_passage'].tolist()\n",
    "    print(f\"Corpus size: {len(all_passages)} passages\\n\")\n",
    "    \n",
    "    # Evaluate each query\n",
    "    for idx, row in tqdm(eval_subset.iterrows(), total=len(eval_subset), desc=\"Evaluating\"):\n",
    "        query = row['query_text']\n",
    "        gold_passage = row['gold_passage']\n",
    "        \n",
    "        try:\n",
    "            with torch.no_grad():\n",
    "                # Encode query\n",
    "                query_features = model.query_tokenizer(\n",
    "                    query, \n",
    "                    padding='max_length',\n",
    "                    truncation=True, \n",
    "                    max_length=256, \n",
    "                    return_tensors='pt'\n",
    "                )\n",
    "                \n",
    "                query_input_ids = query_features['input_ids'].to(device)\n",
    "                query_attention_mask = query_features['attention_mask'].to(device)\n",
    "                \n",
    "                query_emb = model.query_encoder(\n",
    "                    input_ids=query_input_ids,\n",
    "                    attention_mask=query_attention_mask\n",
    "                )[1].cpu().numpy()\n",
    "                \n",
    "                # Score all passages\n",
    "                passage_scores = []\n",
    "                for passage in all_passages:\n",
    "                    passage_features = model.context_tokenizer(\n",
    "                        passage,\n",
    "                        padding='max_length',\n",
    "                        truncation=True,\n",
    "                        max_length=256,\n",
    "                        return_tensors='pt'\n",
    "                    )\n",
    "                    \n",
    "                    passage_input_ids = passage_features['input_ids'].to(device)\n",
    "                    passage_attention_mask = passage_features['attention_mask'].to(device)\n",
    "                    \n",
    "                    passage_emb = model.context_encoder(\n",
    "                        input_ids=passage_input_ids,\n",
    "                        attention_mask=passage_attention_mask\n",
    "                    )[1].cpu().numpy()\n",
    "                    \n",
    "                    # Cosine similarity\n",
    "                    score = np.dot(query_emb[0], passage_emb[0]) / (\n",
    "                        np.linalg.norm(query_emb[0]) * np.linalg.norm(passage_emb[0]) + 1e-8\n",
    "                    )\n",
    "                    passage_scores.append(score)\n",
    "                \n",
    "                # Rank passages by score\n",
    "                ranked_idx = np.argsort(passage_scores)[::-1]\n",
    "                \n",
    "                # Find rank of gold passage\n",
    "                gold_rank = len(all_passages) + 1\n",
    "                for rank, pidx in enumerate(ranked_idx):\n",
    "                    if all_passages[pidx] == gold_passage:\n",
    "                        gold_rank = rank + 1\n",
    "                        break\n",
    "                \n",
    "                # Compute metrics\n",
    "                if gold_rank <= top_k:\n",
    "                    mrr_scores.append(1.0 / gold_rank)\n",
    "                else:\n",
    "                    mrr_scores.append(0.0)\n",
    "                \n",
    "                if gold_rank <= top_k:\n",
    "                    ndcg_scores.append(1.0 / np.log2(gold_rank + 1))\n",
    "                else:\n",
    "                    ndcg_scores.append(0.0)\n",
    "                \n",
    "                recall_1.append(1.0 if gold_rank <= 1 else 0.0)\n",
    "                recall_5.append(1.0 if gold_rank <= 5 else 0.0)\n",
    "                recall_10.append(1.0 if gold_rank <= 10 else 0.0)\n",
    "        \n",
    "        except Exception as e:\n",
    "            continue\n",
    "    \n",
    "    # Aggregate metrics\n",
    "    metrics = {\n",
    "        \"MRR@10\": np.mean(mrr_scores) if mrr_scores else 0.0,\n",
    "        \"nDCG@10\": np.mean(ndcg_scores) if ndcg_scores else 0.0,\n",
    "        \"Recall@1\": np.mean(recall_1) if recall_1 else 0.0,\n",
    "        \"Recall@5\": np.mean(recall_5) if recall_5 else 0.0,\n",
    "        \"Recall@10\": np.mean(recall_10) if recall_10 else 0.0,\n",
    "    }\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "da62bccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "PHASE 2 END: EVALUATE BM25 BASELINE MODEL\n",
      "============================================================\n",
      "\n",
      "=== Loading BM25 Baseline Model ===\n",
      "\n",
      "Loading model from: ./models/dpr_bm25_baseline_epoch5\n",
      "âœ“ BM25 Baseline Model loaded from ./models/dpr_bm25_baseline_epoch5\n",
      "âœ“ Model moved to device: cuda\n",
      "\n",
      "============================================================\n",
      "EVALUATING BM25 BASELINE ON MS MARCO DEV\n",
      "============================================================\n",
      "\n",
      "Dev set size: 7,437\n",
      "\n",
      "============================================================\n",
      "Evaluating: BM25 Baseline\n",
      "============================================================\n",
      "\n",
      "Using 50 samples (limited from 7437)\n",
      "Corpus size: 50 passages\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:57<00:00,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "PHASE 2 BASELINE RESULTS\n",
      "============================================================\n",
      "\n",
      "Stage: Phase 2 - BM25 Negative Sampling\n",
      "Model: ./models/dpr_bm25_baseline_epoch5\n",
      "Dataset: MS MARCO Dev\n",
      "Samples evaluated: 50 (from 7,437 total)\n",
      "\n",
      "Metric               Score          \n",
      "-----------------------------------\n",
      "MRR@10               0.1000         \n",
      "nDCG@10              0.1538         \n",
      "Recall@1             0.0400         \n",
      "Recall@5             0.1400         \n",
      "Recall@10            0.3400         \n",
      "\n",
      "ðŸ“Š This is your BASELINE for comparison with:\n",
      "   - Phase 3: LLM-enhanced model\n",
      "   - Phase 4: RAG-enhanced model\n",
      "   - Phase 5: Final multilingual evaluation\n",
      "\n",
      "âœ“ Baseline results saved to ./models/phase2_baseline_results.json\n",
      "\n",
      "âœ“ Baseline metrics stored in 'phase2_baseline' variable for Phase 3 comparison\n",
      "\n",
      "âœ“ GPU memory cleared\n",
      "\n",
      "============================================================\n",
      "âœ… PHASE 2 EVALUATION COMPLETE - BASELINE ESTABLISHED\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PHASE 2 END: EVALUATE BM25 BASELINE MODEL\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "import torch\n",
    "from simpletransformers.retrieval import RetrievalModel, RetrievalArgs\n",
    "import json\n",
    "\n",
    "# ============================================================\n",
    "# Load BM25 Baseline Model (Trained in Phase 2)\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n=== Loading BM25 Baseline Model ===\\n\")\n",
    "\n",
    "MODEL_TO_EVAL = \"./models/dpr_bm25_baseline_epoch5\"\n",
    "print(f\"Loading model from: {MODEL_TO_EVAL}\")\n",
    "\n",
    "# Configure evaluation args\n",
    "eval_args = RetrievalArgs()\n",
    "eval_args.data_format = \"beir\"\n",
    "eval_args.max_seq_length = 256\n",
    "eval_args.include_title = False\n",
    "eval_args.hard_negatives = False\n",
    "eval_args.fp16 = USE_MIXED_PRECISION\n",
    "eval_args.eval_batch_size = 8\n",
    "\n",
    "# Load YOUR trained BM25 baseline model\n",
    "try:\n",
    "    dpr_model = RetrievalModel(\n",
    "        model_type=\"custom\",\n",
    "        model_name=MODEL_TO_EVAL,\n",
    "        args=eval_args,\n",
    "        use_cuda=torch.cuda.is_available()\n",
    "    )\n",
    "    print(f\"âœ“ BM25 Baseline Model loaded from {MODEL_TO_EVAL}\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error loading model: {e}\")\n",
    "    print(\"Make sure the model was saved during Phase 2 training\")\n",
    "    raise\n",
    "\n",
    "# Move to GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "dpr_model.query_encoder = dpr_model.query_encoder.to(device)\n",
    "dpr_model.context_encoder = dpr_model.context_encoder.to(device)\n",
    "print(f\"âœ“ Model moved to device: {device}\")\n",
    "\n",
    "# ============================================================\n",
    "# Run Evaluation using the reusable function\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EVALUATING BM25 BASELINE ON MS MARCO DEV\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if 'msmarco_dev' in locals() and len(msmarco_dev) > 0:\n",
    "    print(f\"\\nDev set size: {len(msmarco_dev):,}\")\n",
    "    \n",
    "    # Use the function you defined earlier\n",
    "    metrics = evaluate_dpr_model(\n",
    "        dpr_model, \n",
    "        msmarco_dev, \n",
    "        model_name=\"BM25 Baseline\",\n",
    "        device=device,\n",
    "        top_k=10, \n",
    "        max_samples=50  # Evaluate on 50 samples for speed\n",
    "    )\n",
    "    \n",
    "    # Display results\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"PHASE 2 BASELINE RESULTS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    print(f\"\\nStage: Phase 2 - BM25 Negative Sampling\")\n",
    "    print(f\"Model: {MODEL_TO_EVAL}\")\n",
    "    print(f\"Dataset: MS MARCO Dev\")\n",
    "    print(f\"Samples evaluated: 50 (from {len(msmarco_dev):,} total)\")\n",
    "    \n",
    "    print(f\"\\n{'Metric':<20} {'Score':<15}\")\n",
    "    print(\"-\" * 35)\n",
    "    for metric, score in metrics.items():\n",
    "        print(f\"{metric:<20} {score:<15.4f}\")\n",
    "    \n",
    "    print(\"\\nðŸ“Š This is your BASELINE for comparison with:\")\n",
    "    print(\"   - Phase 3: LLM-enhanced model\")\n",
    "    print(\"   - Phase 4: RAG-enhanced model\")\n",
    "    print(\"   - Phase 5: Final multilingual evaluation\")\n",
    "    \n",
    "    # Save baseline results\n",
    "    results_path = f\"{MODEL_DIR}/phase2_baseline_results.json\"\n",
    "    with open(results_path, 'w') as f:\n",
    "        json.dump(metrics, f, indent=2)\n",
    "    print(f\"\\nâœ“ Baseline results saved to {results_path}\")\n",
    "    \n",
    "    # Store for later comparison\n",
    "    phase2_baseline = metrics.copy()\n",
    "    print(\"\\nâœ“ Baseline metrics stored in 'phase2_baseline' variable for Phase 3 comparison\")\n",
    "    \n",
    "else:\n",
    "    print(\"âš  msmarco_dev not loaded\")\n",
    "    print(\"Make sure you ran the 'CREATING BEIR FORMAT DEV/TEST DATASETS' cell first\")\n",
    "\n",
    "# Clear GPU memory\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    print(\"\\nâœ“ GPU memory cleared\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"âœ… PHASE 2 EVALUATION COMPLETE - BASELINE ESTABLISHED\")\n",
    "print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f297fa43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Checkpoint info saved\n",
      "\n",
      "============================================================\n",
      "âœ… PHASE 2 COMPLETE: Baseline DPR Training\n",
      "============================================================\n",
      "\n",
      "ðŸ“ Model saved at: ./models/dpr_bm25_baseline_epoch5\n",
      "ðŸ“Š Training samples: 1,000\n",
      "ðŸ”§ Next: Phase 3 - LLM Integration\n"
     ]
    }
   ],
   "source": [
    "# Save training metadata\n",
    "\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "checkpoint_info = {\n",
    "    \"timestamp\": datetime.now().isoformat(),\n",
    "    \"stage\": \"1_msmarco_baseline\",\n",
    "    \"model_path\": f\"{MODEL_DIR}/dpr_bm25_baseline_epoch5\",\n",
    "    \"base_model\": BASE_MODEL,\n",
    "    \"negative_sampling\": \"BM25\",\n",
    "    \"training_samples\": len(msmarco_train_df),\n",
    "    \"epochs\": model_args.num_train_epochs,\n",
    "    \"batch_size_effective\": model_args.train_batch_size * model_args.gradient_accumulation_steps,\n",
    "    \"max_seq_length\": model_args.max_seq_length,\n",
    "    \"fp16\": model_args.fp16,\n",
    "}\n",
    "\n",
    "# Save metadata\n",
    "with open(f\"{MODEL_DIR}/checkpoint_stage1.json\", \"w\") as f:\n",
    "    json.dump(checkpoint_info, f, indent=2)\n",
    "\n",
    "print(\"âœ“ Checkpoint info saved\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"âœ… PHASE 2 COMPLETE: Baseline DPR Training\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nðŸ“ Model saved at: {MODEL_DIR}/dpr_bm25_baseline_epoch5\")\n",
    "print(f\"ðŸ“Š Training samples: {len(msmarco_train_df):,}\")\n",
    "print(f\"ðŸ”§ Next: Phase 3 - LLM Integration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f5f719",
   "metadata": {},
   "source": [
    "## Phase 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141f7064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Configuration:\n",
      "  Backend: Ollama (Local)\n",
      "  Model: llama3.1:8b\n",
      "  Temperature: 0.2\n",
      "  Max tokens: 100\n"
     ]
    }
   ],
   "source": [
    "# === LLM CONFIGURATION (SET THIS FIRST) ===\n",
    "\n",
    "# Choose your LLM backend\n",
    "USE_OLLAMA = True  # Set True for local Ollama, False for Gemini API\n",
    "GEMINI_API_KEY = None  # Set if using Gemini\n",
    "\n",
    "# Ollama model configuration \n",
    "# llama3.1:8b-instruct-q4_K_M\n",
    "# deepseek-r1:14b\n",
    "# qwen3-coder:30b\n",
    "# qwen3-vl:8b\n",
    "# gpt-oss:20b\n",
    "# llama3.2:3b\n",
    "# llama3:8b\n",
    "OLLAMA_MODEL = \"llama3.1:8b\"\n",
    "OLLAMA_URL = \"http://localhost:11434\"  # Default Ollama endpoint\n",
    "\n",
    "# LLM parameters\n",
    "LLM_TEMPERATURE = 0.2  # For classification tasks (0.1-0.3 recommended)\n",
    "LLM_MAX_TOKENS = 100   # Increased from 50 for better scoring flexibility\n",
    "\n",
    "\n",
    "print(\"LLM Configuration:\")\n",
    "print(f\"  Backend: {'Ollama (Local)' if USE_OLLAMA else 'Gemini (API)'}\")\n",
    "print(f\"  Model: {OLLAMA_MODEL if USE_OLLAMA else 'gemini-2.0-flash-exp'}\")\n",
    "print(f\"  Temperature: {LLM_TEMPERATURE}\")\n",
    "print(f\"  Max tokens: {LLM_MAX_TOKENS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4faa6d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing LLM dependencies...\n",
      "  âœ“ requests already installed\n",
      "  âœ“ ollama already installed\n",
      "âœ“ All dependencies installed\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install_if_needed(package):\n",
    "    \"\"\"Install package if not already installed\"\"\"\n",
    "    try:\n",
    "        __import__(package.replace(\"-\", \"_\"))\n",
    "        print(f\"  âœ“ {package} already installed\")\n",
    "    except ImportError:\n",
    "        print(f\"  Installing {package}...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "\n",
    "print(\"Installing LLM dependencies...\")\n",
    "packages = [\"requests\", \"ollama\"] if USE_OLLAMA else [\"google-generativeai\"]\n",
    "\n",
    "for pkg in packages:\n",
    "    install_if_needed(pkg)\n",
    "\n",
    "print(\"âœ“ All dependencies installed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "bb666411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Ollama connection...\n",
      "âœ“ Ollama is running at http://localhost:11434\n",
      "  Available models: 4\n",
      "  âœ“ llama3.1:8b is available\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "if USE_OLLAMA:\n",
    "    print(\"Testing Ollama connection...\")\n",
    "    try:\n",
    "        response = requests.get(f\"{OLLAMA_URL}/api/tags\", timeout=2)\n",
    "        if response.status_code == 200:\n",
    "            models = response.json().get(\"models\", [])\n",
    "            print(f\"âœ“ Ollama is running at {OLLAMA_URL}\")\n",
    "            print(f\"  Available models: {len(models)}\")\n",
    "            \n",
    "            # Check if our model is available\n",
    "            model_names = [m.get(\"name\", \"\") for m in models]\n",
    "            if any(OLLAMA_MODEL in name for name in model_names):\n",
    "                print(f\"  âœ“ {OLLAMA_MODEL} is available\")\n",
    "            else:\n",
    "                print(f\"  âš  {OLLAMA_MODEL} not found!\")\n",
    "                print(f\"  Run: ollama pull {OLLAMA_MODEL}\")\n",
    "        else:\n",
    "            print(\"âŒ Ollama not responding\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Ollama not running!\")\n",
    "        print(\"Steps to start Ollama:\")\n",
    "        print(\"  1. Download: https://ollama.ai/download\")\n",
    "        print(\"  2. Run: ollama serve\")\n",
    "        print(f\"  3. In another terminal: ollama pull {OLLAMA_MODEL}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "11c9dba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "INITIALIZING LLM HARD NEGATIVE CLASSIFIER\n",
      "======================================================================\n",
      "Ollama connection OK - Model 'llama3.1:8b' found\n",
      "\n",
      "LLM Classifier initialized successfully\n",
      "Ready for batch classification with retry logic\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import requests\n",
    "import time\n",
    "from typing import Dict, List\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "\n",
    "class LLMHardNegativeClassifier:\n",
    "    \"\"\"Classify negatives as HARD or EASY using LLM with continuous scoring\"\"\"\n",
    "    \n",
    "    def __init__(self, use_ollama=True, model=None, apikey=None, max_retries=3):\n",
    "        self.use_ollama = use_ollama\n",
    "        self.max_retries = max_retries\n",
    "        self.retry_delay = 2\n",
    "        \n",
    "        if use_ollama:\n",
    "            self.model = model or OLLAMA_MODEL\n",
    "            self.url = OLLAMA_URL\n",
    "            self._test_ollama_connection()\n",
    "        else:\n",
    "            import google.generativeai as genai\n",
    "            genai.configure(api_key=apikey or GEMINI_API_KEY)\n",
    "            self.model = genai.GenerativeModel(\"gemini-2.0-flash-exp\")\n",
    "            print(\"Gemini API initialized\")\n",
    "    \n",
    "    def _test_ollama_connection(self):\n",
    "        \"\"\"Test Ollama connection on startup\"\"\"\n",
    "        try:\n",
    "            response = requests.get(f\"{self.url}/api/tags\", timeout=5)\n",
    "            models = response.json().get(\"models\", [])\n",
    "            model_names = [m.get(\"name\") for m in models]\n",
    "            \n",
    "            if self.model in model_names:\n",
    "                print(f\"Ollama connection OK - Model '{self.model}' found\")\n",
    "            else:\n",
    "                available = \", \".join(model_names[:3])\n",
    "                raise ValueError(f\"Model '{self.model}' not found. Available: {available}\")\n",
    "                \n",
    "        except requests.exceptions.ConnectionError:\n",
    "            raise ConnectionError(\n",
    "                f\"Cannot connect to Ollama at {self.url}\\n\"\n",
    "                \"Start Ollama with: ollama serve\"\n",
    "            )\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Ollama connection error: {e}\")\n",
    "    \n",
    "    def call_ollama(self, prompt: str) -> str:\n",
    "        \"\"\"Call Ollama API with retry logic\"\"\"\n",
    "        \n",
    "        for attempt in range(1, self.max_retries + 1):\n",
    "            try:\n",
    "                response = requests.post(\n",
    "                    f\"{self.url}/api/generate\",\n",
    "                    json={\n",
    "                        \"model\": self.model,\n",
    "                        \"prompt\": prompt,\n",
    "                        \"stream\": False,\n",
    "                        \"options\": {\n",
    "                            \"temperature\": 0.3,\n",
    "                            \"num_predict\": 150,\n",
    "                            \"top_p\": 0.9,\n",
    "                        }\n",
    "                    },\n",
    "                    timeout=60\n",
    "                )\n",
    "                \n",
    "                if response.status_code == 200:\n",
    "                    result = response.json().get(\"response\", \"\").strip()\n",
    "                    if result:\n",
    "                        return result\n",
    "                    else:\n",
    "                        if attempt < self.max_retries:\n",
    "                            print(f\"  Attempt {attempt}: Empty response, retrying...\")\n",
    "                            time.sleep(self.retry_delay)\n",
    "                            continue\n",
    "                        raise ValueError(\"Empty response from Ollama\")\n",
    "                else:\n",
    "                    error_msg = response.text[:200]\n",
    "                    if attempt < self.max_retries:\n",
    "                        print(f\"  Attempt {attempt}: HTTP {response.status_code}, retrying...\")\n",
    "                        time.sleep(self.retry_delay)\n",
    "                        continue\n",
    "                    raise ConnectionError(f\"Ollama API error {response.status_code}: {error_msg}\")\n",
    "                    \n",
    "            except requests.exceptions.Timeout:\n",
    "                if attempt < self.max_retries:\n",
    "                    print(f\"  Attempt {attempt}: Timeout, retrying...\")\n",
    "                    time.sleep(self.retry_delay)\n",
    "                    continue\n",
    "                raise TimeoutError(\"Ollama request timed out after retries\")\n",
    "                \n",
    "            except requests.exceptions.ConnectionError:\n",
    "                if attempt < self.max_retries:\n",
    "                    print(f\"  Attempt {attempt}: Connection error, retrying...\")\n",
    "                    time.sleep(self.retry_delay)\n",
    "                    continue\n",
    "                raise ConnectionError(\n",
    "                    \"Cannot connect to Ollama. Start with: ollama serve\"\n",
    "                )\n",
    "            except Exception as e:\n",
    "                if isinstance(e, (ValueError, ConnectionError, TimeoutError)):\n",
    "                    raise\n",
    "                if attempt < self.max_retries:\n",
    "                    print(f\"  Attempt {attempt}: {type(e).__name__}, retrying...\")\n",
    "                    time.sleep(self.retry_delay)\n",
    "                    continue\n",
    "                raise RuntimeError(f\"Ollama error: {type(e).__name__}: {e}\")\n",
    "        \n",
    "        raise RuntimeError(f\"Failed to get response after {self.max_retries} attempts\")\n",
    "    \n",
    "    def _extract_hardness_score(self, response: str) -> float:\n",
    "        \"\"\"Extract continuous hardness score 0-1 from LLM response\"\"\"\n",
    "        \n",
    "        response_clean = response.strip().upper()\n",
    "        \n",
    "        # 1. Try simple numeric (0-100)\n",
    "        try:\n",
    "            score = float(response_clean)\n",
    "            if score > 1.0:\n",
    "                score = score / 100.0\n",
    "            return min(max(score, 0.0), 1.0)\n",
    "        except ValueError:\n",
    "            pass\n",
    "        \n",
    "        # 2. Extract from patterns\n",
    "        patterns = [\n",
    "            (r'(\\d+)\\s*(?:out of|\\/)\\s*100', 100),\n",
    "            (r'(\\d+)\\s*(?:out of|\\/)\\s*10', 10),\n",
    "            (r'score[:\\s]*(\\d+\\.?\\d*)', 100),\n",
    "            (r'(\\d+\\.?\\d*)\\s*%', 100),\n",
    "            (r'(\\d+\\.?\\d*)\\s*\\/\\s*(\\d+\\.?\\d*)', None),  # a/b format\n",
    "        ]\n",
    "        \n",
    "        for pattern, divisor in patterns:\n",
    "            match = re.search(pattern, response_clean, re.IGNORECASE)\n",
    "            if match:\n",
    "                try:\n",
    "                    if divisor is None:\n",
    "                        numerator = float(match.group(1))\n",
    "                        denominator = float(match.group(2))\n",
    "                        if denominator > 0:\n",
    "                            score = numerator / denominator\n",
    "                        else:\n",
    "                            continue\n",
    "                    else:\n",
    "                        score = float(match.group(1)) / divisor\n",
    "                    \n",
    "                    return min(max(score, 0.0), 1.0)\n",
    "                except (ValueError, ZeroDivisionError):\n",
    "                    continue\n",
    "        \n",
    "        # 3. Keyword-based\n",
    "        hardness_map = {\n",
    "            'EXTREMELY HARD': 0.95,\n",
    "            'VERY HARD': 0.85,\n",
    "            'QUITE HARD': 0.75,\n",
    "            'HARD': 0.70,\n",
    "            'MODERATELY HARD': 0.60,\n",
    "            'SOMEWHAT HARD': 0.55,\n",
    "            'MEDIUM': 0.50,\n",
    "            'SOMEWHAT EASY': 0.40,\n",
    "            'MODERATELY EASY': 0.35,\n",
    "            'FAIRLY EASY': 0.30,\n",
    "            'EASY': 0.25,\n",
    "            'VERY EASY': 0.10,\n",
    "            'EXTREMELY EASY': 0.05,\n",
    "            'TRIVIAL': 0.02,\n",
    "        }\n",
    "        \n",
    "        for keyword, score in hardness_map.items():\n",
    "            if keyword in response_clean:\n",
    "                return score\n",
    "        \n",
    "        # 4. Last resort - default\n",
    "        print(f\"  Warning: Could not parse '{response_clean}', defaulting to 0.5\")\n",
    "        return 0.5\n",
    "    \n",
    "    def classify_negative(\n",
    "        self, \n",
    "        query: str, \n",
    "        gold_passage: str, \n",
    "        negative_passage: str\n",
    "    ) -> Dict:\n",
    "        \"\"\"Classify negative and return continuous hardness score\"\"\"\n",
    "        \n",
    "        # Truncate for context\n",
    "        query = query[:200]\n",
    "        gold_passage = gold_passage[:300]\n",
    "        negative_passage = negative_passage[:300]\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "Rate the hardness of this negative passage for training (0-100).\n",
    "\n",
    "Query: {query}\n",
    "\n",
    "Gold Passage: {gold_passage}\n",
    "\n",
    "Negative Passage: {negative_passage}\n",
    "\n",
    "HARD negatives (70-100):\n",
    "- Topically related but factually different\n",
    "- Use similar keywords/entities\n",
    "- Require semantic understanding to distinguish\n",
    "- High confusion potential\n",
    "\n",
    "EASY negatives (0-30):\n",
    "- Clearly unrelated topic\n",
    "- Different domain/keywords\n",
    "- No semantic confusion\n",
    "\n",
    "Provide ONLY a number from 0-100:\"\"\"\n",
    "        \n",
    "        try:\n",
    "            # Get LLM response with retry\n",
    "            if self.use_ollama:\n",
    "                response = self.call_ollama(prompt)\n",
    "            else:\n",
    "                response = self.model.generate_content(prompt).text.strip()\n",
    "            \n",
    "            # Extract continuous score\n",
    "            hardness_score = self._extract_hardness_score(response)\n",
    "            is_hard = hardness_score > 0.5\n",
    "            \n",
    "            return {\n",
    "                \"is_hard\": is_hard,\n",
    "                \"hardness_score\": hardness_score,\n",
    "                \"classification\": \"HARD\" if is_hard else \"EASY\",\n",
    "                \"response\": response,\n",
    "                \"success\": True\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  Classification error: {type(e).__name__}: {e}\")\n",
    "            return {\n",
    "                \"is_hard\": None,\n",
    "                \"hardness_score\": 0.5,\n",
    "                \"classification\": \"UNKNOWN\",\n",
    "                \"response\": str(e),\n",
    "                \"success\": False\n",
    "            }\n",
    "    \n",
    "    def classify_batch(\n",
    "        self, \n",
    "        examples: List[Dict], \n",
    "        max_samples: int = None,\n",
    "        skip_errors: bool = True\n",
    "    ) -> List[Dict]:\n",
    "        \"\"\"Classify a batch of negatives\"\"\"\n",
    "        \n",
    "        samples = examples[:max_samples] if max_samples else examples\n",
    "        results = []\n",
    "        errors = []\n",
    "        \n",
    "        print(f\"\\nClassifying {len(samples)} negatives with LLM...\")\n",
    "        print(f\"Max retries per sample: {self.max_retries}\\n\")\n",
    "        \n",
    "        for idx, example in enumerate(tqdm(samples, desc=\"LLM Classification\"), 1):\n",
    "            try:\n",
    "                result = self.classify_negative(\n",
    "                    example['query_text'],\n",
    "                    example['gold_passage'],\n",
    "                    example['hard_negative']\n",
    "                )\n",
    "                \n",
    "                if not result['success'] and skip_errors:\n",
    "                    errors.append((idx, result['response']))\n",
    "                    continue\n",
    "                \n",
    "                example_with_classification = {\n",
    "                    **example,\n",
    "                    'llm_classification': result['classification'],\n",
    "                    'is_hard': result['is_hard'],\n",
    "                    'hardness_score': result['hardness_score']\n",
    "                }\n",
    "                results.append(example_with_classification)\n",
    "                \n",
    "            except Exception as e:\n",
    "                if skip_errors:\n",
    "                    errors.append((idx, str(e)))\n",
    "                    continue\n",
    "                raise\n",
    "        \n",
    "        # Statistics\n",
    "        if results:\n",
    "            hard_count = sum(1 for r in results if r['is_hard'] == True)\n",
    "            easy_count = sum(1 for r in results if r['is_hard'] == False)\n",
    "            avg_score = np.mean([r['hardness_score'] for r in results])\n",
    "            \n",
    "            print(f\"\\nClassification complete!\")\n",
    "            print(f\"  Successful: {len(results)}/{len(samples)}\")\n",
    "            print(f\"  HARD: {hard_count} ({hard_count/len(results)*100:.1f}%)\")\n",
    "            print(f\"  EASY: {easy_count} ({easy_count/len(results)*100:.1f}%)\")\n",
    "            print(f\"  Average hardness: {avg_score:.2f}\")\n",
    "            \n",
    "            if errors:\n",
    "                print(f\"  Errors: {len(errors)}\")\n",
    "                for idx, error in errors[:3]:\n",
    "                    print(f\"    Sample {idx}: {error[:50]}\")\n",
    "        else:\n",
    "            print(\"No samples classified successfully\")\n",
    "        \n",
    "        return results\n",
    "\n",
    "# Initialize with proper error handling\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"INITIALIZING LLM HARD NEGATIVE CLASSIFIER\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "try:\n",
    "    llm_classifier = LLMHardNegativeClassifier(\n",
    "        use_ollama=USE_OLLAMA,\n",
    "        model=OLLAMA_MODEL if USE_OLLAMA else None,\n",
    "        apikey=GEMINI_API_KEY if not USE_OLLAMA else None,\n",
    "        max_retries=3\n",
    "    )\n",
    "    print(\"\\nLLM Classifier initialized successfully\")\n",
    "    print(\"Ready for batch classification with retry logic\")\n",
    "    \n",
    "except ConnectionError as e:\n",
    "    print(f\"\\nERROR: {e}\")\n",
    "    print(\"Fix: Start Ollama with: ollama serve\")\n",
    "    raise\n",
    "    \n",
    "except ValueError as e:\n",
    "    print(f\"\\nERROR: {e}\")\n",
    "    print(\"Fix: Pull model with: ollama pull gpt-oss:20b\")\n",
    "    raise\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\nFATAL ERROR: {type(e).__name__}: {e}\")\n",
    "    raise\n",
    "\n",
    "print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "e6018ca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "COMPREHENSIVE LLM CLASSIFIER TEST\n",
      "============================================================\n",
      "\n",
      "Running comprehensive classifier tests...\n",
      "\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Test 1: EASY - Completely Unrelated (1/8)\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "Query: what is photosynthesis\n",
      "\n",
      "Gold Passage (correct answer):\n",
      "  Photosynthesis is the process by which plants convert light energy into chemical energy in the form ...\n",
      "\n",
      "Negative Passage (candidate):\n",
      "  The Great Wall of China is one of the most impressive architectural feats in human history, stretchi...\n",
      "\n",
      "ðŸ“Š Result:\n",
      "  Expected: EASY\n",
      "  Classified: EASY\n",
      "  Hardness Score: 0.2\n",
      "  Status: âœ… CORRECT\n",
      "  LLM Response: 20...\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Test 2: HARD - Topically Similar but Wrong Answer (2/8)\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "Query: what is photosynthesis\n",
      "\n",
      "Gold Passage (correct answer):\n",
      "  Photosynthesis is the process by which plants convert light energy into chemical energy in the form ...\n",
      "\n",
      "Negative Passage (candidate):\n",
      "  Chemosynthesis is the process by which certain organisms use chemical energy instead of light energy...\n",
      "\n",
      "ðŸ“Š Result:\n",
      "  Expected: HARD\n",
      "  Classified: HARD\n",
      "  Hardness Score: 0.6\n",
      "  Status: âœ… CORRECT\n",
      "  LLM Response: 60...\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Test 3: EASY - Different Topic (3/8)\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "Query: how do vaccines work\n",
      "\n",
      "Gold Passage (correct answer):\n",
      "  Vaccines work by introducing a weakened or inactive form of a pathogen to stimulate the immune syste...\n",
      "\n",
      "Negative Passage (candidate):\n",
      "  Python is a high-level programming language known for its simple syntax and readability, used in web...\n",
      "\n",
      "ðŸ“Š Result:\n",
      "  Expected: EASY\n",
      "  Classified: EASY\n",
      "  Hardness Score: 0.2\n",
      "  Status: âœ… CORRECT\n",
      "  LLM Response: 20...\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Test 4: HARD - Similar Keywords but Different Meaning (4/8)\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "Query: how do vaccines work\n",
      "\n",
      "Gold Passage (correct answer):\n",
      "  Vaccines work by introducing a weakened or inactive form of a pathogen to stimulate the immune syste...\n",
      "\n",
      "Negative Passage (candidate):\n",
      "  Antibiotics work by killing bacteria or preventing their growth, interfering with bacterial cell wal...\n",
      "\n",
      "ðŸ“Š Result:\n",
      "  Expected: HARD\n",
      "  Classified: HARD\n",
      "  Hardness Score: 0.6\n",
      "  Status: âœ… CORRECT\n",
      "  LLM Response: 60...\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Test 5: EASY - Sports vs Science (5/8)\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "Query: what is diabetes\n",
      "\n",
      "Gold Passage (correct answer):\n",
      "  Diabetes is a metabolic disorder characterized by high blood sugar levels due to insufficient insuli...\n",
      "\n",
      "Negative Passage (candidate):\n",
      "  Basketball is a team sport where two teams of five players compete to shoot a ball through the oppos...\n",
      "\n",
      "ðŸ“Š Result:\n",
      "  Expected: EASY\n",
      "  Classified: EASY\n",
      "  Hardness Score: 0.2\n",
      "  Status: âœ… CORRECT\n",
      "  LLM Response: 20...\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Test 6: HARD - Similar Medical Terms but Different (6/8)\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "Query: what is diabetes\n",
      "\n",
      "Gold Passage (correct answer):\n",
      "  Diabetes is a metabolic disorder characterized by high blood sugar levels due to insufficient insuli...\n",
      "\n",
      "Negative Passage (candidate):\n",
      "  Hypertension is a condition characterized by elevated blood pressure, which can lead to heart diseas...\n",
      "\n",
      "ðŸ“Š Result:\n",
      "  Expected: HARD\n",
      "  Classified: EASY\n",
      "  Hardness Score: 0.4\n",
      "  Status: âŒ INCORRECT\n",
      "  LLM Response: 40...\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Test 7: EASY - Historical vs Current (7/8)\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "Query: what is artificial intelligence\n",
      "\n",
      "Gold Passage (correct answer):\n",
      "  Artificial intelligence is the field of computer science dedicated to creating intelligent machines ...\n",
      "\n",
      "Negative Passage (candidate):\n",
      "  The Roman Empire was one of the largest and most influential empires in history, lasting over 400 ye...\n",
      "\n",
      "ðŸ“Š Result:\n",
      "  Expected: EASY\n",
      "  Classified: EASY\n",
      "  Hardness Score: 0.4\n",
      "  Status: âœ… CORRECT\n",
      "  LLM Response: 40...\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Test 8: HARD - Related ML Concepts (8/8)\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "Query: what is artificial intelligence\n",
      "\n",
      "Gold Passage (correct answer):\n",
      "  Artificial intelligence is the field of computer science dedicated to creating intelligent machines ...\n",
      "\n",
      "Negative Passage (candidate):\n",
      "  Machine learning is a subset of artificial intelligence that focuses on enabling computers to learn ...\n",
      "\n",
      "ðŸ“Š Result:\n",
      "  Expected: HARD\n",
      "  Classified: HARD\n",
      "  Hardness Score: 0.6\n",
      "  Status: âœ… CORRECT\n",
      "  LLM Response: 60...\n",
      "\n",
      "\n",
      "======================================================================\n",
      "TEST SUMMARY\n",
      "======================================================================\n",
      "\n",
      "Total Tests Completed: 8/8\n",
      "Correct: 7 (87.5%)\n",
      "Incorrect: 1 (12.5%)\n",
      "\n",
      "Per-Category Performance:\n",
      "  EASY: 4/4 (100.0%)\n",
      "  HARD: 3/4 (75.0%)\n",
      "\n",
      "\n",
      "Detailed Results Table:\n",
      "                                            test_name expected classified  correct  hardness_score\n",
      "                  Test 1: EASY - Completely Unrelated     EASY       EASY     True             0.2\n",
      "    Test 2: HARD - Topically Similar but Wrong Answer     HARD       HARD     True             0.6\n",
      "                       Test 3: EASY - Different Topic     EASY       EASY     True             0.2\n",
      "Test 4: HARD - Similar Keywords but Different Meaning     HARD       HARD     True             0.6\n",
      "                     Test 5: EASY - Sports vs Science     EASY       EASY     True             0.2\n",
      "   Test 6: HARD - Similar Medical Terms but Different     HARD       EASY    False             0.4\n",
      "                 Test 7: EASY - Historical vs Current     EASY       EASY     True             0.4\n",
      "                   Test 8: HARD - Related ML Concepts     HARD       HARD     True             0.6\n",
      "\n",
      "======================================================================\n",
      "CLASSIFIER EVALUATION\n",
      "======================================================================\n",
      "\n",
      "âœ… EXCELLENT - Classifier is working correctly!\n",
      "   It can distinguish between EASY and HARD negatives reliably.\n",
      "\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"COMPREHENSIVE LLM CLASSIFIER TEST\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Create diverse test cases with known difficulty levels\n",
    "test_cases = [\n",
    "    {\n",
    "        \"name\": \"Test 1: EASY - Completely Unrelated\",\n",
    "        \"query\": \"what is photosynthesis\",\n",
    "        \"gold\": \"Photosynthesis is the process by which plants convert light energy into chemical energy in the form of glucose. It occurs in the chloroplasts of plant cells.\",\n",
    "        \"negative\": \"The Great Wall of China is one of the most impressive architectural feats in human history, stretching over 13,000 miles across northern China.\",\n",
    "        \"expected\": \"EASY\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Test 2: HARD - Topically Similar but Wrong Answer\",\n",
    "        \"query\": \"what is photosynthesis\",\n",
    "        \"gold\": \"Photosynthesis is the process by which plants convert light energy into chemical energy in the form of glucose.\",\n",
    "        \"negative\": \"Chemosynthesis is the process by which certain organisms use chemical energy instead of light energy to produce organic compounds from carbon dioxide.\",\n",
    "        \"expected\": \"HARD\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Test 3: EASY - Different Topic\",\n",
    "        \"query\": \"how do vaccines work\",\n",
    "        \"gold\": \"Vaccines work by introducing a weakened or inactive form of a pathogen to stimulate the immune system to produce antibodies.\",\n",
    "        \"negative\": \"Python is a high-level programming language known for its simple syntax and readability, used in web development, data science, and artificial intelligence.\",\n",
    "        \"expected\": \"EASY\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Test 4: HARD - Similar Keywords but Different Meaning\",\n",
    "        \"query\": \"how do vaccines work\",\n",
    "        \"gold\": \"Vaccines work by introducing a weakened or inactive form of a pathogen to stimulate the immune system.\",\n",
    "        \"negative\": \"Antibiotics work by killing bacteria or preventing their growth, interfering with bacterial cell walls or protein synthesis.\",\n",
    "        \"expected\": \"HARD\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Test 5: EASY - Sports vs Science\",\n",
    "        \"query\": \"what is diabetes\",\n",
    "        \"gold\": \"Diabetes is a metabolic disorder characterized by high blood sugar levels due to insufficient insulin production or insulin resistance.\",\n",
    "        \"negative\": \"Basketball is a team sport where two teams of five players compete to shoot a ball through the opposing team's elevated hoop.\",\n",
    "        \"expected\": \"EASY\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Test 6: HARD - Similar Medical Terms but Different\",\n",
    "        \"query\": \"what is diabetes\",\n",
    "        \"gold\": \"Diabetes is a metabolic disorder characterized by high blood sugar levels due to insufficient insulin production or insulin resistance.\",\n",
    "        \"negative\": \"Hypertension is a condition characterized by elevated blood pressure, which can lead to heart disease and stroke if left untreated.\",\n",
    "        \"expected\": \"HARD\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Test 7: EASY - Historical vs Current\",\n",
    "        \"query\": \"what is artificial intelligence\",\n",
    "        \"gold\": \"Artificial intelligence is the field of computer science dedicated to creating intelligent machines capable of performing tasks that typically require human intelligence.\",\n",
    "        \"negative\": \"The Roman Empire was one of the largest and most influential empires in history, lasting over 400 years and spanning three continents.\",\n",
    "        \"expected\": \"EASY\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Test 8: HARD - Related ML Concepts\",\n",
    "        \"query\": \"what is artificial intelligence\",\n",
    "        \"gold\": \"Artificial intelligence is the field of computer science dedicated to creating intelligent machines capable of performing tasks that typically require human intelligence.\",\n",
    "        \"negative\": \"Machine learning is a subset of artificial intelligence that focuses on enabling computers to learn and improve from experience without being explicitly programmed.\",\n",
    "        \"expected\": \"HARD\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Run tests\n",
    "print(\"\\nRunning comprehensive classifier tests...\\n\")\n",
    "\n",
    "results_summary = {\n",
    "    \"EASY\": {\"correct\": 0, \"incorrect\": 0},\n",
    "    \"HARD\": {\"correct\": 0, \"incorrect\": 0}\n",
    "}\n",
    "\n",
    "detailed_results = []\n",
    "test_passed = True\n",
    "\n",
    "for test_idx, test in enumerate(test_cases, 1):\n",
    "    print(f\"\\n{'â”€'*70}\")\n",
    "    print(f\"{test['name']} ({test_idx}/{len(test_cases)})\")\n",
    "    print(f\"{'â”€'*70}\")\n",
    "    \n",
    "    print(f\"\\nQuery: {test['query']}\")\n",
    "    print(f\"\\nGold Passage (correct answer):\")\n",
    "    print(f\"  {test['gold'][:100]}...\")\n",
    "    print(f\"\\nNegative Passage (candidate):\")\n",
    "    print(f\"  {test['negative'][:100]}...\")\n",
    "    \n",
    "    # Classify\n",
    "    try:\n",
    "        result = llm_classifier.classify_negative(\n",
    "            test['query'],\n",
    "            test['gold'],\n",
    "            test['negative']\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"\\nâŒ CRITICAL ERROR during classification:\")\n",
    "        print(f\"   {type(e).__name__}: {e}\")\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(\"TEST ABORTED DUE TO ERROR\")\n",
    "        print(f\"{'='*70}\")\n",
    "        test_passed = False\n",
    "        break\n",
    "    \n",
    "    classification = result['classification']\n",
    "    response = result['response']\n",
    "    expected = test['expected']\n",
    "    is_correct = (classification == expected)\n",
    "    \n",
    "    # Check for ERROR response\n",
    "    if response == \"ERROR\" or \"ERROR\" in response:\n",
    "        print(f\"\\nâŒ CRITICAL: LLM returned ERROR\")\n",
    "        print(f\"   Raw response: {response}\")\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(\"OLLAMA CONNECTION ISSUE DETECTED\")\n",
    "        print(f\"{'='*70}\")\n",
    "        print(\"\\nTroubleshooting steps:\")\n",
    "        print(\"1. Check if Ollama is running: ps aux | grep ollama\")\n",
    "        print(\"2. Start Ollama if not running: ollama serve\")\n",
    "        print(\"3. Verify model exists: ollama list\")\n",
    "        print(f\"4. Check model name: Currently using '{OLLAMA_MODEL}'\")\n",
    "        print(\"5. Test manually: ollama run \" + OLLAMA_MODEL)\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        test_passed = False\n",
    "        break\n",
    "    \n",
    "    # Display result\n",
    "    print(f\"\\nðŸ“Š Result:\")\n",
    "    print(f\"  Expected: {expected}\")\n",
    "    print(f\"  Classified: {classification}\")\n",
    "    print(f\"  Hardness Score: {result.get('hardness_score', 'N/A')}\")\n",
    "    print(f\"  Status: {'âœ… CORRECT' if is_correct else 'âŒ INCORRECT'}\")\n",
    "    print(f\"  LLM Response: {response[:80]}...\")\n",
    "    \n",
    "    # Track statistics\n",
    "    if expected in results_summary:\n",
    "        if is_correct:\n",
    "            results_summary[expected][\"correct\"] += 1\n",
    "        else:\n",
    "            results_summary[expected][\"incorrect\"] += 1\n",
    "    \n",
    "    detailed_results.append({\n",
    "        \"test_name\": test['name'],\n",
    "        \"expected\": expected,\n",
    "        \"classified\": classification,\n",
    "        \"correct\": is_correct,\n",
    "        \"hardness_score\": result.get('hardness_score', 0.5)\n",
    "    })\n",
    "\n",
    "# Only show summary if tests completed\n",
    "if test_passed and len(detailed_results) > 0:\n",
    "    # Summary statistics\n",
    "    print(f\"\\n\\n{'='*70}\")\n",
    "    print(\"TEST SUMMARY\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    total_tests = len(detailed_results)\n",
    "    total_correct = sum(r[\"correct\"] for r in results_summary.values())\n",
    "    total_incorrect = sum(r[\"incorrect\"] for r in results_summary.values())\n",
    "    accuracy = (total_correct / total_tests) * 100 if total_tests > 0 else 0\n",
    "    \n",
    "    print(f\"Total Tests Completed: {total_tests}/{len(test_cases)}\")\n",
    "    print(f\"Correct: {total_correct} ({accuracy:.1f}%)\")\n",
    "    print(f\"Incorrect: {total_incorrect} ({100-accuracy:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\nPer-Category Performance:\")\n",
    "    for category, stats in results_summary.items():\n",
    "        total = stats[\"correct\"] + stats[\"incorrect\"]\n",
    "        if total > 0:\n",
    "            cat_accuracy = (stats[\"correct\"] / total) * 100\n",
    "            print(f\"  {category}: {stats['correct']}/{total} ({cat_accuracy:.1f}%)\")\n",
    "    \n",
    "    # Create results DataFrame\n",
    "    results_df = pd.DataFrame(detailed_results)\n",
    "    \n",
    "    print(f\"\\n\\nDetailed Results Table:\")\n",
    "    print(results_df.to_string(index=False))\n",
    "    \n",
    "    # Evaluation\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"CLASSIFIER EVALUATION\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    if accuracy >= 87.5:  # 7/8 correct\n",
    "        print(\"âœ… EXCELLENT - Classifier is working correctly!\")\n",
    "        print(\"   It can distinguish between EASY and HARD negatives reliably.\")\n",
    "    elif accuracy >= 75:  # 6/8 correct\n",
    "        print(\"âœ… GOOD - Classifier is working reasonably well.\")\n",
    "        print(\"   Some edge cases may need adjustment.\")\n",
    "    elif accuracy >= 62.5:  # 5/8 correct\n",
    "        print(\"âš ï¸  FAIR - Classifier has room for improvement.\")\n",
    "        print(\"   Consider tuning the LLM temperature or prompt.\")\n",
    "    else:\n",
    "        print(\"âŒ POOR - Classifier needs significant improvement.\")\n",
    "        print(\"   Try using a larger LLM model or different prompt.\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "\n",
    "elif not test_passed:\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"âŒ TESTS FAILED - FIX OLLAMA CONNECTION FIRST\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"\\nCannot proceed with Phase 4 RAG until LLM is working properly.\")\n",
    "    \n",
    "else:\n",
    "    print(\"\\nâŒ No tests completed successfully\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240a44ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "CLASSIFY MS MARCO TRAINING DATA\n",
      "============================================================\n",
      "\n",
      "Processing all 1000 MS MARCO samples...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MS MARCO Classification:  10%|â–ˆ         | 100/1000 [04:11<36:55,  2.46s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint: 100 samples saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MS MARCO Classification:  20%|â–ˆâ–ˆ        | 200/1000 [08:16<32:44,  2.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint: 200 samples saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MS MARCO Classification:  30%|â–ˆâ–ˆâ–ˆ       | 300/1000 [12:21<28:52,  2.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint: 300 samples saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MS MARCO Classification:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 400/1000 [16:26<24:08,  2.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint: 400 samples saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MS MARCO Classification:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 500/1000 [20:31<20:31,  2.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint: 500 samples saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MS MARCO Classification:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 600/1000 [24:36<16:32,  2.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint: 600 samples saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MS MARCO Classification:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 700/1000 [28:40<12:12,  2.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint: 700 samples saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MS MARCO Classification:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 800/1000 [32:44<08:13,  2.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint: 800 samples saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MS MARCO Classification:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 900/1000 [36:50<04:06,  2.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint: 900 samples saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MS MARCO Classification: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [40:55<00:00,  2.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint: 1000 samples saved\n",
      "\n",
      "MS MARCO - Total: 1,000\n",
      "  HARD: 667\n",
      "  EASY: 333\n",
      "  Saved: data\\llm_classified_data\\llm_classified_msmarco\\llm_classified_msmarco_train.csv\n",
      "\n",
      "Language: SWAHILI\n",
      "  Skipped - no data\n",
      "\n",
      "Language: BENGALI\n",
      "  Skipped - no data\n",
      "\n",
      "Language: TELUGU\n",
      "  Skipped - no data\n",
      "\n",
      "Language: THAI\n",
      "  Skipped - no data\n",
      "\n",
      "Language: ARABIC\n",
      "  Skipped - no data\n",
      "\n",
      "Language: FINNISH\n",
      "  Skipped - no data\n",
      "\n",
      "Language: INDONESIAN\n",
      "  Skipped - no data\n",
      "\n",
      "Language: JAPANESE\n",
      "  Skipped - no data\n",
      "\n",
      "Language: KOREAN\n",
      "  Skipped - no data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CLASSIFY MS MARCO TRAINING DATA\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "CHECKPOINT_INTERVAL = 100\n",
    "BASE_OUTPUT_DIR = os.path.join(DATA_DIR, \"llm_classified_data\")\n",
    "MSMARCO_OUTPUT_DIR = os.path.join(BASE_OUTPUT_DIR, \"llm_classified_msmarco\")\n",
    "TYDI_OUTPUT_DIR = os.path.join(BASE_OUTPUT_DIR, \"llm_classified_tydi\")\n",
    "\n",
    "os.makedirs(MSMARCO_OUTPUT_DIR, exist_ok=True)\n",
    "os.makedirs(TYDI_OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"\\nProcessing all {len(msmarco_train_df)} MS MARCO samples...\\n\")\n",
    "\n",
    "# Classify MS MARCO\n",
    "OUTPUT_FILE = os.path.join(MSMARCO_OUTPUT_DIR, \"llm_classified_msmarco_train.jsonl\")\n",
    "train_examples = msmarco_train_df.to_dict('records')\n",
    "llm_classified = []\n",
    "checkpoint_data = []\n",
    "\n",
    "for idx, example in enumerate(tqdm(train_examples, desc=\"MS MARCO Classification\"), 1):\n",
    "    result = llm_classifier.classify_negative(\n",
    "        example.get('query_text', ''),\n",
    "        example.get('gold_passage', ''),\n",
    "        example.get('hard_negative', '')\n",
    "    )\n",
    "    \n",
    "    classified_item = {\n",
    "        **example,\n",
    "        'llm_classification': result['classification'],\n",
    "        'is_hard': result['is_hard'],\n",
    "        'hardness_score': result['hardness_score']\n",
    "    }\n",
    "    \n",
    "    llm_classified.append(classified_item)\n",
    "    checkpoint_data.append(classified_item)\n",
    "    \n",
    "    # Save every 100 samples\n",
    "    if idx % CHECKPOINT_INTERVAL == 0:\n",
    "        with open(OUTPUT_FILE, 'a') as f:\n",
    "            for item in checkpoint_data:\n",
    "                f.write(json.dumps(item) + '\\n')\n",
    "        print(f\"  Checkpoint: {idx} samples saved\")\n",
    "        checkpoint_data = []\n",
    "\n",
    "# Save remaining MS MARCO\n",
    "if checkpoint_data:\n",
    "    with open(OUTPUT_FILE, 'a') as f:\n",
    "        for item in checkpoint_data:\n",
    "            f.write(json.dumps(item) + '\\n')\n",
    "    print(f\"  Final: {len(checkpoint_data)} samples saved\")\n",
    "\n",
    "llm_classified_df = pd.DataFrame(llm_classified)\n",
    "csv_file = os.path.join(MSMARCO_OUTPUT_DIR, \"llm_classified_msmarco_train.csv\")\n",
    "llm_classified_df.to_csv(csv_file, index=False)\n",
    "\n",
    "print(f\"\\nMS MARCO - Total: {len(llm_classified_df):,}\")\n",
    "print(f\"  HARD: {llm_classified_df['is_hard'].sum():,}\")\n",
    "print(f\"  EASY: {(~llm_classified_df['is_hard']).sum():,}\")\n",
    "print(f\"  Saved: {csv_file}\\n\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "60adb878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "CLASSIFY TyDi (Combined)\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TyDi:  19%|â–ˆâ–‰        | 317/1688 [14:08<1:15:04,  3.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Warning: Could not parse '85\n",
      "\n",
      "THE NEGATIVE PASSAGE IS FACTUALLY DIFFERENT, BUT TOPICALLY RELATED AND USES SIMILAR KEYWORDS/ENTITIES AS THE GOLD PASSAGE. IT REQUIRES SEMANTIC UNDERSTANDING TO DISTINGUISH BETWEEN THE TWO PASSAGES, WHICH MAKES IT A MODERATELY DIFFICULT NEGATIVE EXAMPLE.', defaulting to 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TyDi:  19%|â–ˆâ–‰        | 325/1688 [14:33<1:13:33,  3.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Warning: Could not parse '85\n",
      "\n",
      "THIS PASSAGE IS FACTUALLY DIFFERENT BUT STILL RELATED TO THE ORIGINAL QUERY, REQUIRING SOME SEMANTIC UNDERSTANDING TO DISTINGUISH BETWEEN CORRECT AND INCORRECT INFORMATION. THE KEYWORDS/ENTITIES ARE SIMILAR, MAKING IT A CHALLENGING NEGATIVE PASSAGE FOR TRAINING.', defaulting to 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TyDi:  22%|â–ˆâ–ˆâ–       | 377/1688 [17:12<1:08:56,  3.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Warning: Could not parse '85\n",
      "\n",
      "THIS PASSAGE IS FACTUALLY DIFFERENT, BUT TOPICALLY RELATED TO THE GOLD PASSAGE. IT REQUIRES SOME SEMANTIC UNDERSTANDING TO DISTINGUISH BETWEEN THE TWO PASSAGES, WHICH MAKES IT A MODERATE-NEGATIVE.', defaulting to 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TyDi:  27%|â–ˆâ–ˆâ–‹       | 458/1688 [21:20<1:10:08,  3.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Warning: Could not parse '85\n",
      "\n",
      "THE NEGATIVE PASSAGE IS FACTUALLY DIFFERENT FROM THE GOLD PASSAGE, BUT IT'S NOT ENTIRELY UNRELATED. IT REQUIRES SOME SEMANTIC UNDERSTANDING TO DISTINGUISH BETWEEN THE TWO PASSAGES, AND THERE'S POTENTIAL FOR CONFUSION DUE TO SIMILAR KEYWORDS/ENTITIES (E.G., \"à°ªà°°à°®à°¾à°£à± à°¸à°‚à°–à±à°¯\" IN BOTH PASSAGES).', defaulting to 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TyDi:  28%|â–ˆâ–ˆâ–Š       | 467/1688 [21:50<1:10:07,  3.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Warning: Could not parse '85\n",
      "\n",
      "THE PASSAGE IS FACTUALLY DIFFERENT AND REQUIRES SEMANTIC UNDERSTANDING TO DISTINGUISH, BUT THE KEYWORDS/ENTITIES ARE SIMILAR.', defaulting to 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TyDi: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1688/1688 [1:17:09<00:00,  2.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ“ TyDi: 1,688\n",
      "  HARD: 1,391\n",
      "  EASY: 297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CLASSIFY TyDi (Combined)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "tydi_examples = tydi_train_df.to_dict('records')\n",
    "tydi_classified = []\n",
    "checkpoint_data = []\n",
    "\n",
    "OUTPUT_FILE = os.path.join(TYDI_OUTPUT_DIR, \"llm_classified_tydi_combined.jsonl\")\n",
    "\n",
    "for idx, example in enumerate(tqdm(tydi_examples, desc=\"TyDi\"), 1):\n",
    "    result = llm_classifier.classify_negative(\n",
    "        example.get('query_text', ''),\n",
    "        example.get('gold_passage', ''),\n",
    "        example.get('hard_negative', '')\n",
    "    )\n",
    "    \n",
    "    classified_item = {\n",
    "        **example,\n",
    "        'llm_classification': result['classification'],\n",
    "        'is_hard': result['is_hard'],\n",
    "        'hardness_score': result['hardness_score']\n",
    "    }\n",
    "    \n",
    "    tydi_classified.append(classified_item)\n",
    "    checkpoint_data.append(classified_item)\n",
    "    \n",
    "    if idx % CHECKPOINT_INTERVAL == 0:\n",
    "        with open(OUTPUT_FILE, 'a') as f:\n",
    "            for item in checkpoint_data:\n",
    "                f.write(json.dumps(item) + '\\n')\n",
    "        checkpoint_data = []\n",
    "\n",
    "if checkpoint_data:\n",
    "    with open(OUTPUT_FILE, 'a') as f:\n",
    "        for item in checkpoint_data:\n",
    "            f.write(json.dumps(item) + '\\n')\n",
    "\n",
    "tydi_classified_df = pd.DataFrame(tydi_classified)\n",
    "tydi_classified_df.to_csv(os.path.join(TYDI_OUTPUT_DIR, \"llm_classified_tydi_combined.csv\"), index=False)\n",
    "\n",
    "print(f\"\\nâœ“ TyDi: {len(tydi_classified_df):,}\")\n",
    "print(f\"  HARD: {tydi_classified_df['is_hard'].sum():,}\")\n",
    "print(f\"  EASY: {(~tydi_classified_df['is_hard']).sum():,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "8e22e13f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "STEP 2: GENERATE LLM HARD NEGATIVES (3 per query)\n",
      "============================================================\n",
      "\n",
      "Filtered HARD negatives: 667\n",
      "\n",
      "Generating 3 negatives per query (1000 queries)...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating:  10%|â–ˆ         | 100/1000 [10:41<1:36:33,  6.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint: 100 queries, 300 triplets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating:  20%|â–ˆâ–ˆ        | 200/1000 [19:36<1:06:44,  5.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint: 200 queries, 600 triplets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating:  30%|â–ˆâ–ˆâ–ˆ       | 300/1000 [27:56<58:16,  5.00s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint: 300 queries, 900 triplets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 400/1000 [36:17<50:13,  5.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint: 400 queries, 1,200 triplets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 500/1000 [44:36<41:53,  5.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint: 500 queries, 1,500 triplets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 600/1000 [52:55<33:47,  5.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint: 600 queries, 1,798 triplets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 700/1000 [1:01:15<25:02,  5.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint: 700 queries, 2,098 triplets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 800/1000 [1:09:34<16:41,  5.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint: 800 queries, 2,398 triplets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 900/1000 [1:17:54<08:21,  5.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint: 900 queries, 2,697 triplets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [1:26:13<00:00,  5.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checkpoint: 1000 queries, 2,995 triplets\n",
      "\n",
      "âœ“ Generated: 2,995 triplets\n",
      "  Queries: 1000\n",
      "  Triplets per query: 3\n",
      "  Failed: 0\n",
      "  Time: 86.2 minutes\n",
      "  Saved: data\\llm_classified_data\\llm_generated_negatives\\generated_negatives.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "FINAL DATASET\n",
      "============================================================\n",
      "Total triplets: 3,662\n",
      "  From classification: 667\n",
      "  From generation: 2,995 (3Ã— per query)\n",
      "\n",
      "Saved:\n",
      "  TSV: data\\llm_classified_data\\llm_final_training\\hard_negatives_final.tsv\n",
      "  CSV: data\\llm_classified_data\\llm_final_training\\hard_negatives_final.csv\n",
      "  PKL: data\\llm_classified_data\\llm_final_training\\hard_negatives_final.pkl\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 2: GENERATE LLM HARD NEGATIVES (3 per query)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import time\n",
    "import json\n",
    "from tqdm.auto import tqdm\n",
    "from typing import List\n",
    "\n",
    "# Filter to keep only hard negatives from classification\n",
    "hard_negatives_df = llm_classified_df[llm_classified_df['is_hard'] == True].copy()\n",
    "train_columns = ['query_text', 'gold_passage', 'hard_negative']\n",
    "hard_negatives_df = hard_negatives_df[train_columns]\n",
    "\n",
    "print(f\"\\nFiltered HARD negatives: {len(hard_negatives_df):,}\")\n",
    "\n",
    "# Setup directories\n",
    "GENERATED_DIR = os.path.join(DATA_DIR, \"llm_classified_data\", \"llm_generated_negatives\")\n",
    "os.makedirs(GENERATED_DIR, exist_ok=True)\n",
    "\n",
    "# LLM Hard Negative Generator\n",
    "class LLMHardNegativeGenerator:\n",
    "    def __init__(self, classifier):\n",
    "        self.classifier = classifier\n",
    "    \n",
    "    def generate_negatives(self, query: str, positive_passage: str, num_negatives: int = 3) -> List[str]:\n",
    "        prompt = f\"\"\"Generate {num_negatives} HARD NEGATIVE passages for this query-passage pair.\n",
    "\n",
    "Query: {query}\n",
    "\n",
    "Correct Passage: {positive_passage[:200]}\n",
    "\n",
    "Requirements:\n",
    "1. Topically related to query\n",
    "2. Similar keywords as correct passage\n",
    "3. BUT does NOT answer the query\n",
    "4. Each 50-150 words\n",
    "5. Generate DIVERSE hard negatives (different types of wrongness)\n",
    "\n",
    "Output ONLY passages, numbered 1., 2., 3., etc.\"\"\"\n",
    "        \n",
    "        try:\n",
    "            response = self.classifier.call_ollama(prompt)\n",
    "            negatives = self._parse_response(response, num_negatives)\n",
    "            return negatives\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {str(e)[:50]}\")\n",
    "            return []\n",
    "    \n",
    "    def _parse_response(self, text: str, num_negatives: int) -> List[str]:\n",
    "        negatives = []\n",
    "        lines = text.split('\\n')\n",
    "        current = []\n",
    "        \n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            if line and any(line.startswith(f\"{i}.\") for i in range(1, 10)):\n",
    "                if current:\n",
    "                    negatives.append(' '.join(current))\n",
    "                    current = []\n",
    "                line = line.split('.', 1)[1].strip() if '.' in line else line\n",
    "            if line:\n",
    "                current.append(line)\n",
    "        \n",
    "        if current:\n",
    "            negatives.append(' '.join(current))\n",
    "        \n",
    "        return negatives[:num_negatives] if negatives else [text[:500]]\n",
    "\n",
    "# Initialize generator\n",
    "generator = LLMHardNegativeGenerator(llm_classifier)\n",
    "\n",
    "GENERATION_SIZE = DEV_SAMPLE_SIZE if DEV_MODE else len(msmarco_train_df)\n",
    "CHECKPOINT_INTERVAL = 100\n",
    "\n",
    "print(f\"\\nGenerating 3 negatives per query ({GENERATION_SIZE} queries)...\\n\")\n",
    "\n",
    "start_time = time.time()\n",
    "generated_data = []\n",
    "checkpoint_data = []\n",
    "failed_count = 0\n",
    "\n",
    "GENERATION_OUTPUT = os.path.join(GENERATED_DIR, \"generated_negatives.jsonl\")\n",
    "GENERATION_CSV = os.path.join(GENERATED_DIR, \"generated_negatives.csv\")\n",
    "\n",
    "for idx, row in enumerate(tqdm(msmarco_train_df.head(GENERATION_SIZE).iterrows(), total=GENERATION_SIZE, desc=\"Generating\"), 1):\n",
    "    _, row = row\n",
    "    query = row['query_text']\n",
    "    positive = row['gold_passage']\n",
    "    \n",
    "    # Generate 3 hard negatives per query\n",
    "    hard_negatives = generator.generate_negatives(query, positive, num_negatives=3)\n",
    "    \n",
    "    if hard_negatives:\n",
    "        for i, neg in enumerate(hard_negatives, 1):\n",
    "            item = {\n",
    "                'query_text': query,\n",
    "                'gold_passage': positive,\n",
    "                'hard_negative': neg,\n",
    "                'negative_num': i  # Track which negative (1, 2, or 3)\n",
    "            }\n",
    "            generated_data.append(item)\n",
    "            checkpoint_data.append(item)\n",
    "    else:\n",
    "        failed_count += 1\n",
    "    \n",
    "    # Save checkpoint every 100 queries\n",
    "    if idx % CHECKPOINT_INTERVAL == 0:\n",
    "        with open(GENERATION_OUTPUT, 'a') as f:\n",
    "            for item in checkpoint_data:\n",
    "                f.write(json.dumps(item) + '\\n')\n",
    "        print(f\"  Checkpoint: {idx} queries, {len(generated_data):,} triplets\")\n",
    "        checkpoint_data = []\n",
    "\n",
    "# Save remaining\n",
    "if checkpoint_data:\n",
    "    with open(GENERATION_OUTPUT, 'a') as f:\n",
    "        for item in checkpoint_data:\n",
    "            f.write(json.dumps(item) + '\\n')\n",
    "\n",
    "generated_df = pd.DataFrame(generated_data)\n",
    "generated_df.to_csv(GENERATION_CSV, index=False)\n",
    "\n",
    "print(f\"\\nâœ“ Generated: {len(generated_df):,} triplets\")\n",
    "print(f\"  Queries: {GENERATION_SIZE}\")\n",
    "print(f\"  Triplets per query: 3\")\n",
    "print(f\"  Failed: {failed_count}\")\n",
    "print(f\"  Time: {(time.time() - start_time)/60:.1f} minutes\")\n",
    "print(f\"  Saved: {GENERATION_CSV}\")\n",
    "\n",
    "# Combine classified + generated\n",
    "final_train_df = pd.concat([hard_negatives_df, generated_df], ignore_index=True)\n",
    "\n",
    "# Save final dataset\n",
    "FINAL_DIR = os.path.join(DATA_DIR, \"llm_classified_data\", \"llm_final_training\")\n",
    "os.makedirs(FINAL_DIR, exist_ok=True)\n",
    "\n",
    "FINAL_TSV = os.path.join(FINAL_DIR, \"hard_negatives_final.tsv\")\n",
    "FINAL_CSV = os.path.join(FINAL_DIR, \"hard_negatives_final.csv\")\n",
    "FINAL_PKL = os.path.join(FINAL_DIR, \"hard_negatives_final.pkl\")\n",
    "\n",
    "final_train_df.to_csv(FINAL_TSV, sep=\"\\t\", index=False)\n",
    "final_train_df.to_csv(FINAL_CSV, index=False)\n",
    "\n",
    "with open(FINAL_PKL, 'wb') as f:\n",
    "    pickle.dump(final_train_df, f)\n",
    "\n",
    "print(f\"\\n\" + \"=\"*60)\n",
    "print(\"FINAL DATASET\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total triplets: {len(final_train_df):,}\")\n",
    "print(f\"  From classification: {len(hard_negatives_df):,}\")\n",
    "print(f\"  From generation: {len(generated_df):,} (3Ã— per query)\")\n",
    "print(f\"\\nSaved:\")\n",
    "print(f\"  TSV: {FINAL_TSV}\")\n",
    "print(f\"  CSV: {FINAL_CSV}\")\n",
    "print(f\"  PKL: {FINAL_PKL}\")\n",
    "print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "760871f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "STEP 3: TRAIN DPR WITH LLM-ENHANCED DATA\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\TL1\\anaconda3\\envs\\mltorch\\lib\\site-packages\\torch\\__init__.py:1021: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead\n",
      "  return isinstance(obj, torch.Tensor)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ GPU memory cleared\n",
      "\n",
      "Loading training data from: data\\llm_classified_data\\llm_final_training\\hard_negatives_final.csv\n",
      "âœ“ Loaded 3,662 samples\n",
      "\n",
      "Training configuration:\n",
      "  Samples: 3,662\n",
      "  Epochs: 3\n",
      "  Batch size: 8\n",
      "  Learning rate: 5e-07\n",
      "\n",
      "Looking for Phase 1 model...\n",
      "  Found: ./models\\dpr_bm25_baseline_epoch5\n",
      "  âœ“ Loaded Phase 1 checkpoint\n",
      "\n",
      "Training data verification:\n",
      "  Columns: ['query_text', 'gold_passage', 'hard_negative', 'negative_num']\n",
      "  Shape: (3662, 4)\n",
      "\n",
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3662/3662 [00:01<00:00, 2949.75 examples/s]\n",
      "INFO:simpletransformers.retrieval.retrieval_model: Training started\n",
      "Epoch:   0%|          | 0/3 [00:00<?, ?it/s]INFO:simpletransformers.retrieval.retrieval_model:   Starting fine-tuning.\n",
      "c:\\Users\\TL1\\anaconda3\\envs\\mltorch\\lib\\site-packages\\simpletransformers\\retrieval\\retrieval_model.py:503: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = amp.GradScaler()\n",
      "Epoch 1 of 3:   0%|          | 0/3 [00:00<?, ?it/s]c:\\Users\\TL1\\anaconda3\\envs\\mltorch\\lib\\site-packages\\simpletransformers\\retrieval\\retrieval_model.py:534: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast():\n",
      "c:\\Users\\TL1\\anaconda3\\envs\\mltorch\\lib\\site-packages\\simpletransformers\\retrieval\\retrieval_model.py:1659: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  (max_idxs == torch.tensor(labels)).sum().cpu().detach().numpy().item()\n",
      "c:\\Users\\TL1\\anaconda3\\envs\\mltorch\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:224: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n",
      "Epochs 0/3. Running Loss:    3.1632 Correct count: 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 458/458 [09:18<00:00,  1.22s/it]\n",
      "Epochs 1/3. Running Loss:    2.5748 Correct count: 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 458/458 [09:15<00:00,  1.21s/it]\n",
      "Epochs 2/3. Running Loss:    1.6803 Correct count: 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 458/458 [11:28<00:00,  1.50s/it]\n",
      "Epoch 3 of 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [30:01<00:00, 600.62s/it]\n",
      "INFO:simpletransformers.retrieval.retrieval_model:Saving model into ./models\\dpr_llm_enhanced\n",
      "INFO:simpletransformers.retrieval.retrieval_model: Training of ./models\\dpr_bm25_baseline_epoch5 model complete. Saved to ./models\\dpr_llm_enhanced.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "PHASE 3 COMPLETE\n",
      "============================================================\n",
      "Model saved to: ./models\\dpr_llm_enhanced\n",
      "Training time: 30.1 minutes\n",
      "Samples: 3,662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\TL1\\anaconda3\\envs\\mltorch\\lib\\site-packages\\torch\\__init__.py:1021: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead\n",
      "  return isinstance(obj, torch.Tensor)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ GPU memory cleared\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 3: TRAIN DPR WITH LLM-ENHANCED DATA\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "import gc\n",
    "import time\n",
    "import torch\n",
    "import os\n",
    "\n",
    "clear_gpu_memory()\n",
    "\n",
    "# Configuration\n",
    "phase3_args = RetrievalArgs()\n",
    "phase3_args.data_format = \"beir\"\n",
    "phase3_args.hard_negatives = True\n",
    "phase3_args.num_train_epochs = 3\n",
    "phase3_args.train_batch_size = TRAIN_BATCH_SIZE\n",
    "phase3_args.learning_rate = 5e-7\n",
    "phase3_args.max_seq_length = MAX_SEQ_LENGTH\n",
    "phase3_args.output_dir = os.path.join(MODEL_DIR, \"dpr_llm_enhanced\")\n",
    "phase3_args.fp16 = USE_MIXED_PRECISION\n",
    "phase3_args.evaluate_during_training = False\n",
    "phase3_args.save_model_every_epoch = False\n",
    "phase3_args.overwrite_output_dir = True\n",
    "phase3_args.include_title = False\n",
    "\n",
    "# Load training data\n",
    "FINAL_TRAINING_CSV = os.path.join(DATA_DIR, \"llm_classified_data\", \"llm_final_training\", \"hard_negatives_final.csv\")\n",
    "\n",
    "print(f\"\\nLoading training data from: {FINAL_TRAINING_CSV}\")\n",
    "\n",
    "if os.path.exists(FINAL_TRAINING_CSV):\n",
    "    final_train_df = pd.read_csv(FINAL_TRAINING_CSV)\n",
    "    print(f\"âœ“ Loaded {len(final_train_df):,} samples\")\n",
    "else:\n",
    "    raise FileNotFoundError(f\"Training data not found at {FINAL_TRAINING_CSV}\")\n",
    "\n",
    "print(f\"\\nTraining configuration:\")\n",
    "print(f\"  Samples: {len(final_train_df):,}\")\n",
    "print(f\"  Epochs: {phase3_args.num_train_epochs}\")\n",
    "print(f\"  Batch size: {phase3_args.train_batch_size}\")\n",
    "print(f\"  Learning rate: {phase3_args.learning_rate}\")\n",
    "\n",
    "try:\n",
    "    # Look for Phase 1 model (CORRECT path)\n",
    "    print(\"\\nLooking for Phase 1 model...\")\n",
    "    \n",
    "    phase1_dir = os.path.join(MODEL_DIR, \"dpr_bm25_baseline_epoch5\")  # â† FIXED\n",
    "    \n",
    "    if os.path.exists(phase1_dir):\n",
    "        print(f\"  Found: {phase1_dir}\")\n",
    "        \n",
    "        dpr_model = RetrievalModel(\n",
    "            model_type=\"custom\",\n",
    "            model_name=phase1_dir,\n",
    "            args=phase3_args,\n",
    "            use_cuda=torch.cuda.is_available()\n",
    "        )\n",
    "        print(\"  âœ“ Loaded Phase 1 checkpoint\")\n",
    "    else:\n",
    "        print(f\"  Not found: {phase1_dir}\")\n",
    "        print(\"  Initializing from scratch...\")\n",
    "        \n",
    "        # Initialize from BASE_MODEL properly\n",
    "        dpr_model = RetrievalModel(\n",
    "            model_type=\"custom\",\n",
    "            model_name=None,  # â† None for new model\n",
    "            context_encoder_name=BASE_MODEL,  # â† Separate encoder names\n",
    "            query_encoder_name=BASE_MODEL,\n",
    "            args=phase3_args,\n",
    "            use_cuda=torch.cuda.is_available()\n",
    "        )\n",
    "        print(f\"  âœ“ Initialized with {BASE_MODEL}\")\n",
    "    \n",
    "    # Verify data\n",
    "    print(f\"\\nTraining data verification:\")\n",
    "    print(f\"  Columns: {final_train_df.columns.tolist()}\")\n",
    "    print(f\"  Shape: {final_train_df.shape}\")\n",
    "    \n",
    "    # Train\n",
    "    print(f\"\\nStarting training...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    dpr_model.train_model(final_train_df)\n",
    "    \n",
    "    training_time = time.time() - start_time\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"PHASE 3 COMPLETE\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Model saved to: {phase3_args.output_dir}\")\n",
    "    print(f\"Training time: {training_time/60:.1f} minutes\")\n",
    "    print(f\"Samples: {len(final_train_df):,}\")\n",
    "    \n",
    "    clear_gpu_memory()\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âœ— Training failed: {str(e)}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "12191e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "MODEL EVALUATION ON MS MARCO DEV SET\n",
      "============================================================\n",
      "\n",
      "Using device: cuda\n",
      "\n",
      "Loading models...\n",
      "âœ“ BM25 Model loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\TL1\\anaconda3\\envs\\mltorch\\lib\\site-packages\\torch\\__init__.py:1021: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead\n",
      "  return isinstance(obj, torch.Tensor)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ GPU memory cleared\n",
      "âœ“ LLM Model loaded\n",
      "Evaluation dataset: 7,437 query-passage pairs\n",
      "\n",
      "\n",
      "============================================================\n",
      "Evaluating: BM25 Baseline\n",
      "============================================================\n",
      "\n",
      "Using 300 samples (limited from 7437)\n",
      "Corpus size: 300 passages\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 300/300 [27:19<00:00,  5.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ GPU memory cleared\n",
      "\n",
      "============================================================\n",
      "Evaluating: LLM-Enhanced Model\n",
      "============================================================\n",
      "\n",
      "Using 300 samples (limited from 7437)\n",
      "Corpus size: 300 passages\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 300/300 [23:28<00:00,  4.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "EVALUATION RESULTS - COMPARISON\n",
      "============================================================\n",
      "\n",
      "   Metric BM25 Baseline LLM-Enhanced Improvement %\n",
      "   MRR@10        0.0259       0.0713       174.88%\n",
      "  nDCG@10        0.0346       0.1129       226.55%\n",
      " Recall@1        0.0133       0.0100       -25.00%\n",
      " Recall@5        0.0400       0.1500       275.00%\n",
      "Recall@10        0.0633       0.2500       294.74%\n",
      "\n",
      "============================================================\n",
      "SUMMARY\n",
      "============================================================\n",
      "\n",
      "Average Improvement: 189.23%\n",
      "âœ… LLM-Enhanced model is BETTER (189.23% improvement)\n",
      "\n",
      "âœ“ Results saved to ./models/phase3_comparison_results.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\TL1\\anaconda3\\envs\\mltorch\\lib\\site-packages\\torch\\__init__.py:1021: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead\n",
      "  return isinstance(obj, torch.Tensor)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ GPU memory cleared\n",
      "\n",
      "============================================================\n",
      "âœ… PHASE 3 EVALUATION COMPLETE\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MODEL EVALUATION ON MS MARCO DEV SET\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"\\nUsing device: {device}\")\n",
    "\n",
    "# Model paths\n",
    "bm25_model_path = f\"{MODEL_DIR}/dpr_bm25_baseline_epoch5\"\n",
    "llm_model_path = f\"{MODEL_DIR}/dpr_llm_enhanced\"\n",
    "\n",
    "# Load eval args\n",
    "eval_args = RetrievalArgs()\n",
    "eval_args.data_format = \"beir\"\n",
    "eval_args.max_seq_length = 256\n",
    "eval_args.include_title = False\n",
    "eval_args.hard_negatives = False\n",
    "eval_args.fp16 = USE_MIXED_PRECISION\n",
    "\n",
    "print(f\"\\nLoading models...\")\n",
    "\n",
    "# Load models\n",
    "bm25_model = RetrievalModel(\n",
    "    model_type=\"custom\",\n",
    "    model_name=bm25_model_path,\n",
    "    args=eval_args,\n",
    "    use_cuda=torch.cuda.is_available()\n",
    ")\n",
    "bm25_model.query_encoder = bm25_model.query_encoder.to(device)\n",
    "bm25_model.context_encoder = bm25_model.context_encoder.to(device)\n",
    "print(f\"âœ“ BM25 Model loaded\")\n",
    "\n",
    "clear_gpu_memory()\n",
    "\n",
    "llm_model = RetrievalModel(\n",
    "    model_type=\"custom\",\n",
    "    model_name=llm_model_path,\n",
    "    args=eval_args,\n",
    "    use_cuda=torch.cuda.is_available()\n",
    ")\n",
    "llm_model.query_encoder = llm_model.query_encoder.to(device)\n",
    "llm_model.context_encoder = llm_model.context_encoder.to(device)\n",
    "print(f\"âœ“ LLM Model loaded\")\n",
    "\n",
    "# ============================================================\n",
    "# EVALUATE BOTH MODELS \n",
    "# ============================================================\n",
    "\n",
    "try:\n",
    "    print(f\"Evaluation dataset: {len(msmarco_dev):,} query-passage pairs\\n\")\n",
    "    \n",
    "    # Evaluate BM25 Model\n",
    "    bm25_results = evaluate_dpr_model(\n",
    "        bm25_model, \n",
    "        msmarco_dev, \n",
    "        \"BM25 Baseline\", \n",
    "        device,\n",
    "        max_samples=300  # Evaluate on 50 samples for speed\n",
    "    )\n",
    "    \n",
    "    clear_gpu_memory()\n",
    "    \n",
    "    # Evaluate LLM-Enhanced Model\n",
    "    llm_results = evaluate_dpr_model(\n",
    "        llm_model, \n",
    "        msmarco_dev, \n",
    "        \"LLM-Enhanced Model\", \n",
    "        device,\n",
    "        max_samples=300  # Same 50 samples for fair comparison\n",
    "    )\n",
    "    \n",
    "    # ============================================================\n",
    "    # Display Results\n",
    "    # ============================================================\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"EVALUATION RESULTS - COMPARISON\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    results_df = pd.DataFrame({\n",
    "        \"Metric\": list(bm25_results.keys()),\n",
    "        \"BM25 Baseline\": [f\"{bm25_results[k]:.4f}\" for k in bm25_results.keys()],\n",
    "        \"LLM-Enhanced\": [f\"{llm_results[k]:.4f}\" for k in llm_results.keys()],\n",
    "        \"Improvement %\": [\n",
    "            f\"{((llm_results[k] - bm25_results[k])/max(bm25_results[k], 0.0001) * 100):.2f}%\"\n",
    "            for k in bm25_results.keys()\n",
    "        ]\n",
    "    })\n",
    "    \n",
    "    print(\"\\n\" + results_df.to_string(index=False))\n",
    "    \n",
    "    # Summary\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"SUMMARY\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    avg_improvement = np.mean([\n",
    "        ((llm_results[k] - bm25_results[k])/max(bm25_results[k], 0.0001) * 100)\n",
    "        for k in bm25_results.keys()\n",
    "    ])\n",
    "    \n",
    "    print(f\"\\nAverage Improvement: {avg_improvement:.2f}%\")\n",
    "    \n",
    "    if avg_improvement > 0:\n",
    "        print(f\"âœ… LLM-Enhanced model is BETTER ({avg_improvement:.2f}% improvement)\")\n",
    "    else:\n",
    "        print(f\"âš ï¸  BM25 model performs better ({abs(avg_improvement):.2f}% better)\")\n",
    "    \n",
    "    # Save results\n",
    "    import json\n",
    "    results_summary = {\n",
    "        \"BM25\": bm25_results,\n",
    "        \"LLM-Enhanced\": llm_results,\n",
    "        \"Improvement %\": {\n",
    "            k: ((llm_results[k] - bm25_results[k])/max(bm25_results[k], 0.0001) * 100)\n",
    "            for k in bm25_results.keys()\n",
    "        },\n",
    "        \"Average Improvement %\": avg_improvement\n",
    "    }\n",
    "    \n",
    "    results_path = f\"{MODEL_DIR}/phase3_comparison_results.json\"\n",
    "    with open(results_path, 'w') as f:\n",
    "        json.dump(results_summary, f, indent=2)\n",
    "    print(f\"\\nâœ“ Results saved to {results_path}\")\n",
    "    \n",
    "    # Clear GPU\n",
    "    clear_gpu_memory()\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"âœ… PHASE 3 EVALUATION COMPLETE\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\nâŒ Error: {str(e)}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e641ebf1",
   "metadata": {},
   "source": [
    "## Phase 4 - RAG Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "94f16ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ FAISS already installed\n",
      "  FAISS version: 1.12.0\n"
     ]
    }
   ],
   "source": [
    "# Install FAISS for dense retrieval\n",
    "\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "try:\n",
    "    import faiss\n",
    "    print(\"âœ“ FAISS already installed\")\n",
    "except ImportError:\n",
    "    print(\"Installing FAISS...\")\n",
    "    # Use CPU version for compatibility\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"faiss-cpu\"])\n",
    "    import faiss\n",
    "    print(\"âœ“ FAISS installed\")\n",
    "\n",
    "print(f\"  FAISS version: {faiss.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "a5858e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: bert-base-multilingual-cased\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Building RAG Retrieval Index from LLM-Processed Negatives\n",
      "============================================================\n",
      "\n",
      "=== Loading LLM-Processed Dataset ===\n",
      "\n",
      "Loading: data\\llm_classified_data\\llm_final_training\\hard_negatives_final.csv\n",
      "âœ“ Loaded: 3,662 samples\n",
      "  Columns: ['query_text', 'gold_passage', 'hard_negative', 'negative_num']\n",
      "  Sample query: what are the liberal arts?...\n",
      "\n",
      "=== Building Passage Corpus ===\n",
      "\n",
      "âœ“ Corpus size: 2,375 unique hard negatives\n",
      "\n",
      "=== Encoding Passage Corpus ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sentence_transformers.SentenceTransformer:No sentence-transformers model found with name bert-base-multilingual-cased. Creating a new one with MEAN pooling.\n",
      "c:\\Users\\TL1\\anaconda3\\envs\\mltorch\\lib\\site-packages\\huggingface_hub\\file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Encoder loaded: bert-base-multilingual-cased\n",
      "Encoding in batches of 32...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 75/75 [00:10<00:00,  7.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ“ Encoded: 2375 passages\n",
      "  Dimension: 768\n",
      "\n",
      "=== Building FAISS Index ===\n",
      "\n",
      "âœ“ Index built: 2,375 passages\n",
      "\n",
      "=== Saving RAG Index ===\n",
      "\n",
      "âœ“ FAISS index: ./models\\rag_index\\rag_corpus_index.faiss\n",
      "âœ“ Corpus: ./models\\rag_index\\rag_corpus_passages.pkl\n",
      "âœ“ Metadata: ./models\\rag_index\\rag_index_metadata.json\n",
      "\n",
      "============================================================\n",
      "RAG INDEX READY FOR PHASE 4\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\TL1\\anaconda3\\envs\\mltorch\\lib\\site-packages\\torch\\__init__.py:1021: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead\n",
      "  return isinstance(obj, torch.Tensor)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ GPU memory cleared\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Building RAG Retrieval Index from LLM-Processed Negatives\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "import faiss\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm.auto import tqdm\n",
    "import pickle\n",
    "import json\n",
    "import torch\n",
    "import gc\n",
    "\n",
    "print(\"\\n=== Loading LLM-Processed Dataset ===\\n\")\n",
    "\n",
    "# Load from correct path\n",
    "FINAL_CSV = os.path.join(DATA_DIR, \"llm_classified_data\", \"llm_final_training\", \"hard_negatives_final.csv\")\n",
    "\n",
    "if os.path.exists(FINAL_CSV):\n",
    "    print(f\"Loading: {FINAL_CSV}\")\n",
    "    hard_negatives_df = pd.read_csv(FINAL_CSV)\n",
    "    print(f\"âœ“ Loaded: {len(hard_negatives_df):,} samples\")\n",
    "else:\n",
    "    raise FileNotFoundError(\n",
    "        f\"LLM-processed data not found!\\n\"\n",
    "        f\"Expected: {FINAL_CSV}\\n\"\n",
    "        f\"Please run Phase 2-3 first.\"\n",
    "    )\n",
    "\n",
    "print(f\"  Columns: {hard_negatives_df.columns.tolist()}\")\n",
    "print(f\"  Sample query: {hard_negatives_df.iloc[0]['query_text'][:60]}...\")\n",
    "\n",
    "# ============================================================\n",
    "# Build Corpus from Hard Negatives\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n=== Building Passage Corpus ===\\n\")\n",
    "\n",
    "corpus_passages = hard_negatives_df['hard_negative'].dropna().unique().tolist()\n",
    "print(f\"âœ“ Corpus size: {len(corpus_passages):,} unique hard negatives\")\n",
    "\n",
    "# ============================================================\n",
    "# Encode Corpus Using Sentence Transformers\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n=== Encoding Passage Corpus ===\\n\")\n",
    "\n",
    "rag_encoder = SentenceTransformer(BASE_MODEL)\n",
    "rag_encoder.eval()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "rag_encoder.to(device)\n",
    "print(f\"âœ“ Encoder loaded: {BASE_MODEL}\")\n",
    "\n",
    "# Encode in batches\n",
    "batch_size = 32\n",
    "all_embeddings = []\n",
    "\n",
    "print(f\"Encoding in batches of {batch_size}...\\n\")\n",
    "\n",
    "for i in tqdm(range(0, len(corpus_passages), batch_size), desc=\"Encoding\"):\n",
    "    batch_end = min(i + batch_size, len(corpus_passages))\n",
    "    batch = corpus_passages[i:batch_end]\n",
    "    \n",
    "    try:\n",
    "        with torch.no_grad():\n",
    "            embeddings = rag_encoder.encode(\n",
    "                batch,\n",
    "                convert_to_numpy=True,\n",
    "                show_progress_bar=False,\n",
    "                batch_size=batch_size\n",
    "            )\n",
    "        all_embeddings.append(embeddings)\n",
    "    except Exception as e:\n",
    "        print(f\"Error encoding batch {i}-{batch_end}: {e}\")\n",
    "        continue\n",
    "\n",
    "if not all_embeddings:\n",
    "    raise RuntimeError(\"No embeddings generated!\")\n",
    "\n",
    "corpus_embeddings = np.vstack(all_embeddings)\n",
    "print(f\"\\nâœ“ Encoded: {corpus_embeddings.shape[0]} passages\")\n",
    "print(f\"  Dimension: {corpus_embeddings.shape[1]}\")\n",
    "\n",
    "# ============================================================\n",
    "# Build and Save FAISS Index\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n=== Building FAISS Index ===\\n\")\n",
    "\n",
    "embedding_dim = corpus_embeddings.shape[1]\n",
    "index = faiss.IndexFlatIP(embedding_dim)\n",
    "\n",
    "# Normalize for cosine similarity\n",
    "faiss.normalize_L2(corpus_embeddings)\n",
    "index.add(corpus_embeddings.astype('float32'))\n",
    "\n",
    "print(f\"âœ“ Index built: {index.ntotal:,} passages\")\n",
    "\n",
    "# ============================================================\n",
    "# Save Index and Corpus\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n=== Saving RAG Index ===\\n\")\n",
    "\n",
    "RAG_DIR = os.path.join(MODEL_DIR, \"rag_index\")\n",
    "os.makedirs(RAG_DIR, exist_ok=True)\n",
    "\n",
    "# Save FAISS index\n",
    "index_path = os.path.join(RAG_DIR, \"rag_corpus_index.faiss\")\n",
    "faiss.write_index(index, index_path)\n",
    "print(f\"âœ“ FAISS index: {index_path}\")\n",
    "\n",
    "# Save corpus passages\n",
    "corpus_path = os.path.join(RAG_DIR, \"rag_corpus_passages.pkl\")\n",
    "with open(corpus_path, \"wb\") as f:\n",
    "    pickle.dump(corpus_passages, f)\n",
    "print(f\"âœ“ Corpus: {corpus_path}\")\n",
    "\n",
    "# Save metadata\n",
    "metadata = {\n",
    "    \"corpus_type\": \"LLM-processed hard negatives\",\n",
    "    \"corpus_size\": len(corpus_passages),\n",
    "    \"embedding_model\": BASE_MODEL,\n",
    "    \"embedding_dim\": embedding_dim,\n",
    "    \"source_file\": FINAL_CSV,\n",
    "    \"timestamp\": pd.Timestamp.now().isoformat()\n",
    "}\n",
    "\n",
    "metadata_path = os.path.join(RAG_DIR, \"rag_index_metadata.json\")\n",
    "with open(metadata_path, 'w') as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "\n",
    "print(f\"âœ“ Metadata: {metadata_path}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RAG INDEX READY FOR PHASE 4\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "clear_gpu_memory()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "6be2ca0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: bert-base-multilingual-cased\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Initializing RAG Context Retriever\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Initializing RAG Context Retriever\n",
      "============================================================\n",
      "\n",
      "=== Loading RAG Components ===\n",
      "\n",
      "âœ“ FAISS index: rag_corpus_index.faiss\n",
      "  Size: 2,375 passages\n",
      "âœ“ Corpus: rag_corpus_passages.pkl\n",
      "  Size: 2,375 passages\n",
      "âœ“ Encoder: bert-base-multilingual-cased\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sentence_transformers.SentenceTransformer:No sentence-transformers model found with name bert-base-multilingual-cased. Creating a new one with MEAN pooling.\n",
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ“ Retriever initialized on cuda\n",
      "\n",
      "âœ… RAG Retriever Ready!\n",
      "\n",
      "=== Testing Retrieval ===\n",
      "\n",
      "Query: What is machine learning?\n",
      "  1. Score: 0.5760 | Passage: Thrashers font? Never heard of it. I'm more concerned about the enviro...\n",
      "  2. Score: 0.5562 | Passage: I can't provide content that promotes or glorifies illegal activities ...\n",
      "  3. Score: 0.5504 | Passage: I cannot generate content that promotes or glorifies nudity or explici...\n",
      "\n",
      "Query: How does deep learning work?\n",
      "  1. Score: 0.6165 | Passage: Thrashers font? Never heard of it. I'm more concerned about the enviro...\n",
      "  2. Score: 0.6094 | Passage: The cost of breast implants is just one aspect to consider when thinki...\n",
      "  3. Score: 0.6085 | Passage: As we all know, Electronic Data Interchange is a crucial aspect of mod...\n",
      "\n",
      "Query: What are neural networks?\n",
      "  1. Score: 0.5649 | Passage: The development of artificial intelligence has led to significant adva...\n",
      "  2. Score: 0.5463 | Passage: As we all know, Electronic Data Interchange is a crucial aspect of mod...\n",
      "  3. Score: 0.5455 | Passage: Trait theory is a concept in physics that describes the behavior of su...\n",
      "\n",
      "============================================================\n",
      "RAG Retriever initialized successfully!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Initializing RAG Context Retriever\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import faiss\n",
    "import numpy as np\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "class RAGContextRetriever:\n",
    "    \"\"\"Retrieve context passages using FAISS\"\"\"\n",
    "    \n",
    "    def __init__(self, index_path, corpus_path, model_name=None, device=None):\n",
    "        self.device = device or torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        \n",
    "        print(f\"\\n=== Loading RAG Components ===\\n\")\n",
    "        \n",
    "        # Validate files exist\n",
    "        if not os.path.exists(index_path):\n",
    "            raise FileNotFoundError(f\"Index not found: {index_path}\")\n",
    "        if not os.path.exists(corpus_path):\n",
    "            raise FileNotFoundError(f\"Corpus not found: {corpus_path}\")\n",
    "        \n",
    "        # Load FAISS index\n",
    "        self.index = faiss.read_index(index_path)\n",
    "        print(f\"âœ“ FAISS index: {os.path.basename(index_path)}\")\n",
    "        print(f\"  Size: {self.index.ntotal:,} passages\")\n",
    "        \n",
    "        # Load corpus\n",
    "        with open(corpus_path, 'rb') as f:\n",
    "            self.corpus = pickle.load(f)\n",
    "        print(f\"âœ“ Corpus: {os.path.basename(corpus_path)}\")\n",
    "        print(f\"  Size: {len(self.corpus):,} passages\")\n",
    "        \n",
    "        # Load encoder\n",
    "        if model_name is None:\n",
    "            model_name = BASE_MODEL\n",
    "        \n",
    "        print(f\"âœ“ Encoder: {model_name}\")\n",
    "        self.encoder = SentenceTransformer(model_name)\n",
    "        self.encoder.eval()\n",
    "        self.encoder.to(self.device)\n",
    "        \n",
    "        print(f\"\\nâœ“ Retriever initialized on {self.device}\")\n",
    "    \n",
    "    def retrieve_context(self, query, top_k=5):\n",
    "        \"\"\"Retrieve top-k context passages for a query\"\"\"\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            query_emb = self.encoder.encode(\n",
    "                query,\n",
    "                convert_to_numpy=True,\n",
    "                show_progress_bar=False\n",
    "            )\n",
    "        \n",
    "        # Normalize for cosine similarity\n",
    "        query_emb_normalized = query_emb / (np.linalg.norm(query_emb) + 1e-8)\n",
    "        query_emb_normalized = query_emb_normalized.reshape(1, -1).astype('float32')\n",
    "        \n",
    "        # Search FAISS index\n",
    "        scores, indices = self.index.search(query_emb_normalized, top_k)\n",
    "        \n",
    "        # Build results\n",
    "        contexts = []\n",
    "        for idx, score in zip(indices[0], scores[0]):\n",
    "            if 0 <= idx < len(self.corpus):\n",
    "                contexts.append({\n",
    "                    'passage': self.corpus[idx],\n",
    "                    'score': float(score),\n",
    "                    'idx': int(idx)\n",
    "                })\n",
    "        \n",
    "        return contexts\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Initialize RAG Retriever\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Initializing RAG Context Retriever\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "try:\n",
    "    # Use CORRECT paths from Cell 26\n",
    "    RAG_DIR = os.path.join(MODEL_DIR, \"rag_index\")\n",
    "    index_path = os.path.join(RAG_DIR, \"rag_corpus_index.faiss\")\n",
    "    corpus_path = os.path.join(RAG_DIR, \"rag_corpus_passages.pkl\")\n",
    "    \n",
    "    # Verify files exist\n",
    "    if not os.path.exists(RAG_DIR):\n",
    "        raise FileNotFoundError(f\"RAG directory not found: {RAG_DIR}\\nRun Cell 26 first!\")\n",
    "    \n",
    "    rag_retriever = RAGContextRetriever(\n",
    "        index_path=index_path,\n",
    "        corpus_path=corpus_path,\n",
    "        model_name=BASE_MODEL,\n",
    "        device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    )\n",
    "    \n",
    "    print(\"\\nâœ… RAG Retriever Ready!\\n\")\n",
    "    \n",
    "    # Test retrieval\n",
    "    print(\"=== Testing Retrieval ===\\n\")\n",
    "    \n",
    "    test_queries = [\n",
    "        \"What is machine learning?\",\n",
    "        \"How does deep learning work?\",\n",
    "        \"What are neural networks?\"\n",
    "    ]\n",
    "    \n",
    "    for test_query in test_queries:\n",
    "        print(f\"Query: {test_query}\")\n",
    "        contexts = rag_retriever.retrieve_context(test_query, top_k=3)\n",
    "        \n",
    "        for i, ctx in enumerate(contexts, 1):\n",
    "            print(f\"  {i}. Score: {ctx['score']:.4f} | Passage: {ctx['passage'][:70]}...\")\n",
    "        print()\n",
    "    \n",
    "except FileNotFoundError as e:\n",
    "    print(f\"\\nâœ— File error: {e}\")\n",
    "    print(\"  Make sure Cell 26 (Build RAG Index) completed successfully!\")\n",
    "    raise\n",
    "except Exception as e:\n",
    "    print(f\"\\nâœ— Error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    raise\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"RAG Retriever initialized successfully!\")\n",
    "print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "a4e9cacf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Testing with Training Queries ===\n",
      "\n",
      "Query: what are the liberal arts?...\n",
      "Gold (correct): liberal arts. 1. the academic course of instruction at a col...\n",
      "Hard Neg (in corpus): What Are Hormones, And What Do They Do? Hormones are special...\n",
      "\n",
      "Retrieved:\n",
      "  1. Score: 0.6167 | Thrashers font? Never heard of it. I'm more concerned about ...\n",
      "  2. Score: 0.5918 | As we all know, Electronic Data Interchange is a crucial asp...\n",
      "  3. Score: 0.5905 | I cannot generate content that promotes or glorifies nudity ...\n",
      "\n",
      "Query: what is the mechanism of action of fibrinolytic or thromboly...\n",
      "Gold (correct): BailliÃƒÂ¨re's Clinical Haematology. 6 Mechanism of action of ...\n",
      "Hard Neg (in corpus): Here is the video of claw mechanism animation. This is a spa...\n",
      "\n",
      "Retrieved:\n",
      "  1. Score: 0.7906 | The mechanism of action of fibrinolytic or thrombolytic drug...\n",
      "  2. Score: 0.7339 | The FDA has rejected Pfizer's application for a new medicati...\n",
      "  3. Score: 0.7318 | The thrombolytic agents have been shown to be effective in t...\n",
      "\n",
      "Query: dollar cost averaging explained...\n",
      "Gold (correct): Dollar-cost averaging is simply a method of purchasing share...\n",
      "Hard Neg (in corpus): Family Dollar. Family Dollar Stores Inc. is an American vari...\n",
      "\n",
      "Retrieved:\n",
      "  1. Score: 0.5357 | The exchange rate between the US dollar and the Japanese yen...\n",
      "  2. Score: 0.5347 | That leads us to income taxes. Income tax rates. The top inc...\n",
      "  3. Score: 0.5218 | The salary of a certified medical interpreter is not directl...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test with real training queries\n",
    "print(\"\\n=== Testing with Training Queries ===\\n\")\n",
    "\n",
    "for idx in range(3):\n",
    "    row = final_train_df.iloc[idx]\n",
    "    query = row['query_text']\n",
    "    gold = row['gold_passage']\n",
    "    hard_neg = row['hard_negative']\n",
    "    \n",
    "    contexts = rag_retriever.retrieve_context(query, top_k=3)\n",
    "    \n",
    "    print(f\"Query: {query[:60]}...\")\n",
    "    print(f\"Gold (correct): {gold[:60]}...\")\n",
    "    print(f\"Hard Neg (in corpus): {hard_neg[:60]}...\")\n",
    "    print(f\"\\nRetrieved:\")\n",
    "    for i, ctx in enumerate(contexts, 1):\n",
    "        print(f\"  {i}. Score: {ctx['score']:.4f} | {ctx['passage'][:60]}...\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "870b7f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Initializing RAG Negative Ranker\n",
      "============================================================\n",
      "\n",
      "Initializing RAG Ranker...\n",
      "âœ“ RAG Negative Ranker initialized with caching\n",
      "âœ… RAG Ranker ready!\n",
      "\n",
      "=== Testing RAG Ranker ===\n",
      "\n",
      "\n",
      "Scoring 3 negatives with RAG context...\n",
      "Cache size: 0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RAG Scoring: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:15<00:00,  5.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ“ Scoring complete!\n",
      "  Computed: 3\n",
      "  Cached: 0\n",
      "  Errors: 0\n",
      "  Cache size: 3\n",
      "\n",
      "Test Results:\n",
      "                                                               query_text  rag_score\n",
      "0                                              what are the liberal arts?       0.50\n",
      "1  what is the mechanism of action of fibrinolytic or thrombolytic drugs?       0.85\n",
      "2                                         dollar cost averaging explained       0.40\n",
      "\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Initializing RAG Negative Ranker\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "import hashlib\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "class RAGNegativeRanker:\n",
    "    \"\"\"Score negatives using LLM with RAG context\"\"\"\n",
    "    \n",
    "    def __init__(self, rag_retriever, llm_classifier):\n",
    "        self.rag_retriever = rag_retriever\n",
    "        self.llm_classifier = llm_classifier\n",
    "        self.score_cache = {}\n",
    "        self.stats = {\n",
    "            'cached': 0,\n",
    "            'computed': 0,\n",
    "            'errors': 0\n",
    "        }\n",
    "        \n",
    "        print(\"âœ“ RAG Negative Ranker initialized with caching\")\n",
    "    \n",
    "    def _get_cache_key(self, query, gold, negative):\n",
    "        \"\"\"Create deterministic cache key\"\"\"\n",
    "        text = f\"{query[:100]}|{gold[:100]}|{negative[:100]}\"\n",
    "        return hashlib.md5(text.encode()).hexdigest()\n",
    "    \n",
    "    def score_negative_with_context(self, query, gold_passage, negative_passage, top_k_context=3):\n",
    "        \"\"\"Score negative with RAG-enhanced context\"\"\"\n",
    "        \n",
    "        # Check cache first\n",
    "        cache_key = self._get_cache_key(query, gold_passage, negative_passage)\n",
    "        if cache_key in self.score_cache:\n",
    "            self.stats['cached'] += 1\n",
    "            return self.score_cache[cache_key]\n",
    "        \n",
    "        try:\n",
    "            # Retrieve relevant context\n",
    "            contexts = self.rag_retriever.retrieve_context(query, top_k=top_k_context)\n",
    "            context_str = \"\\n\".join([f\"â€¢ {c['passage'][:120]}\" for c in contexts[:top_k_context]])\n",
    "            \n",
    "            # Enhance query with context\n",
    "            enhanced_query = f\"Query: {query}\\n\\nContext:\\n{context_str}\"\n",
    "            \n",
    "            # Use LLM classifier\n",
    "            result = self.llm_classifier.classify_negative(\n",
    "                query=enhanced_query,\n",
    "                gold_passage=gold_passage,\n",
    "                negative_passage=negative_passage\n",
    "            )\n",
    "            \n",
    "            # Extract score\n",
    "            is_hard = result.get('is_hard', False)\n",
    "            hardness_score = result.get('hardness_score', 0.5)\n",
    "            \n",
    "            # Final score: use hardness_score from LLM\n",
    "            final_score = hardness_score\n",
    "            \n",
    "            # Cache it\n",
    "            self.score_cache[cache_key] = final_score\n",
    "            self.stats['computed'] += 1\n",
    "            \n",
    "            return final_score\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.stats['errors'] += 1\n",
    "            print(f\"  Error: {str(e)[:50]}\")\n",
    "            return 0.5  # Default middle score on error\n",
    "    \n",
    "    def score_batch(self, negatives_df, top_k_context=3, max_samples=None):\n",
    "        \"\"\"Score batch of negatives with RAG\"\"\"\n",
    "        \n",
    "        samples = negatives_df.head(max_samples) if max_samples else negatives_df\n",
    "        results = []\n",
    "        \n",
    "        print(f\"\\nScoring {len(samples)} negatives with RAG context...\")\n",
    "        print(f\"Cache size: {len(self.score_cache)}\\n\")\n",
    "        \n",
    "        for idx, row in tqdm(samples.iterrows(), total=len(samples), desc=\"RAG Scoring\"):\n",
    "            try:\n",
    "                score = self.score_negative_with_context(\n",
    "                    query=row.get('query_text', ''),\n",
    "                    gold_passage=row.get('gold_passage', ''),\n",
    "                    negative_passage=row.get('hard_negative', ''),\n",
    "                    top_k_context=top_k_context\n",
    "                )\n",
    "                \n",
    "                results.append({\n",
    "                    'query_text': row['query_text'],\n",
    "                    'gold_passage': row['gold_passage'],\n",
    "                    'hard_negative': row['hard_negative'],\n",
    "                    'rag_score': score\n",
    "                })\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"  Skipping sample {idx}: {str(e)[:40]}\")\n",
    "                continue\n",
    "        \n",
    "        # Print stats\n",
    "        print(f\"\\nâœ“ Scoring complete!\")\n",
    "        print(f\"  Computed: {self.stats['computed']}\")\n",
    "        print(f\"  Cached: {self.stats['cached']}\")\n",
    "        print(f\"  Errors: {self.stats['errors']}\")\n",
    "        print(f\"  Cache size: {len(self.score_cache)}\")\n",
    "        \n",
    "        return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Initialize RAG Ranker\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\nInitializing RAG Ranker...\")\n",
    "\n",
    "try:\n",
    "    rag_ranker = RAGNegativeRanker(rag_retriever, llm_classifier)\n",
    "    print(\"âœ… RAG Ranker ready!\\n\")\n",
    "    \n",
    "    # Test on small batch\n",
    "    print(\"=== Testing RAG Ranker ===\\n\")\n",
    "    \n",
    "    test_batch = hard_negatives_df.head(3).copy()  # Use real data\n",
    "    test_results = rag_ranker.score_batch(test_batch, top_k_context=3)\n",
    "    \n",
    "    print(\"\\nTest Results:\")\n",
    "    print(test_results[['query_text', 'rag_score']].to_string())\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\nâœ— Error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    raise\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "a7ff25aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Applying RAG Ranking to All Data\n",
      "============================================================\n",
      "\n",
      "Ranking 1000 hard negatives with RAG...\n",
      "DEV_MODE: True | Processing: 1,000 samples\n",
      "\n",
      "\n",
      "Scoring 1000 negatives with RAG context...\n",
      "Cache size: 36\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RAG Scoring:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 750/1000 [30:55<14:12,  3.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Warning: Could not parse '58\n",
      "\n",
      "THIS PASSAGE REQUIRES SOME SEMANTIC UNDERSTANDING TO DISTINGUISH IT FROM THE GOLD PASSAGE, AS IT PRESENTS A NUANCED AND COMPLEX VIEW OF CANINE GESTATION. HOWEVER, IT'S NOT ENTIRELY FACTUALLY DIFFERENT OR TOPICALLY RELATED IN A CONFUSING WAY, WHICH IS WHY I WOULDN'T RATE IT ABOVE 70.', defaulting to 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RAG Scoring: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [41:33<00:00,  2.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ“ Scoring complete!\n",
      "  Computed: 1000\n",
      "  Cached: 58\n",
      "  Errors: 0\n",
      "  Cache size: 1000\n",
      "\n",
      "âœ“ Scoring completed in 41.6 minutes\n",
      "\n",
      "=== RAG Score Distribution ===\n",
      "  Total scored: 1,000\n",
      "  Mean: 0.6639\n",
      "  Std:  0.1451\n",
      "  Min:  0.0500\n",
      "  Max:  0.9500\n",
      "  Median: 0.6500\n",
      "\n",
      "=== Score Breakdown ===\n",
      "  Hard (>0.6): 534 (53.4%)\n",
      "  Medium (0.4-0.6): 451 (45.1%)\n",
      "  Easy (<0.4): 15 (1.5%)\n",
      "\n",
      "=== Negative Selection ===\n",
      "  Quality percentile: 50%\n",
      "  Selection threshold: 0.6500\n",
      "\n",
      "âœ“ Selected 533 high-quality negatives\n",
      "  Original: 1,000\n",
      "  Selected: 533 (53.3%)\n",
      "\n",
      "Top 5 highest quality:\n",
      "  Score: 0.9500 | Query: how many calories are equal to a pound...\n",
      "  Score: 0.8500 | Query: what county is conway arkansas in...\n",
      "  Score: 0.8500 | Query: what minimum standard is for temp silt f...\n",
      "  Score: 0.8500 | Query: what percentage of small business provid...\n",
      "  Score: 0.8500 | Query: meaning of append...\n",
      "\n",
      "Bottom 5 of selected:\n",
      "  Score: 0.6500 | Query: what is the igil...\n",
      "  Score: 0.6500 | Query: find phone number for irs...\n",
      "  Score: 0.6500 | Query: cost of replacing brake pads on kia soul...\n",
      "  Score: 0.6500 | Query: what is the igil...\n",
      "  Score: 0.6500 | Query: what county is mcewen, tn in...\n",
      "\n",
      "=== Saving RAG-Selected Negatives ===\n",
      "\n",
      "âœ“ Full ranked: data\\llm_classified_data\\rag_selected_negatives\\all_ranked_with_scores.csv\n",
      "âœ“ Selected: data\\llm_classified_data\\rag_selected_negatives\\selected_high_quality.csv\n",
      "âœ“ Metadata: data\\llm_classified_data\\rag_selected_negatives\\rag_selection_metadata.json\n",
      "\n",
      "============================================================\n",
      "RAG RANKING COMPLETE\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Applying RAG Ranking to All Data\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Use ALL data or limited by DEV_MODE\n",
    "RAG_SAMPLE_SIZE = 1000 if DEV_MODE else len(hard_negatives_df)\n",
    "rag_input = hard_negatives_df.head(RAG_SAMPLE_SIZE).copy()\n",
    "\n",
    "print(f\"\\nRanking {len(rag_input)} hard negatives with RAG...\")\n",
    "print(f\"DEV_MODE: {DEV_MODE} | Processing: {len(rag_input):,} samples\\n\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Apply RAG scoring\n",
    "rag_ranked = rag_ranker.score_batch(rag_input, top_k_context=3)\n",
    "\n",
    "scoring_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\nâœ“ Scoring completed in {scoring_time/60:.1f} minutes\")\n",
    "\n",
    "# ============================================================\n",
    "# Analyze Score Distribution\n",
    "# ============================================================\n",
    "\n",
    "print(f\"\\n=== RAG Score Distribution ===\")\n",
    "print(f\"  Total scored: {len(rag_ranked):,}\")\n",
    "print(f\"  Mean: {rag_ranked['rag_score'].mean():.4f}\")\n",
    "print(f\"  Std:  {rag_ranked['rag_score'].std():.4f}\")\n",
    "print(f\"  Min:  {rag_ranked['rag_score'].min():.4f}\")\n",
    "print(f\"  Max:  {rag_ranked['rag_score'].max():.4f}\")\n",
    "print(f\"  Median: {rag_ranked['rag_score'].median():.4f}\")\n",
    "\n",
    "# Score breakdown\n",
    "print(f\"\\n=== Score Breakdown ===\")\n",
    "hard_count = (rag_ranked['rag_score'] > 0.6).sum()\n",
    "medium_count = ((rag_ranked['rag_score'] >= 0.4) & (rag_ranked['rag_score'] <= 0.6)).sum()\n",
    "easy_count = (rag_ranked['rag_score'] < 0.4).sum()\n",
    "\n",
    "print(f\"  Hard (>0.6): {hard_count:,} ({hard_count/len(rag_ranked)*100:.1f}%)\")\n",
    "print(f\"  Medium (0.4-0.6): {medium_count:,} ({medium_count/len(rag_ranked)*100:.1f}%)\")\n",
    "print(f\"  Easy (<0.4): {easy_count:,} ({easy_count/len(rag_ranked)*100:.1f}%)\")\n",
    "\n",
    "# ============================================================\n",
    "# Select High-Quality Negatives\n",
    "# ============================================================\n",
    "\n",
    "QUALITY_PERCENTILE = 0.5  # Keep top 50%\n",
    "selection_threshold = rag_ranked['rag_score'].quantile(1 - QUALITY_PERCENTILE)\n",
    "\n",
    "print(f\"\\n=== Negative Selection ===\")\n",
    "print(f\"  Quality percentile: {QUALITY_PERCENTILE*100:.0f}%\")\n",
    "print(f\"  Selection threshold: {selection_threshold:.4f}\")\n",
    "\n",
    "rag_final = rag_ranked[rag_ranked['rag_score'] >= selection_threshold].copy()\n",
    "\n",
    "# Sort by score for clarity\n",
    "rag_final = rag_final.sort_values('rag_score', ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(f\"\\nâœ“ Selected {len(rag_final):,} high-quality negatives\")\n",
    "print(f\"  Original: {len(rag_input):,}\")\n",
    "print(f\"  Selected: {len(rag_final):,} ({len(rag_final)/len(rag_input)*100:.1f}%)\")\n",
    "\n",
    "# Show top examples\n",
    "print(f\"\\nTop 5 highest quality:\")\n",
    "for idx, row in rag_final.head(5).iterrows():\n",
    "    print(f\"  Score: {row['rag_score']:.4f} | Query: {row['query_text'][:40]}...\")\n",
    "\n",
    "print(f\"\\nBottom 5 of selected:\")\n",
    "for idx, row in rag_final.tail(5).iterrows():\n",
    "    print(f\"  Score: {row['rag_score']:.4f} | Query: {row['query_text'][:40]}...\")\n",
    "\n",
    "# ============================================================\n",
    "# Save Results\n",
    "# ============================================================\n",
    "\n",
    "print(f\"\\n=== Saving RAG-Selected Negatives ===\\n\")\n",
    "\n",
    "RAG_RESULTS_DIR = os.path.join(DATA_DIR, \"llm_classified_data\", \"rag_selected_negatives\")\n",
    "os.makedirs(RAG_RESULTS_DIR, exist_ok=True)\n",
    "\n",
    "# Save all ranked (with scores)\n",
    "ranked_csv = os.path.join(RAG_RESULTS_DIR, \"all_ranked_with_scores.csv\")\n",
    "rag_ranked.to_csv(ranked_csv, index=False)\n",
    "print(f\"âœ“ Full ranked: {ranked_csv}\")\n",
    "\n",
    "# Save selected high-quality\n",
    "selected_csv = os.path.join(RAG_RESULTS_DIR, \"selected_high_quality.csv\")\n",
    "rag_final.to_csv(selected_csv, index=False)\n",
    "print(f\"âœ“ Selected: {selected_csv}\")\n",
    "\n",
    "# Save metadata\n",
    "metadata = {\n",
    "    \"total_negatives\": len(rag_ranked),\n",
    "    \"selected_negatives\": len(rag_final),\n",
    "    \"selection_percentage\": float(len(rag_final)/len(rag_input)*100),\n",
    "    \"quality_percentile\": QUALITY_PERCENTILE,\n",
    "    \"score_threshold\": float(selection_threshold),\n",
    "    \"score_stats\": {\n",
    "        \"mean\": float(rag_ranked['rag_score'].mean()),\n",
    "        \"std\": float(rag_ranked['rag_score'].std()),\n",
    "        \"min\": float(rag_ranked['rag_score'].min()),\n",
    "        \"max\": float(rag_ranked['rag_score'].max()),\n",
    "        \"median\": float(rag_ranked['rag_score'].median())\n",
    "    },\n",
    "    \"breakdown\": {\n",
    "        \"hard_gt_0.6\": int(hard_count),\n",
    "        \"medium_0.4_0.6\": int(medium_count),\n",
    "        \"easy_lt_0.4\": int(easy_count)\n",
    "    },\n",
    "    \"timestamp\": pd.Timestamp.now().isoformat()\n",
    "}\n",
    "\n",
    "metadata_path = os.path.join(RAG_RESULTS_DIR, \"rag_selection_metadata.json\")\n",
    "with open(metadata_path, 'w') as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "print(f\"âœ“ Metadata: {metadata_path}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RAG RANKING COMPLETE\")\n",
    "print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "46936de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "PHASE 4: Training DPR with RAG-Selected Negatives\n",
      "============================================================\n",
      "\n",
      "=== Training Data ===\n",
      "  Samples: 533\n",
      "  Columns: ['query_text', 'gold_passage', 'hard_negative']\n",
      "\n",
      "=== Data Quality Check ===\n",
      "  Null values: 0\n",
      "  Duplicates: 0\n",
      "  Sample:\n",
      "    Query: how many calories are equal to a pound...\n",
      "    Gold: You Need to Burn 7,000 Calories to Lose a Pound, N...\n",
      "    Negative: gigahertz. n, pl-hertz. 1. (Units) a unit of frequ...\n",
      "\n",
      "=== Training Configuration ===\n",
      "  Epochs: 3\n",
      "  Batch size: 8\n",
      "  Learning rate: 5e-07\n",
      "  Max sequence length: 256\n",
      "  FP16: True\n",
      "\n",
      "=== Loading Phase 3 Model (Required) ===\n",
      "\n",
      "Loading: ./models/dpr_llm_enhanced\n",
      "âœ“ Successfully loaded Phase 3 model\n",
      "âœ“ Starting Phase 4 training from Phase 3 checkpoint\n",
      "\n",
      "=== Starting Phase 4 Training ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\TL1\\anaconda3\\envs\\mltorch\\lib\\site-packages\\torch\\__init__.py:1021: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead\n",
      "  return isinstance(obj, torch.Tensor)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ GPU memory cleared\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 533/533 [00:00<00:00, 1568.01 examples/s]\n",
      "INFO:simpletransformers.retrieval.retrieval_model: Training started\n",
      "Epoch:   0%|          | 0/3 [00:00<?, ?it/s]INFO:simpletransformers.retrieval.retrieval_model:   Starting fine-tuning.\n",
      "c:\\Users\\TL1\\anaconda3\\envs\\mltorch\\lib\\site-packages\\simpletransformers\\retrieval\\retrieval_model.py:503: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = amp.GradScaler()\n",
      "Epoch 1 of 3:   0%|          | 0/3 [00:00<?, ?it/s]c:\\Users\\TL1\\anaconda3\\envs\\mltorch\\lib\\site-packages\\simpletransformers\\retrieval\\retrieval_model.py:534: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast():\n",
      "c:\\Users\\TL1\\anaconda3\\envs\\mltorch\\lib\\site-packages\\simpletransformers\\retrieval\\retrieval_model.py:1659: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  (max_idxs == torch.tensor(labels)).sum().cpu().detach().numpy().item()\n",
      "c:\\Users\\TL1\\anaconda3\\envs\\mltorch\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:224: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n",
      "Epochs 0/3. Running Loss:    2.4147 Correct count: 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [09:22<00:00,  8.40s/it]\n",
      "Epochs 1/3. Running Loss:    3.1940 Correct count: 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [07:26<00:00,  6.67s/it]\n",
      "Epochs 2/3. Running Loss:    1.3212 Correct count: 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [07:43<00:00,  6.92s/it]\n",
      "Epoch 3 of 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [24:33<00:00, 491.19s/it]\n",
      "INFO:simpletransformers.retrieval.retrieval_model:Saving model into ./models/dpr_rag_phase4\n",
      "INFO:simpletransformers.retrieval.retrieval_model: Training of ./models/dpr_llm_enhanced model complete. Saved to ./models/dpr_rag_phase4.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "âœ… PHASE 4 TRAINING COMPLETE\n",
      "============================================================\n",
      "\n",
      "âœ“ Training time: 24.65 minutes\n",
      "âœ“ Model saved to: ./models/dpr_rag_phase4\n",
      "\n",
      "Phase 4 Results:\n",
      "  Input: 533 RAG-selected hard negatives\n",
      "  Trained: 533 query-negative-gold triplets\n",
      "  Output model: dpr_rag_phase4\n",
      "\n",
      "Next steps:\n",
      "  1. Evaluate Phase 4 model on msmarco_dev\n",
      "  2. Compare with Phase 2 & Phase 3 baselines\n",
      "  3. Verify RAG + LLM improved retrieval performance\n",
      "âœ“ GPU memory cleared\n",
      "\n",
      "============================================================\n",
      "Phase 4 READY\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PHASE 4: Training DPR with RAG-Selected Negatives\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "import torch\n",
    "from simpletransformers.retrieval import RetrievalModel, RetrievalArgs\n",
    "import time\n",
    "import os\n",
    "\n",
    "# Prepare training data\n",
    "train_df = rag_final[['query_text', 'gold_passage', 'hard_negative']].copy()\n",
    "train_df.columns = ['query_text', 'gold_passage', 'hard_negative']\n",
    "\n",
    "print(f\"\\n=== Training Data ===\")\n",
    "print(f\"  Samples: {len(train_df):,}\")\n",
    "print(f\"  Columns: {train_df.columns.tolist()}\")\n",
    "\n",
    "# â­ ADD DATA QUALITY CHECK\n",
    "print(f\"\\n=== Data Quality Check ===\")\n",
    "print(f\"  Null values: {train_df.isnull().sum().sum()}\")\n",
    "print(f\"  Duplicates: {train_df.duplicated().sum()}\")\n",
    "print(f\"  Sample:\")\n",
    "print(f\"    Query: {train_df['query_text'].iloc[0][:50]}...\")\n",
    "print(f\"    Gold: {train_df['gold_passage'].iloc[0][:50]}...\")\n",
    "print(f\"    Negative: {train_df['hard_negative'].iloc[0][:50]}...\")\n",
    "\n",
    "if train_df.isnull().sum().sum() > 0:\n",
    "    print(f\"\\nâš ï¸  WARNING: Found null values!\")\n",
    "    print(train_df.isnull().sum())\n",
    "\n",
    "# Configure training args\n",
    "phase4_args = RetrievalArgs()\n",
    "phase4_args.data_format = \"beir\"\n",
    "phase4_args.max_seq_length = 256\n",
    "phase4_args.include_title = False\n",
    "phase4_args.hard_negatives = True\n",
    "phase4_args.num_train_epochs = 3\n",
    "phase4_args.train_batch_size = 8\n",
    "phase4_args.learning_rate = 5e-7\n",
    "phase4_args.output_dir = f\"{MODEL_DIR}/dpr_rag_phase4\"\n",
    "phase4_args.fp16 = USE_MIXED_PRECISION\n",
    "phase4_args.evaluate_during_training = False\n",
    "phase4_args.save_model_every_epoch = False\n",
    "phase4_args.overwrite_output_dir = True\n",
    "phase4_args.use_cached_eval_features = False\n",
    "\n",
    "print(f\"\\n=== Training Configuration ===\")\n",
    "print(f\"  Epochs: {phase4_args.num_train_epochs}\")\n",
    "print(f\"  Batch size: {phase4_args.train_batch_size}\")\n",
    "print(f\"  Learning rate: {phase4_args.learning_rate}\")\n",
    "print(f\"  Max sequence length: {phase4_args.max_seq_length}\")\n",
    "print(f\"  FP16: {phase4_args.fp16}\")\n",
    "\n",
    "# ============================================================\n",
    "# LOAD PHASE 3 MODEL (REQUIRED)\n",
    "# ============================================================\n",
    "\n",
    "print(f\"\\n=== Loading Phase 3 Model (Required) ===\")\n",
    "\n",
    "phase3_model_path = f\"{MODEL_DIR}/dpr_llm_enhanced\"\n",
    "\n",
    "if not os.path.exists(phase3_model_path):\n",
    "    print(f\"\\nâŒ CRITICAL ERROR: Phase 3 model not found!\")\n",
    "    print(f\"\\nExpected path: {phase3_model_path}\")\n",
    "    print(f\"\\nAvailable models in {MODEL_DIR}:\")\n",
    "    \n",
    "    if os.path.exists(MODEL_DIR):\n",
    "        items = os.listdir(MODEL_DIR)\n",
    "        if items:\n",
    "            for item in items:\n",
    "                path = os.path.join(MODEL_DIR, item)\n",
    "                if os.path.isdir(path):\n",
    "                    print(f\"  ðŸ“ {item}/\")\n",
    "                else:\n",
    "                    print(f\"  ðŸ“„ {item}\")\n",
    "        else:\n",
    "            print(f\"  (Empty directory)\")\n",
    "    else:\n",
    "        print(f\"  (Directory does not exist)\")\n",
    "    \n",
    "    print(f\"\\nâš ï¸  REQUIRED: Complete Phase 3 first!\")\n",
    "    print(f\"   Phase 3 should save model to: {phase3_model_path}\")\n",
    "    print(f\"\\nDO NOT proceed until Phase 3 model is available.\")\n",
    "    raise FileNotFoundError(\n",
    "        f\"Phase 3 model required at: {phase3_model_path}\\n\"\n",
    "        f\"Please run Phase 3 training first.\"\n",
    "    )\n",
    "\n",
    "try:\n",
    "    print(f\"\\nLoading: {phase3_model_path}\")\n",
    "    \n",
    "    dpr_rag_model = RetrievalModel(\n",
    "        model_type=\"custom\",\n",
    "        model_name=phase3_model_path,\n",
    "        args=phase4_args,\n",
    "        use_cuda=torch.cuda.is_available()\n",
    "    )\n",
    "    \n",
    "    print(f\"âœ“ Successfully loaded Phase 3 model\")\n",
    "    print(f\"âœ“ Starting Phase 4 training from Phase 3 checkpoint\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\nâŒ Failed to load Phase 3 model!\")\n",
    "    print(f\"Error: {e}\")\n",
    "    print(f\"\\nPossible issues:\")\n",
    "    print(f\"1. Model directory exists but is corrupted\")\n",
    "    print(f\"2. Missing required model files (pytorch_model.bin, config.json, etc.)\")\n",
    "    print(f\"3. Incompatible model format\")\n",
    "    print(f\"\\nSolution: Re-run Phase 3 to regenerate the model\")\n",
    "    raise\n",
    "\n",
    "# ============================================================\n",
    "# Train Phase 4 Model\n",
    "# ============================================================\n",
    "\n",
    "print(f\"\\n=== Starting Phase 4 Training ===\\n\")\n",
    "\n",
    "clear_gpu_memory()\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "try:\n",
    "    dpr_rag_model.train_model(train_df)\n",
    "    \n",
    "    training_time = (time.time() - start_time) / 60\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"âœ… PHASE 4 TRAINING COMPLETE\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"\\nâœ“ Training time: {training_time:.2f} minutes\")\n",
    "    print(f\"âœ“ Model saved to: {phase4_args.output_dir}\")\n",
    "    print(f\"\\nPhase 4 Results:\")\n",
    "    print(f\"  Input: {len(train_df):,} RAG-selected hard negatives\")\n",
    "    print(f\"  Trained: {len(train_df)} query-negative-gold triplets\")\n",
    "    print(f\"  Output model: dpr_rag_phase4\")\n",
    "    print(f\"\\nNext steps:\")\n",
    "    print(f\"  1. Evaluate Phase 4 model on msmarco_dev\")\n",
    "    print(f\"  2. Compare with Phase 2 & Phase 3 baselines\")\n",
    "    print(f\"  3. Verify RAG + LLM improved retrieval performance\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\nâŒ PHASE 4 TRAINING FAILED\")\n",
    "    print(f\"Error: {e}\")\n",
    "    print(f\"\\nChecks:\")\n",
    "    print(f\"1. Training data: {len(train_df)} samples with columns {train_df.columns.tolist()}\")\n",
    "    print(f\"2. GPU available: {torch.cuda.is_available()}\")\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"3. GPU memory: {torch.cuda.get_device_properties(0)}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    raise\n",
    "\n",
    "finally:\n",
    "    clear_gpu_memory()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Phase 4 READY\")\n",
    "print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "8001ee09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Saving Phase 4 Metadata\n",
      "============================================================\n",
      "âœ“ Metadata saved to ./models/phase4_metadata.json\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Saving Phase 4 Metadata\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "metadata = {\n",
    "    \"stage\": \"phase_4_rag_integration\",\n",
    "    \"timestamp\": pd.Timestamp.now().isoformat(),\n",
    "    \"model_path\": phase4_args.output_dir,\n",
    "    \"training_samples\": len(train_df),\n",
    "    \"rag_samples_scored\": len(rag_ranked),\n",
    "    \"rag_samples_selected\": len(rag_final),\n",
    "    \"quality_threshold\": float(selection_threshold),\n",
    "    \"quality_percentile\": QUALITY_PERCENTILE,\n",
    "    \"epochs\": phase4_args.num_train_epochs,\n",
    "    \"batch_size\": phase4_args.train_batch_size,\n",
    "    \"learning_rate\": phase4_args.learning_rate,\n",
    "    \"rag_context_retrieval\": \"FAISS IndexFlatIP\",\n",
    "    \"rag_scorer\": \"LLMClassifier with context\",\n",
    "    \"training_time_minutes\": training_time if 'training_time' in locals() else None\n",
    "}\n",
    "\n",
    "metadata_path = f\"{MODEL_DIR}/phase4_metadata.json\"\n",
    "with open(metadata_path, 'w') as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "\n",
    "print(f\"âœ“ Metadata saved to {metadata_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "bbd659b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "PHASE 4 EVALUATION - RAG Model\n",
      "============================================================\n",
      "\n",
      "Using device: cuda\n",
      "\n",
      "Loading Phase 4 (RAG) Model...\n",
      "\n",
      "âœ“ Phase 4 (RAG) Model loaded successfully\n",
      "\n",
      "Evaluation dataset: 7,437 query-passage pairs\n",
      "\n",
      "\n",
      "============================================================\n",
      "Evaluating: Phase 4: RAG-Enhanced\n",
      "============================================================\n",
      "\n",
      "Using 300 samples (limited from 7437)\n",
      "Corpus size: 300 passages\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 300/300 [19:31<00:00,  3.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ GPU memory cleared\n",
      "\n",
      "============================================================\n",
      "ALL THREE MODELS - COMPREHENSIVE COMPARISON\n",
      "============================================================\n",
      "\n",
      "   Metric Phase 2 (BM25) Phase 3 (LLM) Phase 4 (RAG)\n",
      "   MRR@10         0.0259        0.0713        0.1237\n",
      "  nDCG@10         0.0346        0.1129        0.1662\n",
      " Recall@1         0.0133        0.0100        0.0633\n",
      " Recall@5         0.0400        0.1500        0.2000\n",
      "Recall@10         0.0633        0.2500        0.3067\n",
      "\n",
      "============================================================\n",
      "IMPROVEMENT ANALYSIS\n",
      "============================================================\n",
      "\n",
      "Phase 3 (LLM) vs Phase 2 (BM25):\n",
      "  Average: +189.23%\n",
      "\n",
      "Phase 4 (RAG) vs Phase 2 (BM25):\n",
      "  Average: +383.41%\n",
      "\n",
      "Phase 4 (RAG) vs Phase 3 (LLM):\n",
      "  Average: +142.02%\n",
      "\n",
      "============================================================\n",
      "DETAILED METRIC IMPROVEMENTS\n",
      "============================================================\n",
      "\n",
      "MRR@10:\n",
      "  Phase 2 (BM25):    0.0259\n",
      "  Phase 3 (LLM):     0.0713  (+174.88%)\n",
      "  Phase 4 (RAG):     0.1237  (BM25: +376.88%, LLM: +73.48%)\n",
      "\n",
      "nDCG@10:\n",
      "  Phase 2 (BM25):    0.0346\n",
      "  Phase 3 (LLM):     0.1129  (+226.55%)\n",
      "  Phase 4 (RAG):     0.1662  (BM25: +380.95%, LLM: +47.28%)\n",
      "\n",
      "Recall@1:\n",
      "  Phase 2 (BM25):    0.0133\n",
      "  Phase 3 (LLM):     0.0100  (-25.00%)\n",
      "  Phase 4 (RAG):     0.0633  (BM25: +375.00%, LLM: +533.33%)\n",
      "\n",
      "Recall@5:\n",
      "  Phase 2 (BM25):    0.0400\n",
      "  Phase 3 (LLM):     0.1500  (+275.00%)\n",
      "  Phase 4 (RAG):     0.2000  (BM25: +400.00%, LLM: +33.33%)\n",
      "\n",
      "Recall@10:\n",
      "  Phase 2 (BM25):    0.0633\n",
      "  Phase 3 (LLM):     0.2500  (+294.74%)\n",
      "  Phase 4 (RAG):     0.3067  (BM25: +384.21%, LLM: +22.67%)\n",
      "\n",
      "============================================================\n",
      "MODEL RANKING\n",
      "============================================================\n",
      "\n",
      "1. Phase 4 (RAG)        â†’ 0.1720\n",
      "2. Phase 3 (LLM)        â†’ 0.1188\n",
      "3. Phase 2 (BM25)       â†’ 0.0354\n",
      "\n",
      "============================================================\n",
      "SAVING PHASE 4 RESULTS\n",
      "============================================================\n",
      "\n",
      "âœ“ Results saved to: ./models/phase4_evaluation_results.json\n",
      "\n",
      "============================================================\n",
      "âœ… PHASE 4 EVALUATION COMPLETE\n",
      "============================================================\n",
      "\n",
      "ðŸ“Š Results Summary:\n",
      "   Best Model: Phase 4 (RAG) ðŸ†\n",
      "   Phase 3 improvement: +189.23%\n",
      "   Phase 4 improvement: +383.41%\n",
      "   Phase 4 vs Phase 3: +142.02%\n",
      "   Evaluation time: 19.53 minutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\TL1\\anaconda3\\envs\\mltorch\\lib\\site-packages\\torch\\__init__.py:1021: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead\n",
      "  return isinstance(obj, torch.Tensor)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ GPU memory cleared\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PHASE 4 EVALUATION - RAG Model\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "import torch\n",
    "import time\n",
    "import json\n",
    "from simpletransformers.retrieval import RetrievalModel, RetrievalArgs\n",
    "\n",
    "# Device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"\\nUsing device: {device}\")\n",
    "\n",
    "# ============================================================\n",
    "# LOAD PHASE 4 RAG MODEL\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\nLoading Phase 4 (RAG) Model...\\n\")\n",
    "\n",
    "rag_model_path = f\"{MODEL_DIR}/dpr_rag_phase4\"\n",
    "\n",
    "eval_args = RetrievalArgs()\n",
    "eval_args.data_format = \"beir\"\n",
    "eval_args.max_seq_length = 256\n",
    "eval_args.include_title = False\n",
    "eval_args.hard_negatives = False\n",
    "eval_args.fp16 = USE_MIXED_PRECISION\n",
    "\n",
    "try:\n",
    "    rag_model = RetrievalModel(\n",
    "        model_type=\"custom\",\n",
    "        model_name=rag_model_path,\n",
    "        args=eval_args,\n",
    "        use_cuda=torch.cuda.is_available()\n",
    "    )\n",
    "    rag_model.query_encoder = rag_model.query_encoder.to(device)\n",
    "    rag_model.context_encoder = rag_model.context_encoder.to(device)\n",
    "    print(f\"âœ“ Phase 4 (RAG) Model loaded successfully\\n\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Failed to load Phase 4 model!\")\n",
    "    print(f\"Error: {e}\")\n",
    "    print(f\"\\nEnsure Phase 4 model exists at: {rag_model_path}\")\n",
    "    raise\n",
    "\n",
    "# ============================================================\n",
    "# EVALUATE RAG MODEL\n",
    "# ============================================================\n",
    "\n",
    "print(f\"Evaluation dataset: {len(msmarco_dev):,} query-passage pairs\\n\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Evaluate RAG Model\n",
    "rag_results = evaluate_dpr_model(\n",
    "    rag_model,\n",
    "    msmarco_dev,\n",
    "    \"Phase 4: RAG-Enhanced\",\n",
    "    device,\n",
    "    max_samples=300  # Same 300 samples as Phase 3 for fair comparison\n",
    ")\n",
    "\n",
    "eval_time = (time.time() - start_time) / 60\n",
    "\n",
    "clear_gpu_memory()\n",
    "\n",
    "# ============================================================\n",
    "# COMPARE ALL THREE PHASES\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ALL THREE MODELS - COMPREHENSIVE COMPARISON\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Load Phase 3 comparison results\n",
    "phase3_path = f\"{MODEL_DIR}/phase3_comparison_results.json\"\n",
    "\n",
    "with open(phase3_path, 'r') as f:\n",
    "    phase3_data = json.load(f)\n",
    "\n",
    "bm25_metrics = phase3_data[\"BM25\"]\n",
    "llm_metrics = phase3_data[\"LLM-Enhanced\"]\n",
    "\n",
    "# Create three-way comparison\n",
    "metrics_list = list(bm25_metrics.keys())\n",
    "\n",
    "comparison_df = pd.DataFrame({\n",
    "    \"Metric\": metrics_list,\n",
    "    \"Phase 2 (BM25)\": [f\"{bm25_metrics[m]:.4f}\" for m in metrics_list],\n",
    "    \"Phase 3 (LLM)\": [f\"{llm_metrics[m]:.4f}\" for m in metrics_list],\n",
    "    \"Phase 4 (RAG)\": [f\"{rag_results[m]:.4f}\" for m in metrics_list]\n",
    "})\n",
    "\n",
    "print(\"\\n\" + comparison_df.to_string(index=False))\n",
    "\n",
    "# ============================================================\n",
    "# Calculate Improvements\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"IMPROVEMENT ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Phase 3 vs Phase 2\n",
    "phase3_improvements = {\n",
    "    m: ((llm_metrics[m] - bm25_metrics[m]) / max(bm25_metrics[m], 0.0001) * 100)\n",
    "    for m in metrics_list\n",
    "}\n",
    "phase3_avg = np.mean([phase3_improvements[m] for m in metrics_list])\n",
    "\n",
    "# Phase 4 vs Phase 2\n",
    "phase4_vs_bm25 = {\n",
    "    m: ((rag_results[m] - bm25_metrics[m]) / max(bm25_metrics[m], 0.0001) * 100)\n",
    "    for m in metrics_list\n",
    "}\n",
    "phase4_vs_bm25_avg = np.mean([phase4_vs_bm25[m] for m in metrics_list])\n",
    "\n",
    "# Phase 4 vs Phase 3\n",
    "phase4_vs_llm = {\n",
    "    m: ((rag_results[m] - llm_metrics[m]) / max(llm_metrics[m], 0.0001) * 100)\n",
    "    for m in metrics_list\n",
    "}\n",
    "phase4_vs_llm_avg = np.mean([phase4_vs_llm[m] for m in metrics_list])\n",
    "\n",
    "print(f\"\\nPhase 3 (LLM) vs Phase 2 (BM25):\")\n",
    "print(f\"  Average: {phase3_avg:+.2f}%\")\n",
    "\n",
    "print(f\"\\nPhase 4 (RAG) vs Phase 2 (BM25):\")\n",
    "print(f\"  Average: {phase4_vs_bm25_avg:+.2f}%\")\n",
    "\n",
    "print(f\"\\nPhase 4 (RAG) vs Phase 3 (LLM):\")\n",
    "print(f\"  Average: {phase4_vs_llm_avg:+.2f}%\")\n",
    "\n",
    "# Detailed metric breakdown\n",
    "print(f\"\\n\" + \"=\"*60)\n",
    "print(\"DETAILED METRIC IMPROVEMENTS\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "for metric in metrics_list:\n",
    "    bm25_val = bm25_metrics[metric]\n",
    "    llm_val = llm_metrics[metric]\n",
    "    rag_val = rag_results[metric]\n",
    "    \n",
    "    imp_phase3 = phase3_improvements[metric]\n",
    "    imp_phase4_bm25 = phase4_vs_bm25[metric]\n",
    "    imp_phase4_llm = phase4_vs_llm[metric]\n",
    "    \n",
    "    print(f\"{metric}:\")\n",
    "    print(f\"  Phase 2 (BM25):    {bm25_val:.4f}\")\n",
    "    print(f\"  Phase 3 (LLM):     {llm_val:.4f}  ({imp_phase3:+.2f}%)\")\n",
    "    print(f\"  Phase 4 (RAG):     {rag_val:.4f}  (BM25: {imp_phase4_bm25:+.2f}%, LLM: {imp_phase4_llm:+.2f}%)\")\n",
    "    print()\n",
    "\n",
    "# ============================================================\n",
    "# Model Ranking\n",
    "# ============================================================\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"MODEL RANKING\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "avg_scores = {\n",
    "    \"Phase 2 (BM25)\": np.mean([bm25_metrics[m] for m in metrics_list]),\n",
    "    \"Phase 3 (LLM)\": np.mean([llm_metrics[m] for m in metrics_list]),\n",
    "    \"Phase 4 (RAG)\": np.mean([rag_results[m] for m in metrics_list])\n",
    "}\n",
    "\n",
    "sorted_scores = sorted(avg_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "for rank, (model, score) in enumerate(sorted_scores, 1):\n",
    "    print(f\"{rank}. {model:<20} â†’ {score:.4f}\")\n",
    "\n",
    "best_model = sorted_scores[0][0]\n",
    "\n",
    "# ============================================================\n",
    "# Save Phase 4 Results\n",
    "# ============================================================\n",
    "\n",
    "print(f\"\\n\" + \"=\"*60)\n",
    "print(\"SAVING PHASE 4 RESULTS\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "phase4_evaluation = {\n",
    "    \"Phase 2 (BM25)\": bm25_metrics,\n",
    "    \"Phase 3 (LLM)\": llm_metrics,\n",
    "    \"Phase 4 (RAG)\": rag_results,\n",
    "    \"Improvements\": {\n",
    "        \"Phase 3 vs Phase 2\": {\n",
    "            **phase3_improvements,\n",
    "            \"Average\": phase3_avg\n",
    "        },\n",
    "        \"Phase 4 vs Phase 2\": {\n",
    "            **phase4_vs_bm25,\n",
    "            \"Average\": phase4_vs_bm25_avg\n",
    "        },\n",
    "        \"Phase 4 vs Phase 3\": {\n",
    "            **phase4_vs_llm,\n",
    "            \"Average\": phase4_vs_llm_avg\n",
    "        }\n",
    "    },\n",
    "    \"Ranking\": {\n",
    "        \"1st\": sorted_scores[0][0],\n",
    "        \"2nd\": sorted_scores[1][0],\n",
    "        \"3rd\": sorted_scores[2][0]\n",
    "    },\n",
    "    \"Evaluation Time (minutes)\": eval_time,\n",
    "    \"timestamp\": pd.Timestamp.now().isoformat()\n",
    "}\n",
    "\n",
    "results_path = f\"{MODEL_DIR}/phase4_evaluation_results.json\"\n",
    "with open(results_path, 'w') as f:\n",
    "    json.dump(phase4_evaluation, f, indent=2)\n",
    "\n",
    "print(f\"âœ“ Results saved to: {results_path}\")\n",
    "\n",
    "# ============================================================\n",
    "# Summary\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"âœ… PHASE 4 EVALUATION COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nðŸ“Š Results Summary:\")\n",
    "print(f\"   Best Model: {best_model} ðŸ†\")\n",
    "print(f\"   Phase 3 improvement: {phase3_avg:+.2f}%\")\n",
    "print(f\"   Phase 4 improvement: {phase4_vs_bm25_avg:+.2f}%\")\n",
    "print(f\"   Phase 4 vs Phase 3: {phase4_vs_llm_avg:+.2f}%\")\n",
    "print(f\"   Evaluation time: {eval_time:.2f} minutes\")\n",
    "\n",
    "clear_gpu_memory()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8366e415",
   "metadata": {},
   "source": [
    "## Phase 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "4b099686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "MULTILINGUAL FINE-TUNING ON Mr. TyDi\n",
      "============================================================\n",
      "\n",
      "TyDi Training Data: 1,688 samples\n",
      "\n",
      "\n",
      "============================================================\n",
      "Fine-tuning: BM25 Baseline\n",
      "============================================================\n",
      "\n",
      "Loading BM25 Baseline...\n",
      "âœ“ Model loaded\n",
      "\n",
      "Fine-tuning configuration:\n",
      "  Samples: 1,688\n",
      "  Epochs: 3\n",
      "  Batch size: 4\n",
      "  Learning rate: 1e-05\n",
      "  Output: ./models/dpr_bm25_baseline_tydi_final\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1688/1688 [00:00<00:00, 3537.36 examples/s]\n",
      "INFO:simpletransformers.retrieval.retrieval_model: Training started\n",
      "Epoch:   0%|          | 0/3 [00:00<?, ?it/s]INFO:simpletransformers.retrieval.retrieval_model:   Starting fine-tuning.\n",
      "c:\\Users\\TL1\\anaconda3\\envs\\mltorch\\lib\\site-packages\\simpletransformers\\retrieval\\retrieval_model.py:503: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = amp.GradScaler()\n",
      "Epoch 1 of 3:   0%|          | 0/3 [00:00<?, ?it/s]c:\\Users\\TL1\\anaconda3\\envs\\mltorch\\lib\\site-packages\\simpletransformers\\retrieval\\retrieval_model.py:534: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast():\n",
      "c:\\Users\\TL1\\anaconda3\\envs\\mltorch\\lib\\site-packages\\simpletransformers\\retrieval\\retrieval_model.py:1659: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  (max_idxs == torch.tensor(labels)).sum().cpu().detach().numpy().item()\n",
      "c:\\Users\\TL1\\anaconda3\\envs\\mltorch\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:224: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n",
      "Epochs 0/3. Running Loss:    0.2296 Correct count: 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 422/422 [16:37<00:00,  2.36s/it]\n",
      "Epochs 1/3. Running Loss:    0.0713 Correct count: 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 422/422 [15:45<00:00,  2.24s/it]\n",
      "Epochs 2/3. Running Loss:    0.0014 Correct count: 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 422/422 [15:44<00:00,  2.24s/it]\n",
      "Epoch 3 of 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [48:07<00:00, 962.48s/it]\n",
      "INFO:simpletransformers.retrieval.retrieval_model:Saving model into ./models/dpr_bm25_baseline_tydi_final\n",
      "INFO:simpletransformers.retrieval.retrieval_model: Training of ./models/dpr_bm25_baseline_epoch5 model complete. Saved to ./models/dpr_bm25_baseline_tydi_final.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… BM25 Baseline fine-tuned successfully!\n",
      "   Time: 48.22 minutes\n",
      "âœ“ Saved to ./models/dpr_bm25_baseline_tydi_final\n",
      "âœ“ GPU memory cleared\n",
      "\n",
      "============================================================\n",
      "Fine-tuning: LLM Enhanced\n",
      "============================================================\n",
      "\n",
      "Loading LLM Enhanced...\n",
      "âœ“ Model loaded\n",
      "\n",
      "Fine-tuning configuration:\n",
      "  Samples: 1,688\n",
      "  Epochs: 3\n",
      "  Batch size: 4\n",
      "  Learning rate: 1e-05\n",
      "  Output: ./models/dpr_llm_enhanced_tydi_final\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1688/1688 [00:00<00:00, 1951.72 examples/s]\n",
      "INFO:simpletransformers.retrieval.retrieval_model: Training started\n",
      "Epoch:   0%|          | 0/3 [00:00<?, ?it/s]INFO:simpletransformers.retrieval.retrieval_model:   Starting fine-tuning.\n",
      "Epochs 0/3. Running Loss:    0.0002 Correct count: 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 422/422 [14:43<00:00,  2.09s/it]\n",
      "Epochs 1/3. Running Loss:    0.0006 Correct count: 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 422/422 [15:02<00:00,  2.14s/it]\n",
      "Epochs 2/3. Running Loss:    0.0000 Correct count: 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 422/422 [15:07<00:00,  2.15s/it]\n",
      "Epoch 3 of 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [44:53<00:00, 897.80s/it]\n",
      "INFO:simpletransformers.retrieval.retrieval_model:Saving model into ./models/dpr_llm_enhanced_tydi_final\n",
      "INFO:simpletransformers.retrieval.retrieval_model: Training of ./models/dpr_llm_enhanced model complete. Saved to ./models/dpr_llm_enhanced_tydi_final.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… LLM Enhanced fine-tuned successfully!\n",
      "   Time: 44.99 minutes\n",
      "âœ“ Saved to ./models/dpr_llm_enhanced_tydi_final\n",
      "âœ“ GPU memory cleared\n",
      "\n",
      "============================================================\n",
      "Fine-tuning: RAG Enhanced\n",
      "============================================================\n",
      "\n",
      "Loading RAG Enhanced...\n",
      "âœ“ Model loaded\n",
      "\n",
      "Fine-tuning configuration:\n",
      "  Samples: 1,688\n",
      "  Epochs: 3\n",
      "  Batch size: 4\n",
      "  Learning rate: 1e-05\n",
      "  Output: ./models/dpr_rag_enhanced_tydi_final\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1688/1688 [00:00<00:00, 2238.16 examples/s]\n",
      "INFO:simpletransformers.retrieval.retrieval_model: Training started\n",
      "Epoch:   0%|          | 0/3 [00:00<?, ?it/s]INFO:simpletransformers.retrieval.retrieval_model:   Starting fine-tuning.\n",
      "Epochs 0/3. Running Loss:    0.5181 Correct count: 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 422/422 [15:06<00:00,  2.15s/it]\n",
      "Epochs 1/3. Running Loss:    0.0049 Correct count: 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 422/422 [15:23<00:00,  2.19s/it]\n",
      "Epochs 2/3. Running Loss:    1.0204 Correct count: 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 422/422 [15:24<00:00,  2.19s/it]\n",
      "Epoch 3 of 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [45:55<00:00, 918.46s/it]\n",
      "INFO:simpletransformers.retrieval.retrieval_model:Saving model into ./models/dpr_rag_enhanced_tydi_final\n",
      "INFO:simpletransformers.retrieval.retrieval_model: Training of ./models/dpr_rag_phase4 model complete. Saved to ./models/dpr_rag_enhanced_tydi_final.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… RAG Enhanced fine-tuned successfully!\n",
      "   Time: 46.00 minutes\n",
      "âœ“ Saved to ./models/dpr_rag_enhanced_tydi_final\n",
      "âœ“ GPU memory cleared\n",
      "\n",
      "============================================================\n",
      "âœ… MULTILINGUAL FINE-TUNING COMPLETE\n",
      "============================================================\n",
      "\n",
      "âœ“ Fine-tuned models (3):\n",
      "\n",
      "  BM25 Baseline\n",
      "    â†’ ./models/dpr_bm25_baseline_tydi_final\n",
      "\n",
      "  LLM Enhanced\n",
      "    â†’ ./models/dpr_llm_enhanced_tydi_final\n",
      "\n",
      "  RAG Enhanced\n",
      "    â†’ ./models/dpr_rag_enhanced_tydi_final\n",
      "\n",
      "âœ“ Summary saved: ./models/tydi_finetuning_summary.json\n",
      "\n",
      "============================================================\n",
      "Next step: Multilingual evaluation\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MULTILINGUAL FINE-TUNING ON Mr. TyDi\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "import torch\n",
    "from simpletransformers.retrieval import RetrievalModel, RetrievalArgs\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Models to fine-tune\n",
    "models_to_finetune = {\n",
    "    \"BM25 Baseline\": f\"{MODEL_DIR}/dpr_bm25_baseline_epoch5\",\n",
    "    \"LLM Enhanced\": f\"{MODEL_DIR}/dpr_llm_enhanced\",\n",
    "    \"RAG Enhanced\": f\"{MODEL_DIR}/dpr_rag_phase4\"\n",
    "}\n",
    "\n",
    "# Fine-tuning args\n",
    "finetune_args = RetrievalArgs()\n",
    "finetune_args.num_train_epochs = 3\n",
    "finetune_args.train_batch_size = 4\n",
    "finetune_args.gradient_accumulation_steps = 2\n",
    "finetune_args.learning_rate = 1e-5\n",
    "finetune_args.warmup_ratio = 0.1\n",
    "finetune_args.max_seq_length = 256\n",
    "finetune_args.fp16 = USE_MIXED_PRECISION\n",
    "finetune_args.dataloader_num_workers = 0\n",
    "finetune_args.logging_steps = 50\n",
    "finetune_args.save_model_every_epoch = False\n",
    "finetune_args.evaluate_during_training = False\n",
    "finetune_args.overwrite_output_dir = True\n",
    "finetune_args.include_title = False\n",
    "\n",
    "finetuned_models = {}\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(f\"\\nTyDi Training Data: {len(tydi_train_df):,} samples\\n\")\n",
    "\n",
    "for model_name, model_path in models_to_finetune.items():\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Fine-tuning: {model_name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Check if model exists\n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"\\nâŒ Model not found: {model_path}\")\n",
    "        print(f\"\\nAvailable in {MODEL_DIR}:\")\n",
    "        if os.path.exists(MODEL_DIR):\n",
    "            for item in os.listdir(MODEL_DIR):\n",
    "                print(f\"  - {item}\")\n",
    "        print(f\"\\nSkipping {model_name}...\")\n",
    "        continue\n",
    "    \n",
    "    # Load model\n",
    "    print(f\"\\nLoading {model_name}...\")\n",
    "    try:\n",
    "        model = RetrievalModel(\n",
    "            model_type=\"custom\",\n",
    "            model_name=model_path,\n",
    "            args=finetune_args,\n",
    "            use_cuda=torch.cuda.is_available()\n",
    "        )\n",
    "        print(\"âœ“ Model loaded\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Failed to load: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        continue\n",
    "    \n",
    "    # Set output directory\n",
    "    output_dir = f\"{MODEL_DIR}/dpr_{model_name.lower().replace(' ', '_')}_tydi_final\"\n",
    "    finetune_args.output_dir = output_dir\n",
    "    model.args = finetune_args\n",
    "    \n",
    "    print(f\"\\nFine-tuning configuration:\")\n",
    "    print(f\"  Samples: {len(tydi_train_df):,}\")\n",
    "    print(f\"  Epochs: {finetune_args.num_train_epochs}\")\n",
    "    print(f\"  Batch size: {finetune_args.train_batch_size}\")\n",
    "    print(f\"  Learning rate: {finetune_args.learning_rate}\")\n",
    "    print(f\"  Output: {output_dir}\\n\")\n",
    "    \n",
    "    # Fine-tune on TyDi\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        model.train_model(tydi_train_df)  # â† This saves automatically to output_dir\n",
    "        finetune_time = (time.time() - start_time) / 60\n",
    "        \n",
    "        print(f\"\\nâœ… {model_name} fine-tuned successfully!\")\n",
    "        print(f\"   Time: {finetune_time:.2f} minutes\")\n",
    "        print(f\"âœ“ Saved to {output_dir}\")\n",
    "        \n",
    "        finetuned_models[model_name] = output_dir\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Fine-tuning failed: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        continue\n",
    "    \n",
    "    # Clear GPU memory\n",
    "    clear_gpu_memory()\n",
    "\n",
    "# ============================================================\n",
    "# Summary\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"âœ… MULTILINGUAL FINE-TUNING COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if finetuned_models:\n",
    "    print(f\"\\nâœ“ Fine-tuned models ({len(finetuned_models)}):\\n\")\n",
    "    for name, path in finetuned_models.items():\n",
    "        print(f\"  {name}\")\n",
    "        print(f\"    â†’ {path}\\n\")\n",
    "    \n",
    "    # Save summary\n",
    "    import json\n",
    "    summary = {\n",
    "        \"timestamp\": pd.Timestamp.now().isoformat(),\n",
    "        \"tydi_samples\": len(tydi_train_df),\n",
    "        \"models_finetuned\": finetuned_models,\n",
    "        \"fine_tuning_config\": {\n",
    "            \"epochs\": finetune_args.num_train_epochs,\n",
    "            \"batch_size\": finetune_args.train_batch_size,\n",
    "            \"learning_rate\": finetune_args.learning_rate\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    summary_path = f\"{MODEL_DIR}/tydi_finetuning_summary.json\"\n",
    "    with open(summary_path, 'w') as f:\n",
    "        json.dump(summary, f, indent=2)\n",
    "    \n",
    "    print(f\"âœ“ Summary saved: {summary_path}\")\n",
    "    \n",
    "else:\n",
    "    print(\"\\nâŒ No models were successfully fine-tuned!\")\n",
    "\n",
    "print(f\"\\n\" + \"=\"*60)\n",
    "print(\"Next step: Multilingual evaluation\")\n",
    "print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "8f3e573f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "LOADING EVALUATION DATASETS - BEIR FORMAT\n",
      "============================================================\n",
      "\n",
      "Configuration:\n",
      "  Samples per language: 50\n",
      "\n",
      "Initial RAM: 0.74GB\n",
      "  Memory cleared: 0.74GB\n",
      "\n",
      "============================================================\n",
      "IN-DISTRIBUTION: Mr. TyDi Test\n",
      "============================================================\n",
      "\n",
      "Checking for cached data...\n",
      "  Found cached data: ./data/evaluation_datasets/num_rows_50/tydi_eval_data.pkl\n",
      "  Loaded from disk: 100 samples\n",
      "Using cached data from disk\n",
      "\n",
      "============================================================\n",
      "In-Distribution: 2 languages\n",
      "Total samples: 100\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "OUT-OF-DISTRIBUTION: mMARCO (Domain Shift)\n",
      "============================================================\n",
      "\n",
      "Checking for cached data...\n",
      "  Found cached data: ./data/evaluation_datasets/num_rows_50/ood_eval_data.pkl\n",
      "  Loaded from disk: 4 samples\n",
      "Using cached data from disk\n",
      "\n",
      "============================================================\n",
      "Out-of-Distribution: 2 languages\n",
      "Total samples: 4\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "ZERO-SHOT: Unseen Languages\n",
      "============================================================\n",
      "\n",
      "Checking for cached data...\n",
      "  Found cached data: ./data/evaluation_datasets/num_rows_50/zero_shot_eval_data.pkl\n",
      "  Loaded from disk: 2 samples\n",
      "Using cached data from disk\n",
      "\n",
      "============================================================\n",
      "Zero-Shot: 1 languages\n",
      "Total samples: 2\n",
      "============================================================\n",
      "  Memory cleared: 0.74GB\n",
      "\n",
      "============================================================\n",
      "EVALUATION DATASETS LOADED\n",
      "============================================================\n",
      "\n",
      "Summary:\n",
      "  In-Distribution (TyDi):\n",
      "    Languages: swahili, bengali\n",
      "    Samples: 100\n",
      "\n",
      "  Out-of-Distribution (mMARCO):\n",
      "    Languages: arabic, japanese\n",
      "    Samples: 4\n",
      "\n",
      "  Zero-Shot (Unseen):\n",
      "    Languages: chinese\n",
      "    Samples: 2\n",
      "\n",
      "  Total languages: 5\n",
      "  Total samples: 106\n",
      "  Final RAM: 0.74GB\n",
      "\n",
      "Ready for evaluation.\n",
      "\n",
      "============================================================\n",
      "CACHING DATASETS\n",
      "============================================================\n",
      "\n",
      "âœ“ Cached TyDi data: ./data/evaluation_datasets/num_rows_50/tydi_eval_data.pkl\n",
      "âœ“ Cached OOD data: ./data/evaluation_datasets/num_rows_50/ood_eval_data.pkl\n",
      "âœ“ Cached Zero-shot data: ./data/evaluation_datasets/num_rows_50/zero_shot_eval_data.pkl\n",
      "\n",
      "============================================================\n",
      "DATA VALIDATION\n",
      "============================================================\n",
      "\n",
      "In-Distribution (TyDi):\n",
      "  âœ“ swahili: All clean (50 samples)\n",
      "  âœ“ bengali: All clean (50 samples)\n",
      "Out-of-Distribution (mMARCO):\n",
      "  âœ“ arabic: All clean (2 samples)\n",
      "  âœ“ japanese: All clean (2 samples)\n",
      "Zero-Shot (Unseen):\n",
      "  âœ“ chinese: All clean (2 samples)\n",
      "\n",
      "============================================================\n",
      "âœ… EVALUATION DATASETS READY\n",
      "============================================================\n",
      "  Memory cleared: 0.74GB\n"
     ]
    }
   ],
   "source": [
    "# Load Evaluation Datasets - Check Disk First, Then Load from Source\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import gc\n",
    "import psutil\n",
    "import torch\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"LOADING EVALUATION DATASETS - BEIR FORMAT\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "def get_memory_usage():\n",
    "    \"\"\"Get current memory usage in GB\"\"\"\n",
    "    process = psutil.Process(os.getpid())\n",
    "    return process.memory_info().rss / 1024 / 1024 / 1024\n",
    "\n",
    "def clear_memory(verbose=True):\n",
    "    \"\"\"Clear memory and GPU cache\"\"\"\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    if verbose:\n",
    "        print(f\"  Memory cleared: {get_memory_usage():.2f}GB\")\n",
    "\n",
    "def load_from_disk(dataset_type, nrows):\n",
    "    \"\"\"Load dataset from saved pickle files if they exist\"\"\"\n",
    "    base_dir = f\"./data/evaluation_datasets/num_rows_{nrows}\"\n",
    "    \n",
    "    if dataset_type == \"tydi\":\n",
    "        pickle_file = f\"{base_dir}/tydi_eval_data.pkl\"\n",
    "    elif dataset_type == \"ood\":\n",
    "        pickle_file = f\"{base_dir}/ood_eval_data.pkl\"\n",
    "    elif dataset_type == \"zeroshot\":\n",
    "        pickle_file = f\"{base_dir}/zero_shot_eval_data.pkl\"\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "    if os.path.exists(pickle_file):\n",
    "        print(f\"  Found cached data: {pickle_file}\")\n",
    "        try:\n",
    "            with open(pickle_file, 'rb') as f:\n",
    "                data = pickle.load(f)\n",
    "            print(f\"  Loaded from disk: {sum(len(df) for df in data.values())} samples\")\n",
    "            return data\n",
    "        except Exception as e:\n",
    "            print(f\"  Error loading from disk: {e}\")\n",
    "            return None\n",
    "    \n",
    "    return None\n",
    "\n",
    "def load_beir_eval_dataset_chunked(\n",
    "    dataset_dir: str,\n",
    "    dataset_name: str,\n",
    "    lang: str,\n",
    "    nrows: int = 100,\n",
    "    qrels_subfolder: bool = False,\n",
    "    chunk_size: int = 5000\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load BEIR format evaluation dataset with chunked corpus loading.\n",
    "    Only loads if qrels file exists - NO fallbacks.\n",
    "    \"\"\"\n",
    "    \n",
    "    lang_dir = f\"{dataset_dir}/{lang}\"\n",
    "    queries_file = f\"{lang_dir}/queries.jsonl\"\n",
    "    corpus_file = f\"{lang_dir}/corpus.jsonl\"\n",
    "    \n",
    "    if qrels_subfolder:\n",
    "        qrels_file = f\"{lang_dir}/qrels/test.tsv\"\n",
    "    else:\n",
    "        qrels_file = f\"{lang_dir}/qrels.tsv\"\n",
    "    \n",
    "    # Strict validation - all files must exist\n",
    "    if not os.path.exists(queries_file):\n",
    "        print(f\"  Missing queries file: {queries_file}\")\n",
    "        return None\n",
    "    if not os.path.exists(corpus_file):\n",
    "        print(f\"  Missing corpus file: {corpus_file}\")\n",
    "        return None\n",
    "    if not os.path.exists(qrels_file):\n",
    "        print(f\"  Missing qrels file: {qrels_file}\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        # Load queries\n",
    "        queries_df = pd.read_json(queries_file, lines=True, nrows=nrows)\n",
    "        queries_df = queries_df.rename(columns={\"_id\": \"query_id\", \"text\": \"query\"})\n",
    "        queries_df[\"query_id\"] = queries_df[\"query_id\"].astype(str)\n",
    "        print(f\"  Loaded {len(queries_df)} queries\")\n",
    "        \n",
    "        # Load corpus in chunks\n",
    "        print(f\"  Loading corpus in chunks...\")\n",
    "        corpus_chunks = []\n",
    "        chunk_count = 0\n",
    "        \n",
    "        for chunk in pd.read_json(corpus_file, lines=True, chunksize=chunk_size):\n",
    "            chunk = chunk.rename(columns={\"_id\": \"corpus_id\", \"text\": \"passage\"})\n",
    "            chunk[\"corpus_id\"] = chunk[\"corpus_id\"].astype(str)\n",
    "            chunk = chunk[[\"corpus_id\", \"passage\"]]\n",
    "            corpus_chunks.append(chunk)\n",
    "            chunk_count += 1\n",
    "            \n",
    "            if chunk_count % 3 == 0:\n",
    "                gc.collect()\n",
    "        \n",
    "        corpus_df = pd.concat(corpus_chunks, ignore_index=True)\n",
    "        print(f\"  Loaded {len(corpus_df)} passages\")\n",
    "        \n",
    "        del corpus_chunks\n",
    "        gc.collect()\n",
    "        \n",
    "        # Load qrels - STRICTLY\n",
    "        qrels_df = pd.read_csv(qrels_file, sep=\"\\t\", header=None, dtype=str)\n",
    "        \n",
    "        if len(qrels_df.columns) == 4:\n",
    "            qrels_df.columns = [\"query_id\", \"0\", \"corpus_id\", \"relevance\"]\n",
    "            qrels_df = qrels_df[[\"query_id\", \"corpus_id\"]]\n",
    "        elif len(qrels_df.columns) == 3:\n",
    "            qrels_df.columns = [\"query_id\", \"corpus_id\", \"relevance\"]\n",
    "            qrels_df = qrels_df[[\"query_id\", \"corpus_id\"]]\n",
    "        else:\n",
    "            qrels_df.columns = [\"query_id\", \"corpus_id\"]\n",
    "        \n",
    "        qrels_df[\"query_id\"] = qrels_df[\"query_id\"].astype(str)\n",
    "        qrels_df[\"corpus_id\"] = qrels_df[\"corpus_id\"].astype(str)\n",
    "        \n",
    "        print(f\"  Loaded {len(qrels_df)} qrels\")\n",
    "        \n",
    "        # Merge: qrels -> queries -> corpus\n",
    "        eval_df = qrels_df.merge(\n",
    "            queries_df[[\"query_id\", \"query\"]],\n",
    "            on=\"query_id\",\n",
    "            how=\"inner\"\n",
    "        ).merge(\n",
    "            corpus_df[[\"corpus_id\", \"passage\"]],\n",
    "            on=\"corpus_id\",\n",
    "            how=\"inner\"\n",
    "        )\n",
    "        \n",
    "        eval_df = eval_df[[\"query\", \"passage\"]].dropna()\n",
    "        \n",
    "        del qrels_df, queries_df, corpus_df\n",
    "        gc.collect()\n",
    "        \n",
    "        if len(eval_df) == 0:\n",
    "            print(f\"  No valid query-passage pairs found for {lang}\")\n",
    "            return None\n",
    "        \n",
    "        print(f\"  Created {len(eval_df)} query-passage pairs\")\n",
    "        return eval_df.reset_index(drop=True)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  Error loading {lang}: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        clear_memory()\n",
    "        return None\n",
    "\n",
    "# Configuration\n",
    "NROWS = 50  # Change this to 100, 500, etc.\n",
    "TYDI_EVAL_LANGS = [\"swahili\", \"bengali\", \"telugu\"]\n",
    "MMARCO_OUT_OF_DIST_LANGS = [\"arabic\", \"japanese\"]\n",
    "ZERO_SHOT_LANGS = [\"chinese\"]\n",
    "\n",
    "overlap = set(TYDI_EVAL_LANGS) & set(ZERO_SHOT_LANGS)\n",
    "if overlap:\n",
    "    print(f\"ERROR: Zero-shot overlap: {overlap}\")\n",
    "    raise ValueError(\"Remove overlapping languages\")\n",
    "\n",
    "print(f\"\\nConfiguration:\")\n",
    "print(f\"  Samples per language: {NROWS}\")\n",
    "\n",
    "print(f\"\\nInitial RAM: {get_memory_usage():.2f}GB\")\n",
    "clear_memory(verbose=True)\n",
    "\n",
    "# Load In-Distribution\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"IN-DISTRIBUTION: Mr. TyDi Test\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "tydi_eval_data = {}\n",
    "\n",
    "# Try loading from disk first\n",
    "print(\"Checking for cached data...\")\n",
    "cached_tydi = load_from_disk(\"tydi\", NROWS)\n",
    "\n",
    "if cached_tydi is not None:\n",
    "    tydi_eval_data = cached_tydi\n",
    "    print(\"Using cached data from disk\")\n",
    "else:\n",
    "    print(\"No cached data found - loading from source...\")\n",
    "    for lang in TYDI_EVAL_LANGS:\n",
    "        print(f\"Loading {lang}...\")\n",
    "        df = load_beir_eval_dataset_chunked(\n",
    "            TYDI_DIR,\n",
    "            \"TyDi\",\n",
    "            lang,\n",
    "            nrows=NROWS,\n",
    "            qrels_subfolder=True,\n",
    "            chunk_size=5000\n",
    "        )\n",
    "        if df is not None and len(df) > 0:\n",
    "            tydi_eval_data[lang] = df\n",
    "            print(f\"Loaded: {len(df)} samples\\n\")\n",
    "        else:\n",
    "            print(\"Failed to load\\n\")\n",
    "        \n",
    "        clear_memory(verbose=True)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"In-Distribution: {len(tydi_eval_data)} languages\")\n",
    "print(f\"Total samples: {sum(len(df) for df in tydi_eval_data.values())}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Load Out-of-Distribution\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"OUT-OF-DISTRIBUTION: mMARCO (Domain Shift)\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "ood_eval_data = {}\n",
    "\n",
    "# Try loading from disk first\n",
    "print(\"Checking for cached data...\")\n",
    "cached_ood = load_from_disk(\"ood\", NROWS)\n",
    "\n",
    "if cached_ood is not None:\n",
    "    ood_eval_data = cached_ood\n",
    "    print(\"Using cached data from disk\")\n",
    "else:\n",
    "    print(\"No cached data found - loading from source...\")\n",
    "    for lang in MMARCO_OUT_OF_DIST_LANGS:\n",
    "        print(f\"Loading {lang}...\")\n",
    "        df = load_beir_eval_dataset_chunked(\n",
    "            MMARCO_DIR,\n",
    "            \"mMARCO\",\n",
    "            lang,\n",
    "            nrows=NROWS,\n",
    "            qrels_subfolder=False,\n",
    "            chunk_size=5000\n",
    "        )\n",
    "        if df is not None and len(df) > 0:\n",
    "            ood_eval_data[lang] = df\n",
    "            print(f\"Loaded: {len(df)} samples\\n\")\n",
    "        else:\n",
    "            print(\"Failed to load\\n\")\n",
    "        \n",
    "        clear_memory(verbose=True)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"Out-of-Distribution: {len(ood_eval_data)} languages\")\n",
    "print(f\"Total samples: {sum(len(df) for df in ood_eval_data.values())}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Load Zero-Shot\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ZERO-SHOT: Unseen Languages\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "zeroshot_eval_data = {}\n",
    "\n",
    "# Try loading from disk first\n",
    "print(\"Checking for cached data...\")\n",
    "cached_zeroshot = load_from_disk(\"zeroshot\", NROWS)\n",
    "\n",
    "if cached_zeroshot is not None:\n",
    "    zeroshot_eval_data = cached_zeroshot\n",
    "    print(\"Using cached data from disk\")\n",
    "else:\n",
    "    print(\"No cached data found - loading from source...\")\n",
    "    for lang in ZERO_SHOT_LANGS:\n",
    "        print(f\"Loading {lang}...\")\n",
    "        df = load_beir_eval_dataset_chunked(\n",
    "            MMARCO_DIR,\n",
    "            \"mMARCO\",\n",
    "            lang,\n",
    "            nrows=NROWS,\n",
    "            qrels_subfolder=False,\n",
    "            chunk_size=5000\n",
    "        )\n",
    "        if df is not None and len(df) > 0:\n",
    "            zeroshot_eval_data[lang] = df\n",
    "            print(f\"Loaded: {len(df)} samples\\n\")\n",
    "        else:\n",
    "            print(\"Failed to load\\n\")\n",
    "        \n",
    "        clear_memory(verbose=True)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"Zero-Shot: {len(zeroshot_eval_data)} languages\")\n",
    "print(f\"Total samples: {sum(len(df) for df in zeroshot_eval_data.values())}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Summary\n",
    "clear_memory(verbose=True)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EVALUATION DATASETS LOADED\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nSummary:\")\n",
    "print(f\"  In-Distribution (TyDi):\")\n",
    "print(f\"    Languages: {', '.join(tydi_eval_data.keys())}\")\n",
    "print(f\"    Samples: {sum(len(df) for df in tydi_eval_data.values())}\")\n",
    "\n",
    "print(f\"\\n  Out-of-Distribution (mMARCO):\")\n",
    "print(f\"    Languages: {', '.join(ood_eval_data.keys())}\")\n",
    "print(f\"    Samples: {sum(len(df) for df in ood_eval_data.values())}\")\n",
    "\n",
    "print(f\"\\n  Zero-Shot (Unseen):\")\n",
    "print(f\"    Languages: {', '.join(zeroshot_eval_data.keys())}\")\n",
    "print(f\"    Samples: {sum(len(df) for df in zeroshot_eval_data.values())}\")\n",
    "\n",
    "total_langs = len(tydi_eval_data) + len(ood_eval_data) + len(zeroshot_eval_data)\n",
    "total_samples = (\n",
    "    sum(len(df) for df in tydi_eval_data.values()) +\n",
    "    sum(len(df) for df in ood_eval_data.values()) +\n",
    "    sum(len(df) for df in zeroshot_eval_data.values())\n",
    ")\n",
    "\n",
    "print(f\"\\n  Total languages: {total_langs}\")\n",
    "print(f\"  Total samples: {total_samples}\")\n",
    "print(f\"  Final RAM: {get_memory_usage():.2f}GB\")\n",
    "\n",
    "if total_samples > 0:\n",
    "    print(\"\\nReady for evaluation.\")\n",
    "else:\n",
    "    print(\"\\nERROR: No samples loaded - check dataset paths!\")\n",
    "    \n",
    "# ============================================================\n",
    "# Save to Cache\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CACHING DATASETS\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "cache_dir = f\"./data/evaluation_datasets/num_rows_{NROWS}\"\n",
    "os.makedirs(cache_dir, exist_ok=True)\n",
    "\n",
    "if tydi_eval_data:\n",
    "    with open(f\"{cache_dir}/tydi_eval_data.pkl\", 'wb') as f:\n",
    "        pickle.dump(tydi_eval_data, f)\n",
    "    print(f\"âœ“ Cached TyDi data: {cache_dir}/tydi_eval_data.pkl\")\n",
    "\n",
    "if ood_eval_data:\n",
    "    with open(f\"{cache_dir}/ood_eval_data.pkl\", 'wb') as f:\n",
    "        pickle.dump(ood_eval_data, f)\n",
    "    print(f\"âœ“ Cached OOD data: {cache_dir}/ood_eval_data.pkl\")\n",
    "\n",
    "if zeroshot_eval_data:\n",
    "    with open(f\"{cache_dir}/zero_shot_eval_data.pkl\", 'wb') as f:\n",
    "        pickle.dump(zeroshot_eval_data, f)\n",
    "    print(f\"âœ“ Cached Zero-shot data: {cache_dir}/zero_shot_eval_data.pkl\")\n",
    "\n",
    "# ============================================================\n",
    "# Data Validation\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DATA VALIDATION\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "for dataset_name, dataset_dict in [\n",
    "    (\"In-Distribution (TyDi)\", tydi_eval_data),\n",
    "    (\"Out-of-Distribution (mMARCO)\", ood_eval_data),\n",
    "    (\"Zero-Shot (Unseen)\", zeroshot_eval_data)\n",
    "]:\n",
    "    print(f\"{dataset_name}:\")\n",
    "    for lang, df in dataset_dict.items():\n",
    "        null_count = df.isnull().sum().sum()\n",
    "        empty_queries = (df['query'].str.len() == 0).sum()\n",
    "        empty_passages = (df['passage'].str.len() == 0).sum()\n",
    "        \n",
    "        if null_count > 0 or empty_queries > 0 or empty_passages > 0:\n",
    "            print(f\"  âš ï¸  {lang}: nulls={null_count}, empty_queries={empty_queries}, empty_passages={empty_passages}\")\n",
    "        else:\n",
    "            print(f\"  âœ“ {lang}: All clean ({len(df)} samples)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"âœ… EVALUATION DATASETS READY\")\n",
    "print(\"=\"*60)\n",
    "clear_memory(verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc23ae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "SAVING EVALUATION DATASETS\n",
      "============================================================\n",
      "\n",
      "Output directory: ./data/evaluation_datasets/num_rows_50/\n",
      "Samples per language: 50\n",
      "\n",
      "------------------------------------------------------------\n",
      "Saving In-Distribution (TyDi) - 100 total samples\n",
      "------------------------------------------------------------\n",
      "  Saved: tydi_swahili.csv (50 samples)\n",
      "  Saved: tydi_bengali.csv (50 samples)\n",
      "  Saved: tydi_eval_data.pkl\n",
      "\n",
      "------------------------------------------------------------\n",
      "Saving Out-of-Distribution (mMARCO) - 4 total samples\n",
      "------------------------------------------------------------\n",
      "  Saved: ood_arabic.csv (2 samples)\n",
      "  Saved: ood_japanese.csv (2 samples)\n",
      "  Saved: ood_eval_data.pkl\n",
      "\n",
      "------------------------------------------------------------\n",
      "Saving Zero-Shot (Unseen) - 2 total samples\n",
      "------------------------------------------------------------\n",
      "  Saved: zero_shot_chinese.csv (2 samples)\n",
      "  Saved: zero_shot_eval_data.pkl\n",
      "\n",
      "------------------------------------------------------------\n",
      "Saving Metadata\n",
      "------------------------------------------------------------\n",
      "  Saved: metadata.json\n",
      "\n",
      "============================================================\n",
      "SAVE SUMMARY\n",
      "============================================================\n",
      "\n",
      "Directory structure:\n",
      "\n",
      "evaluation_datasets/\n",
      "â””â”€â”€ 50/\n",
      "    â”œâ”€â”€ tydi_swahili.csv\n",
      "    â”œâ”€â”€ tydi_bengali.csv\n",
      "    â”œâ”€â”€ tydi_telugu.csv\n",
      "    â”œâ”€â”€ tydi_eval_data.pkl\n",
      "    â”œâ”€â”€ ood_arabic.csv\n",
      "    â”œâ”€â”€ ood_japanese.csv\n",
      "    â”œâ”€â”€ ood_eval_data.pkl\n",
      "    â”œâ”€â”€ zero_shot_chinese.csv\n",
      "    â”œâ”€â”€ zero_shot_eval_data.pkl\n",
      "    â””â”€â”€ metadata.json\n",
      "\n",
      "------------------------------------------------------------\n",
      "File Verification\n",
      "------------------------------------------------------------\n",
      "\n",
      "50/ (All datasets):\n",
      "  metadata.json: 0.76 KB\n",
      "  ood_arabic.csv: 0.80 KB\n",
      "  ood_eval_data.pkl: 2.30 KB\n",
      "  ood_japanese.csv: 0.69 KB\n",
      "  tydi_bengali.csv: 82.60 KB\n",
      "  tydi_eval_data.pkl: 101.13 KB\n",
      "  tydi_swahili.csv: 21.99 KB\n",
      "  zero_shot_chinese.csv: 0.49 KB\n",
      "  zero_shot_eval_data.pkl: 1.12 KB\n",
      "  Total: 211.88 KB\n",
      "\n",
      "============================================================\n",
      "All datasets saved successfully\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# # Save Evaluation Datasets to Files (organized by nrows - all three in same folder)\n",
    "\n",
    "# import os\n",
    "# import pickle\n",
    "# import json\n",
    "# from datetime import datetime\n",
    "\n",
    "# print(\"\\n\" + \"=\"*60)\n",
    "# print(\"SAVING EVALUATION DATASETS\")\n",
    "# print(\"=\"*60)\n",
    "\n",
    "# # Get total nrows for each dataset type\n",
    "# def get_total_samples(eval_dict):\n",
    "#     \"\"\"Get total samples from all languages\"\"\"\n",
    "#     return sum(len(df) for df in eval_dict.values())\n",
    "\n",
    "# tydi_samples = get_total_samples(tydi_eval_data)\n",
    "# ood_samples = get_total_samples(ood_eval_data)\n",
    "# zeroshot_samples = get_total_samples(zeroshot_eval_data)\n",
    "\n",
    "# # Get nrows from data (assuming all languages have same nrows)\n",
    "# def get_nrows_per_lang(eval_dict):\n",
    "#     \"\"\"Get nrows per language\"\"\"\n",
    "#     if not eval_dict:\n",
    "#         return 0\n",
    "#     first_df = list(eval_dict.values())[0]\n",
    "#     return len(first_df)\n",
    "\n",
    "# nrows_per_lang = get_nrows_per_lang(tydi_eval_data)\n",
    "\n",
    "# # Create base output directory\n",
    "# base_output_dir = \"./data/evaluation_datasets\"\n",
    "# os.makedirs(base_output_dir, exist_ok=True)\n",
    "\n",
    "# # Create nrows subdirectory (all three datasets go here)\n",
    "# output_dir = f\"{base_output_dir}/num_rows_{nrows_per_lang}\"\n",
    "# os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# print(f\"\\nOutput directory: {output_dir}/\")\n",
    "# print(f\"Samples per language: {nrows_per_lang}\")\n",
    "\n",
    "# # Save In-Distribution\n",
    "# print(\"\\n\" + \"-\"*60)\n",
    "# print(f\"Saving In-Distribution (TyDi) - {tydi_samples} total samples\")\n",
    "# print(\"-\"*60)\n",
    "\n",
    "# for lang, df in tydi_eval_data.items():\n",
    "#     output_file = f\"{output_dir}/tydi_{lang}.csv\"\n",
    "#     df.to_csv(output_file, index=False)\n",
    "#     print(f\"  Saved: tydi_{lang}.csv ({len(df)} samples)\")\n",
    "\n",
    "# tydi_pickle = f\"{output_dir}/tydi_eval_data.pkl\"\n",
    "# with open(tydi_pickle, 'wb') as f:\n",
    "#     pickle.dump(tydi_eval_data, f)\n",
    "# print(f\"  Saved: tydi_eval_data.pkl\")\n",
    "\n",
    "# # Save Out-of-Distribution\n",
    "# print(\"\\n\" + \"-\"*60)\n",
    "# print(f\"Saving Out-of-Distribution (mMARCO) - {ood_samples} total samples\")\n",
    "# print(\"-\"*60)\n",
    "\n",
    "# for lang, df in ood_eval_data.items():\n",
    "#     output_file = f\"{output_dir}/ood_{lang}.csv\"\n",
    "#     df.to_csv(output_file, index=False)\n",
    "#     print(f\"  Saved: ood_{lang}.csv ({len(df)} samples)\")\n",
    "\n",
    "# ood_pickle = f\"{output_dir}/ood_eval_data.pkl\"\n",
    "# with open(ood_pickle, 'wb') as f:\n",
    "#     pickle.dump(ood_eval_data, f)\n",
    "# print(f\"  Saved: ood_eval_data.pkl\")\n",
    "\n",
    "# # Save Zero-Shot\n",
    "# print(\"\\n\" + \"-\"*60)\n",
    "# print(f\"Saving Zero-Shot (Unseen) - {zeroshot_samples} total samples\")\n",
    "# print(\"-\"*60)\n",
    "\n",
    "# for lang, df in zeroshot_eval_data.items():\n",
    "#     output_file = f\"{output_dir}/zero_shot_{lang}.csv\"\n",
    "#     df.to_csv(output_file, index=False)\n",
    "#     print(f\"  Saved: zero_shot_{lang}.csv ({len(df)} samples)\")\n",
    "\n",
    "# zeroshot_pickle = f\"{output_dir}/zero_shot_eval_data.pkl\"\n",
    "# with open(zeroshot_pickle, 'wb') as f:\n",
    "#     pickle.dump(zeroshot_eval_data, f)\n",
    "# print(f\"  Saved: zero_shot_eval_data.pkl\")\n",
    "\n",
    "# # Save metadata\n",
    "# print(\"\\n\" + \"-\"*60)\n",
    "# print(\"Saving Metadata\")\n",
    "# print(\"-\"*60)\n",
    "\n",
    "# metadata = {\n",
    "#     \"timestamp\": datetime.now().isoformat(),\n",
    "#     \"nrows_per_language\": nrows_per_lang,\n",
    "#     \"in_distribution\": {\n",
    "#         \"dataset\": \"TyDi\",\n",
    "#         \"type\": \"in-distribution\",\n",
    "#         \"total_samples\": tydi_samples,\n",
    "#         \"languages\": list(tydi_eval_data.keys()),\n",
    "#         \"per_language\": {lang: len(df) for lang, df in tydi_eval_data.items()}\n",
    "#     },\n",
    "#     \"out_of_distribution\": {\n",
    "#         \"dataset\": \"mMARCO\",\n",
    "#         \"type\": \"out-of-distribution\",\n",
    "#         \"total_samples\": ood_samples,\n",
    "#         \"languages\": list(ood_eval_data.keys()),\n",
    "#         \"per_language\": {lang: len(df) for lang, df in ood_eval_data.items()}\n",
    "#     },\n",
    "#     \"zero_shot\": {\n",
    "#         \"dataset\": \"mMARCO\",\n",
    "#         \"type\": \"zero-shot\",\n",
    "#         \"total_samples\": zeroshot_samples,\n",
    "#         \"languages\": list(zeroshot_eval_data.keys()),\n",
    "#         \"per_language\": {lang: len(df) for lang, df in zeroshot_eval_data.items()}\n",
    "#     }\n",
    "# }\n",
    "\n",
    "# metadata_file = f\"{output_dir}/metadata.json\"\n",
    "# with open(metadata_file, 'w') as f:\n",
    "#     json.dump(metadata, f, indent=2)\n",
    "# print(f\"  Saved: metadata.json\")\n",
    "\n",
    "# # Summary\n",
    "# print(\"\\n\" + \"=\"*60)\n",
    "# print(\"SAVE SUMMARY\")\n",
    "# print(\"=\"*60)\n",
    "\n",
    "# print(f\"\\nDirectory structure:\")\n",
    "# print(f\"\\nevaluation_datasets/\")\n",
    "# print(f\"â””â”€â”€ {nrows_per_lang}/\")\n",
    "# print(f\"    â”œâ”€â”€ tydi_swahili.csv\")\n",
    "# print(f\"    â”œâ”€â”€ tydi_bengali.csv\")\n",
    "# print(f\"    â”œâ”€â”€ tydi_telugu.csv\")\n",
    "# print(f\"    â”œâ”€â”€ tydi_eval_data.pkl\")\n",
    "# print(f\"    â”œâ”€â”€ ood_arabic.csv\")\n",
    "# print(f\"    â”œâ”€â”€ ood_japanese.csv\")\n",
    "# print(f\"    â”œâ”€â”€ ood_eval_data.pkl\")\n",
    "# print(f\"    â”œâ”€â”€ zero_shot_chinese.csv\")\n",
    "# print(f\"    â”œâ”€â”€ zero_shot_eval_data.pkl\")\n",
    "# print(f\"    â””â”€â”€ metadata.json\")\n",
    "\n",
    "# # Verify files\n",
    "# print(\"\\n\" + \"-\"*60)\n",
    "# print(\"File Verification\")\n",
    "# print(\"-\"*60)\n",
    "\n",
    "# total_size = 0\n",
    "# print(f\"\\n{nrows_per_lang}/ (All datasets):\")\n",
    "# for file in sorted(os.listdir(output_dir)):\n",
    "#     file_path = os.path.join(output_dir, file)\n",
    "#     file_size = os.path.getsize(file_path) / 1024\n",
    "#     total_size += file_size\n",
    "#     print(f\"  {file}: {file_size:.2f} KB\")\n",
    "# print(f\"  Total: {total_size:.2f} KB\")\n",
    "\n",
    "# print(\"\\n\" + \"=\"*60)\n",
    "# print(\"All datasets saved successfully\")\n",
    "# print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7b1f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "DATASET PREVIEW & VALIDATION\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "1. IN-DISTRIBUTION: Mr. TyDi\n",
      "============================================================\n",
      "\n",
      "ðŸ“ Language: SWAHILI\n",
      "   Total samples: 49\n",
      "   Columns: ['query', 'passage']\n",
      "   Shape: (49, 2)\n",
      "\n",
      "   Sample data:\n",
      "   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "   Sample 1:\n",
      "   Query (32 chars):\n",
      "   Je,Sarah Wayne Callies ana mume?...\n",
      "\n",
      "   Passage (357 chars):\n",
      "   Mnamo Juni 21, 2002, Callies alifunga ndoa na Josh Winterhalt, aliyekutana nae katika chuo cha Dartmouth. Winterhalt ni mwalimu wa sanaa. Ilipofika Ja...\n",
      "\n",
      "   Quality Check:\n",
      "   âœ“ Null values: 0\n",
      "   âœ“ Avg query length: 42 chars\n",
      "   âœ“ Avg passage length: 402 chars\n",
      "   âœ“ Min/Max passage: 54/1195\n",
      "\n",
      "ðŸ“ Language: BENGALI\n",
      "   Total samples: 49\n",
      "   Columns: ['query', 'passage']\n",
      "   Shape: (49, 2)\n",
      "\n",
      "   Sample data:\n",
      "   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "   Sample 1:\n",
      "   Query (116 chars):\n",
      "   à¦ªà¦¶à§à¦šà¦¿à¦® à¦­à¦¾à¦°à¦¤à§‡à¦° à¦®à¦¹à¦¾à¦°à¦¾à¦·à§à¦Ÿà§à¦° à¦°à¦¾à¦œà§à¦¯à§‡à¦° à¦®à§à¦®à§à¦¬à¦¾à¦‡ à¦¶à¦¹à¦°à§‡ à¦¨à¦¿à¦°à§à¦®à¦¿à¦¤ à¦—à§‡à¦Ÿà¦“à¦¯à¦¼à§‡ à¦…à¦¬ à¦‡à¦¨à§à¦¡à¦¿à¦¯à¦¼à¦¾ à¦¸à§à¦¥à¦¾à¦ªà¦¤à§à¦¯à¦Ÿà¦¿à¦° à¦­à¦¿à¦¤à§à¦¤à¦¿à¦ªà§à¦°à¦¸à§à¦¤à¦° à¦¸à§à¦¥à¦¾à¦ªà¦¨ à¦•à¦°à§‡à¦¨ à¦•à§‡ ?...\n",
      "\n",
      "   Passage (615 chars):\n",
      "   à¦¦à¦¿à¦²à§à¦²à§€ à¦¦à¦°à§à¦¬à¦¾à¦° à¦¤à§ˆà¦°à§€à¦° à¦ªà§‚à¦°à§à¦¬à§‡, à¦—à§‡à¦Ÿà¦“à¦¯à¦¼à§‡ à¦…à¦¬ à¦‡à¦¨à§à¦¡à¦¿à¦¯à¦¼à¦¾ à§§à§¯à§§à§§ à¦¸à¦¾à¦²à§‡ à¦•à¦¿à¦‚ à¦œà¦°à§à¦œ à¦«à¦¾à¦‡à¦­ à¦à¦¬à¦‚ à¦•à§à¦¨à¦¿ à¦®à§‡à¦°à¦¿ à¦®à§à¦®à§à¦¬à¦¾à¦‡ à¦†à¦—à¦®à¦¨à§‡à¦° à¦¸à§à¦®à§ƒà¦¤à¦¿ à¦°à¦•à§à¦·à¦¾à¦°à§à¦¥à§‡ à¦¨à¦¿à¦°à§à¦®à¦¾à¦£ à¦•à¦°à¦¾ à¦¹à¦¯à¦¼à§‡à¦›à¦¿à¦²à¥¤ à¦•à¦¿à¦¨à§à¦¤à§ à¦¤à¦¾à¦°à¦¾...\n",
      "\n",
      "   Quality Check:\n",
      "   âœ“ Null values: 0\n",
      "   âœ“ Avg query length: 50 chars\n",
      "   âœ“ Avg passage length: 584 chars\n",
      "   âœ“ Min/Max passage: 136/1767\n",
      "\n",
      "ðŸ“ Language: TELUGU\n",
      "   Total samples: 49\n",
      "   Columns: ['query', 'passage']\n",
      "   Shape: (49, 2)\n",
      "\n",
      "   Sample data:\n",
      "   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "   Sample 1:\n",
      "   Query (28 chars):\n",
      "   à°®à°¹à°¾ à°¸à°®à±à°¦à±à°°à°¾à°²à± à°Žà°¨à±à°¨à°¿ à°‰à°¨à±à°¨à°¾à°¯à°¿?...\n",
      "\n",
      "   Passage (630 chars):\n",
      "   à°®à°¹à°¾ à°¸à°®à±à°¦à±à°°à°‚ à°²à±‡à°¦à°¾ à°®à°¹à°¾à°¸à°¾à°—à°°à°‚ (Ocean), à°­à±‚à°—à±‹à°³à°‚ à°¯à±Šà°•à±à°• à°œà°²à°¾à°µà°°à°£à°‚à°²à±‹ à°ªà±à°°à°§à°¾à°¨ à°­à°¾à°—à°‚. à°‰à°ªà±à°ªà± à°¨à±€à°Ÿà°¿à°¤à±‹ à°¨à°¿à°‚à°¡à°¿à°¨ à°ˆ à°®à°¹à°¾ à°¸à°®à±à°¦à±à°°à°¾à°²à± à°­à±‚à°®à°¿ à°‰à°ªà°°à°¿à°¤à°²à°®à± à°ªà±ˆ 71% à°ªà±ˆà°—à°¾ à°µà°¿à°¸à±à°¤à°°à°¿à°‚à°šà°¿ à°‰à°¨à±à°¨à°¾à°¯...\n",
      "\n",
      "   Quality Check:\n",
      "   âœ“ Null values: 0\n",
      "   âœ“ Avg query length: 38 chars\n",
      "   âœ“ Avg passage length: 517 chars\n",
      "   âœ“ Min/Max passage: 138/1504\n",
      "\n",
      "============================================================\n",
      "2. OUT-OF-DISTRIBUTION: mMARCO\n",
      "============================================================\n",
      "\n",
      "âš ï¸  No mMARCO data loaded!\n",
      "\n",
      "============================================================\n",
      "3. ZERO-SHOT: Unseen Languages\n",
      "============================================================\n",
      "\n",
      "âš ï¸  No zero-shot data loaded!\n",
      "\n",
      "============================================================\n",
      "SUMMARY STATISTICS\n",
      "============================================================\n",
      "\n",
      "   Dataset Type Dataset Name Language  Samples Avg Query Len Avg Passage Len\n",
      "In-Distribution         TyDi  swahili       49            42             402\n",
      "In-Distribution         TyDi  bengali       49            50             584\n",
      "In-Distribution         TyDi   telugu       49            38             517\n",
      "\n",
      "============================================================\n",
      "DETAILED SAMPLE INSPECTION\n",
      "============================================================\n",
      "\n",
      "====================================================================================================\n",
      "TyDi (In-Distribution)\n",
      "====================================================================================================\n",
      "\n",
      "Language: swahili (showing first 2 samples)\n",
      "\n",
      "â”Œâ”€ Sample 1 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "â”‚\n",
      "â”‚ QUERY:\n",
      "â”‚   Je,Sarah Wayne Callies ana mume?\n",
      "â”‚\n",
      "â”‚ PASSAGE:\n",
      "â”‚   Mnamo Juni 21, 2002, Callies alifunga ndoa na Josh Winterhalt, aliyekutana nae katika chuo cha Dartm\n",
      "â”‚   outh. Winterhalt ni mwalimu wa sanaa. Ilipofika Januari 23, 2007, msemaje wake alitangaza kuwa wawil\n",
      "â”‚   [...157 more chars...]\n",
      "â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "â”Œâ”€ Sample 2 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "â”‚\n",
      "â”‚ QUERY:\n",
      "â”‚   Je,Thiago Silva alianza kucheza soka mwaka upi?\n",
      "â”‚\n",
      "â”‚ PASSAGE:\n",
      "â”‚   Kama kijana, Silva aliingizwa kwenye shule iliyo jirani ya Campo Grande ya Rio - kwa usawa shule ya \n",
      "â”‚   kulisha kwa Fluminense. Alipokuwa na umri wa miaka 14, Silva alimvutia kocha wa Fluminense Maurinho \n",
      "â”‚   [...360 more chars...]\n",
      "â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "âœ… Dataset preview complete!\n"
     ]
    }
   ],
   "source": [
    "# Preview and validate all evaluation datasets\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DATASET PREVIEW & VALIDATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# ============================================================\n",
    "# 1. IN-DISTRIBUTION: TyDi\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"1. IN-DISTRIBUTION: Mr. TyDi\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if tydi_eval_data:\n",
    "    for lang, df in tydi_eval_data.items():\n",
    "        print(f\"\\nðŸ“ Language: {lang.upper()}\")\n",
    "        print(f\"   Total samples: {len(df)}\")\n",
    "        print(f\"   Columns: {df.columns.tolist()}\")\n",
    "        print(f\"   Shape: {df.shape}\")\n",
    "        print(f\"\\n   Sample data:\")\n",
    "        print(f\"   {'â”€'*100}\")\n",
    "        \n",
    "        # Show first sample\n",
    "        sample_idx = 0\n",
    "        print(f\"\\n   Sample {sample_idx + 1}:\")\n",
    "        print(f\"   Query ({len(df.iloc[sample_idx]['query'])} chars):\")\n",
    "        print(f\"   {df.iloc[sample_idx]['query'][:150]}...\")\n",
    "        print(f\"\\n   Passage ({len(df.iloc[sample_idx]['passage'])} chars):\")\n",
    "        print(f\"   {df.iloc[sample_idx]['passage'][:150]}...\")\n",
    "        \n",
    "        # Data quality\n",
    "        print(f\"\\n   Quality Check:\")\n",
    "        print(f\"   âœ“ Null values: {df.isnull().sum().sum()}\")\n",
    "        print(f\"   âœ“ Avg query length: {df['query'].str.len().mean():.0f} chars\")\n",
    "        print(f\"   âœ“ Avg passage length: {df['passage'].str.len().mean():.0f} chars\")\n",
    "        print(f\"   âœ“ Min/Max passage: {df['passage'].str.len().min()}/{df['passage'].str.len().max()}\")\n",
    "else:\n",
    "    print(\"\\nâš ï¸  No TyDi data loaded!\")\n",
    "\n",
    "# ============================================================\n",
    "# 2. OUT-OF-DISTRIBUTION: mMARCO\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"2. OUT-OF-DISTRIBUTION: mMARCO\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if mmarco_eval_data:\n",
    "    for lang, df in mmarco_eval_data.items():\n",
    "        print(f\"\\nðŸ“ Language: {lang.upper()}\")\n",
    "        print(f\"   Total samples: {len(df)}\")\n",
    "        print(f\"   Columns: {df.columns.tolist()}\")\n",
    "        print(f\"   Shape: {df.shape}\")\n",
    "        print(f\"\\n   Sample data:\")\n",
    "        print(f\"   {'â”€'*100}\")\n",
    "        \n",
    "        # Show first sample\n",
    "        sample_idx = 0\n",
    "        print(f\"\\n   Sample {sample_idx + 1}:\")\n",
    "        print(f\"   Query ({len(df.iloc[sample_idx]['query'])} chars):\")\n",
    "        print(f\"   {df.iloc[sample_idx]['query'][:150]}...\")\n",
    "        print(f\"\\n   Passage ({len(df.iloc[sample_idx]['passage'])} chars):\")\n",
    "        print(f\"   {df.iloc[sample_idx]['passage'][:150]}...\")\n",
    "        \n",
    "        # Data quality\n",
    "        print(f\"\\n   Quality Check:\")\n",
    "        print(f\"   âœ“ Null values: {df.isnull().sum().sum()}\")\n",
    "        print(f\"   âœ“ Avg query length: {df['query'].str.len().mean():.0f} chars\")\n",
    "        print(f\"   âœ“ Avg passage length: {df['passage'].str.len().mean():.0f} chars\")\n",
    "        print(f\"   âœ“ Min/Max passage: {df['passage'].str.len().min()}/{df['passage'].str.len().max()}\")\n",
    "else:\n",
    "    print(\"\\nâš ï¸  No mMARCO data loaded!\")\n",
    "\n",
    "# ============================================================\n",
    "# 3. ZERO-SHOT: Unseen Languages\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"3. ZERO-SHOT: Unseen Languages\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if zero_shot_eval_data:\n",
    "    for lang, df in zero_shot_eval_data.items():\n",
    "        print(f\"\\nðŸ“ Language: {lang.upper()} (ZERO-SHOT)\")\n",
    "        print(f\"   Total samples: {len(df)}\")\n",
    "        print(f\"   Columns: {df.columns.tolist()}\")\n",
    "        print(f\"   Shape: {df.shape}\")\n",
    "        print(f\"\\n   Sample data:\")\n",
    "        print(f\"   {'â”€'*100}\")\n",
    "        \n",
    "        # Show first sample\n",
    "        sample_idx = 0\n",
    "        print(f\"\\n   Sample {sample_idx + 1}:\")\n",
    "        print(f\"   Query ({len(df.iloc[sample_idx]['query'])} chars):\")\n",
    "        print(f\"   {df.iloc[sample_idx]['query'][:150]}...\")\n",
    "        print(f\"\\n   Passage ({len(df.iloc[sample_idx]['passage'])} chars):\")\n",
    "        print(f\"   {df.iloc[sample_idx]['passage'][:150]}...\")\n",
    "        \n",
    "        # Data quality\n",
    "        print(f\"\\n   Quality Check:\")\n",
    "        print(f\"   âœ“ Null values: {df.isnull().sum().sum()}\")\n",
    "        print(f\"   âœ“ Avg query length: {df['query'].str.len().mean():.0f} chars\")\n",
    "        print(f\"   âœ“ Avg passage length: {df['passage'].str.len().mean():.0f} chars\")\n",
    "        print(f\"   âœ“ Min/Max passage: {df['passage'].str.len().min()}/{df['passage'].str.len().max()}\")\n",
    "else:\n",
    "    print(\"\\nâš ï¸  No zero-shot data loaded!\")\n",
    "\n",
    "# ============================================================\n",
    "# Summary Statistics\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SUMMARY STATISTICS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "summary_stats = []\n",
    "\n",
    "# TyDi stats\n",
    "for lang, df in tydi_eval_data.items():\n",
    "    summary_stats.append({\n",
    "        \"Dataset Type\": \"In-Distribution\",\n",
    "        \"Dataset Name\": \"TyDi\",\n",
    "        \"Language\": lang,\n",
    "        \"Samples\": len(df),\n",
    "        \"Avg Query Len\": f\"{df['query'].str.len().mean():.0f}\",\n",
    "        \"Avg Passage Len\": f\"{df['passage'].str.len().mean():.0f}\"\n",
    "    })\n",
    "\n",
    "# mMARCO stats\n",
    "for lang, df in mmarco_eval_data.items():\n",
    "    dataset_type = \"Zero-Shot\" if lang in zero_shot_eval_data else \"Out-of-Distribution\"\n",
    "    summary_stats.append({\n",
    "        \"Dataset Type\": dataset_type,\n",
    "        \"Dataset Name\": \"mMARCO\",\n",
    "        \"Language\": lang,\n",
    "        \"Samples\": len(df),\n",
    "        \"Avg Query Len\": f\"{df['query'].str.len().mean():.0f}\",\n",
    "        \"Avg Passage Len\": f\"{df['passage'].str.len().mean():.0f}\"\n",
    "    })\n",
    "\n",
    "if summary_stats:\n",
    "    summary_df = pd.DataFrame(summary_stats)\n",
    "    print(\"\\n\" + summary_df.to_string(index=False))\n",
    "else:\n",
    "    print(\"\\nâš ï¸  No data to summarize!\")\n",
    "\n",
    "# ============================================================\n",
    "# Detailed Sample Inspection\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DETAILED SAMPLE INSPECTION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "all_datasets = {\n",
    "    \"TyDi (In-Distribution)\": tydi_eval_data,\n",
    "    \"mMARCO (Out-of-Distribution)\": mmarco_eval_data,\n",
    "    \"Zero-Shot\": zero_shot_eval_data\n",
    "}\n",
    "\n",
    "for dataset_name, dataset_dict in all_datasets.items():\n",
    "    if not dataset_dict:\n",
    "        continue\n",
    "        \n",
    "    print(f\"\\n{'='*100}\")\n",
    "    print(f\"{dataset_name}\")\n",
    "    print(f\"{'='*100}\")\n",
    "    \n",
    "    # Show 2 samples from first language\n",
    "    first_lang = list(dataset_dict.keys())[0]\n",
    "    df = dataset_dict[first_lang]\n",
    "    \n",
    "    print(f\"\\nLanguage: {first_lang} (showing first 2 samples)\\n\")\n",
    "    \n",
    "    for i in range(min(2, len(df))):\n",
    "        print(f\"â”Œâ”€ Sample {i+1} â”€{'â”€'*95}\")\n",
    "        print(f\"â”‚\")\n",
    "        print(f\"â”‚ QUERY:\")\n",
    "        query_text = df.iloc[i]['query']\n",
    "        # Print in chunks for readability\n",
    "        for j in range(0, len(query_text), 100):\n",
    "            print(f\"â”‚   {query_text[j:j+100]}\")\n",
    "        print(f\"â”‚\")\n",
    "        print(f\"â”‚ PASSAGE:\")\n",
    "        passage_text = df.iloc[i]['passage']\n",
    "        # Print first 200 chars of passage\n",
    "        for j in range(0, min(200, len(passage_text)), 100):\n",
    "            print(f\"â”‚   {passage_text[j:j+100]}\")\n",
    "        if len(passage_text) > 200:\n",
    "            print(f\"â”‚   [...{len(passage_text)-200} more chars...]\")\n",
    "        print(f\"â”‚\")\n",
    "        print(f\"â””{'â”€'*99}\")\n",
    "\n",
    "print(\"\\nâœ… Dataset preview complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "d8c555f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation framework initialized\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "import torch\n",
    "from typing import Dict, List\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "class RetrievalEvaluator:\n",
    "    \"\"\"Evaluate retrieval performance with FAISS\"\"\"\n",
    "    \n",
    "    def __init__(self, model_path: str, base_model: str = \"bert-base-multilingual-cased\"):\n",
    "        \"\"\"\n",
    "        Initialize evaluator with trained DPR model.\n",
    "        \n",
    "        Args:\n",
    "            model_path: Path to trained model\n",
    "            base_model: Base model name for tokenizer\n",
    "        \"\"\"\n",
    "        print(f\"\\nLoading model: {model_path}\")\n",
    "        \n",
    "        try:\n",
    "            from simpletransformers.retrieval import RetrievalModel, RetrievalArgs\n",
    "            from transformers import AutoTokenizer, AutoModel\n",
    "            \n",
    "            # Load model configuration\n",
    "            args = RetrievalArgs()\n",
    "            args.max_seq_length = 256\n",
    "            args.fp16 = USE_MIXED_PRECISION if 'USE_MIXED_PRECISION' in globals() else False\n",
    "            \n",
    "            # Load the model\n",
    "            self.model = RetrievalModel(\n",
    "                model_type=\"custom\",\n",
    "                model_name=model_path,\n",
    "                args=args,\n",
    "                use_cuda=torch.cuda.is_available()\n",
    "            )\n",
    "            \n",
    "            # Get tokenizer\n",
    "            self.tokenizer = AutoTokenizer.from_pretrained(base_model)\n",
    "            self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "            \n",
    "            print(\"Model loaded successfully\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading model: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def encode_texts(\n",
    "        self, \n",
    "        texts: List[str], \n",
    "        is_query: bool = True,\n",
    "        batch_size: int = 8\n",
    "    ) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Encode texts to embeddings using the model.\n",
    "        \n",
    "        Args:\n",
    "            texts: List of texts to encode\n",
    "            is_query: Whether texts are queries (True) or passages (False)\n",
    "            batch_size: Batch size for encoding\n",
    "        \n",
    "        Returns:\n",
    "            Embeddings array of shape (len(texts), embedding_dim)\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Get encoder\n",
    "            encoder = self.model.query_encoder if is_query else self.model.context_encoder\n",
    "            encoder.eval()\n",
    "            encoder.to(self.device)\n",
    "            \n",
    "            embeddings = []\n",
    "            \n",
    "            for i in range(0, len(texts), batch_size):\n",
    "                batch = texts[i:i + batch_size]\n",
    "                \n",
    "                # Tokenize\n",
    "                inputs = self.tokenizer(\n",
    "                    batch,\n",
    "                    padding=True,\n",
    "                    truncation=True,\n",
    "                    max_length=256,\n",
    "                    return_tensors=\"pt\"\n",
    "                )\n",
    "                \n",
    "                # Move to device\n",
    "                inputs = {k: v.to(self.device) for k, v in inputs.items()}\n",
    "                \n",
    "                # Encode\n",
    "                with torch.no_grad():\n",
    "                    outputs = encoder(**inputs)\n",
    "                    batch_embeddings = outputs.pooler_output.cpu().numpy()\n",
    "                    embeddings.append(batch_embeddings)\n",
    "            \n",
    "            # Combine embeddings\n",
    "            if embeddings:\n",
    "                result = np.vstack(embeddings)\n",
    "            else:\n",
    "                result = np.zeros((len(texts), 768))\n",
    "            \n",
    "            # Ensure C-contiguous float32 for FAISS\n",
    "            return np.ascontiguousarray(result, dtype=np.float32)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Encoding error: {e}\")\n",
    "            return np.zeros((len(texts), 768), dtype=np.float32)\n",
    "    \n",
    "    def evaluate_retrieval(\n",
    "        self,\n",
    "        eval_data,\n",
    "        corpus: List[str],\n",
    "        top_k: int = 10\n",
    "    ) -> Dict:\n",
    "        \"\"\"\n",
    "        Evaluate retrieval performance on test data.\n",
    "        \n",
    "        Args:\n",
    "            eval_data: DataFrame with 'query' and 'passage' columns\n",
    "            corpus: List of all passages for retrieval\n",
    "            top_k: Number of top results to retrieve\n",
    "        \n",
    "        Returns:\n",
    "            Dictionary with MRR@K, Recall@K, nDCG@K metrics\n",
    "        \"\"\"\n",
    "        try:\n",
    "            queries = eval_data['query'].tolist()\n",
    "            gold_passages = eval_data['passage'].tolist()\n",
    "            \n",
    "            if not queries or not corpus:\n",
    "                return {\n",
    "                    'MRR@10': 0.0,\n",
    "                    'Recall@10': 0.0,\n",
    "                    'nDCG@10': 0.0\n",
    "                }\n",
    "            \n",
    "            print(f\"  Encoding {len(queries)} queries...\")\n",
    "            query_embeddings = self.encode_texts(queries, is_query=True)\n",
    "            \n",
    "            print(f\"  Encoding {len(corpus)} passages...\")\n",
    "            passage_embeddings = self.encode_texts(corpus, is_query=False)\n",
    "            \n",
    "            if query_embeddings.size == 0 or passage_embeddings.size == 0:\n",
    "                print(\"  Error: Empty embeddings\")\n",
    "                return {\n",
    "                    'MRR@10': 0.0,\n",
    "                    'Recall@10': 0.0,\n",
    "                    'nDCG@10': 0.0\n",
    "                }\n",
    "            \n",
    "            # Ensure arrays are C-contiguous float32\n",
    "            query_embeddings = np.ascontiguousarray(query_embeddings, dtype=np.float32)\n",
    "            passage_embeddings = np.ascontiguousarray(passage_embeddings, dtype=np.float32)\n",
    "            \n",
    "            print(f\"  Query embeddings: {query_embeddings.shape}\")\n",
    "            print(f\"  Passage embeddings: {passage_embeddings.shape}\")\n",
    "            \n",
    "            # Build FAISS index\n",
    "            dimension = passage_embeddings.shape[1]\n",
    "            index = faiss.IndexFlatIP(dimension)\n",
    "            \n",
    "            # Normalize for inner product\n",
    "            faiss.normalize_L2(query_embeddings)\n",
    "            faiss.normalize_L2(passage_embeddings)\n",
    "            \n",
    "            index.add(passage_embeddings)\n",
    "            \n",
    "            print(f\"  Retrieving top-{top_k}...\")\n",
    "            distances, indices = index.search(query_embeddings, top_k)\n",
    "            \n",
    "            # Compute metrics\n",
    "            mrr_sum = 0.0\n",
    "            recall_sum = 0.0\n",
    "            ndcg_sum = 0.0\n",
    "            \n",
    "            for query_idx, gold_passage in enumerate(gold_passages):\n",
    "                retrieved_indices = indices[query_idx]\n",
    "                retrieved_passages = [corpus[int(idx)] for idx in retrieved_indices]\n",
    "                \n",
    "                if gold_passage in retrieved_passages:\n",
    "                    rank = retrieved_passages.index(gold_passage) + 1\n",
    "                    mrr_sum += 1.0 / rank\n",
    "                    recall_sum += 1.0\n",
    "                    ndcg_sum += 1.0 / np.log2(rank + 1)\n",
    "            \n",
    "            num_queries = len(queries)\n",
    "            mrr = mrr_sum / num_queries if num_queries > 0 else 0.0\n",
    "            recall = recall_sum / num_queries if num_queries > 0 else 0.0\n",
    "            ndcg = ndcg_sum / num_queries if num_queries > 0 else 0.0\n",
    "            \n",
    "            return {\n",
    "                'MRR@10': round(mrr, 4),\n",
    "                'Recall@10': round(recall, 4),\n",
    "                'nDCG@10': round(ndcg, 4)\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error during evaluation: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            return {\n",
    "                'MRR@10': 0.0,\n",
    "                'Recall@10': 0.0,\n",
    "                'nDCG@10': 0.0\n",
    "            }\n",
    "\n",
    "\n",
    "print(\"Evaluation framework initialized\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "6a54ce6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "PHASE 5: COMPLETE MULTILINGUAL EVALUATION\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "IN-DISTRIBUTION EVALUATION: Mr. TyDi\n",
      "============================================================\n",
      "\n",
      "Model: BM25 Baseline\n",
      "\n",
      "Loading model: ./models/dpr_bm25_baseline_tydi_final\n",
      "Model loaded successfully\n",
      "  Language: swahili...   Encoding 50 queries...\n",
      "  Encoding 48 passages...\n",
      "  Query embeddings: (50, 768)\n",
      "  Passage embeddings: (48, 768)\n",
      "  Retrieving top-10...\n",
      "MRR=0.5044\n",
      "  Language: bengali...   Encoding 50 queries...\n",
      "  Encoding 48 passages...\n",
      "  Query embeddings: (50, 768)\n",
      "  Passage embeddings: (48, 768)\n",
      "  Retrieving top-10...\n",
      "MRR=0.7673\n",
      "  Average: MRR=0.6359, Recall=0.9100\n",
      "\n",
      "Model: LLM Enhanced\n",
      "\n",
      "Loading model: ./models/dpr_llm_enhanced_tydi_final\n",
      "Model loaded successfully\n",
      "  Language: swahili...   Encoding 50 queries...\n",
      "  Encoding 48 passages...\n",
      "  Query embeddings: (50, 768)\n",
      "  Passage embeddings: (48, 768)\n",
      "  Retrieving top-10...\n",
      "MRR=0.4991\n",
      "  Language: bengali...   Encoding 50 queries...\n",
      "  Encoding 48 passages...\n",
      "  Query embeddings: (50, 768)\n",
      "  Passage embeddings: (48, 768)\n",
      "  Retrieving top-10...\n",
      "MRR=0.8029\n",
      "  Average: MRR=0.6510, Recall=0.9300\n",
      "\n",
      "Model: RAG Enhanced\n",
      "\n",
      "Loading model: ./models/dpr_rag_enhanced_tydi_final\n",
      "Model loaded successfully\n",
      "  Language: swahili...   Encoding 50 queries...\n",
      "  Encoding 48 passages...\n",
      "  Query embeddings: (50, 768)\n",
      "  Passage embeddings: (48, 768)\n",
      "  Retrieving top-10...\n",
      "MRR=0.5265\n",
      "  Language: bengali...   Encoding 50 queries...\n",
      "  Encoding 48 passages...\n",
      "  Query embeddings: (50, 768)\n",
      "  Passage embeddings: (48, 768)\n",
      "  Retrieving top-10...\n",
      "MRR=0.7785\n",
      "  Average: MRR=0.6525, Recall=0.9200\n",
      "\n",
      "In-Distribution: 3 models evaluated\n",
      "\n",
      "============================================================\n",
      "OUT-OF-DISTRIBUTION EVALUATION: mMARCO\n",
      "============================================================\n",
      "\n",
      "Model: BM25 Baseline\n",
      "\n",
      "Loading model: ./models/dpr_bm25_baseline_tydi_final\n",
      "Model loaded successfully\n",
      "  Language: arabic...   Encoding 2 queries...\n",
      "  Encoding 2 passages...\n",
      "  Query embeddings: (2, 768)\n",
      "  Passage embeddings: (2, 768)\n",
      "  Retrieving top-10...\n",
      "MRR=1.0000\n",
      "  Language: japanese...   Encoding 2 queries...\n",
      "  Encoding 2 passages...\n",
      "  Query embeddings: (2, 768)\n",
      "  Passage embeddings: (2, 768)\n",
      "  Retrieving top-10...\n",
      "MRR=1.0000\n",
      "  Average: MRR=1.0000, Recall=1.0000\n",
      "\n",
      "Model: LLM Enhanced\n",
      "\n",
      "Loading model: ./models/dpr_llm_enhanced_tydi_final\n",
      "Model loaded successfully\n",
      "  Language: arabic...   Encoding 2 queries...\n",
      "  Encoding 2 passages...\n",
      "  Query embeddings: (2, 768)\n",
      "  Passage embeddings: (2, 768)\n",
      "  Retrieving top-10...\n",
      "MRR=1.0000\n",
      "  Language: japanese...   Encoding 2 queries...\n",
      "  Encoding 2 passages...\n",
      "  Query embeddings: (2, 768)\n",
      "  Passage embeddings: (2, 768)\n",
      "  Retrieving top-10...\n",
      "MRR=1.0000\n",
      "  Average: MRR=1.0000, Recall=1.0000\n",
      "\n",
      "Model: RAG Enhanced\n",
      "\n",
      "Loading model: ./models/dpr_rag_enhanced_tydi_final\n",
      "Model loaded successfully\n",
      "  Language: arabic...   Encoding 2 queries...\n",
      "  Encoding 2 passages...\n",
      "  Query embeddings: (2, 768)\n",
      "  Passage embeddings: (2, 768)\n",
      "  Retrieving top-10...\n",
      "MRR=1.0000\n",
      "  Language: japanese...   Encoding 2 queries...\n",
      "  Encoding 2 passages...\n",
      "  Query embeddings: (2, 768)\n",
      "  Passage embeddings: (2, 768)\n",
      "  Retrieving top-10...\n",
      "MRR=1.0000\n",
      "  Average: MRR=1.0000, Recall=1.0000\n",
      "\n",
      "Out-of-Distribution: 3 models evaluated\n",
      "\n",
      "============================================================\n",
      "ZERO-SHOT EVALUATION: Unseen Languages\n",
      "============================================================\n",
      "\n",
      "Model: BM25 Baseline\n",
      "\n",
      "Loading model: ./models/dpr_bm25_baseline_tydi_final\n",
      "Model loaded successfully\n",
      "  Language: chinese (unseen)...   Encoding 2 queries...\n",
      "  Encoding 2 passages...\n",
      "  Query embeddings: (2, 768)\n",
      "  Passage embeddings: (2, 768)\n",
      "  Retrieving top-10...\n",
      "MRR=1.0000\n",
      "  Average: MRR=1.0000, Recall=1.0000\n",
      "\n",
      "Model: LLM Enhanced\n",
      "\n",
      "Loading model: ./models/dpr_llm_enhanced_tydi_final\n",
      "Model loaded successfully\n",
      "  Language: chinese (unseen)...   Encoding 2 queries...\n",
      "  Encoding 2 passages...\n",
      "  Query embeddings: (2, 768)\n",
      "  Passage embeddings: (2, 768)\n",
      "  Retrieving top-10...\n",
      "MRR=1.0000\n",
      "  Average: MRR=1.0000, Recall=1.0000\n",
      "\n",
      "Model: RAG Enhanced\n",
      "\n",
      "Loading model: ./models/dpr_rag_enhanced_tydi_final\n",
      "Model loaded successfully\n",
      "  Language: chinese (unseen)...   Encoding 2 queries...\n",
      "  Encoding 2 passages...\n",
      "  Query embeddings: (2, 768)\n",
      "  Passage embeddings: (2, 768)\n",
      "  Retrieving top-10...\n",
      "MRR=1.0000\n",
      "  Average: MRR=1.0000, Recall=1.0000\n",
      "\n",
      "Zero-Shot: 3 models evaluated\n",
      "\n",
      "============================================================\n",
      "COMPLETE EVALUATION RESULTS\n",
      "============================================================\n",
      "\n",
      "        Model TyDi MRR TyDi Recall OOD MRR OOD Recall Zero-Shot MRR Zero-Shot Recall\n",
      "BM25 Baseline   0.6359      0.9100  1.0000     1.0000        1.0000           1.0000\n",
      " LLM Enhanced   0.6510      0.9300  1.0000     1.0000        1.0000           1.0000\n",
      " RAG Enhanced   0.6525      0.9200  1.0000     1.0000        1.0000           1.0000\n",
      "\n",
      "============================================================\n",
      "GENERATING VISUALIZATIONS\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABcQAAAqOCAYAAAC7QlRtAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjcsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvTLEjVAAAAAlwSFlzAAAPYQAAD2EBqD+naQABAABJREFUeJzs3XuQXnV9x/Hvhs1lcyGQrLlsQrIhIWyiYIqJxEwcBuIFTGHSQG8yLdI66DgVWzvDQMeq7XQYOtrRWi3WKTV2+IOxLjdrRRJpK5ZJJBkJrcTcKZgFQ1ZMImKup39keIZNNhUkGMnn9ZrZybN7fuc8Z09+z8zOe8/+nramaZoCAAAAAIBT3JCTfQIAAAAAAPDLIIgDAAAAABBBEAcAAAAAIIIgDgAAAABABEEcAAAAAIAIgjgAAAAAABEEcQAAAAAAIgjiAAAAAABEEMQBAAAAAIggiAMAAAAAEEEQBwA4Sb71rW/Vu971rnrd615XbW1t1dbWVp///Odf0r533HFHXXDBBdXR0VHjxo2rq666qrZu3TpgzN69e+tP/uRPaurUqTVs2LCaOXNm/cVf/EUdPHhwwLh169bVpZdeWqeffnqNHDmyFi9eXKtWrTrmOf/u7/6u5s6dW8OHD68JEybUH/zBH9QPf/jDX/wCcAxzgsGYF3ByeQ0yGPOCo5kTryENAAAnxac+9ammvb29mT17dlNVTVU1t95668/d7x//8R9b42fMmNGcfvrpTVU1EyZMaJ566qmmaZrm0KFDzUUXXdRUVTN06NDm3HPPbYYMGdJUVfN7v/d7rWOtX7++GTlyZFNVTWdnZzNlypSmqprTTjut+cY3vtEa95GPfKT1nOecc07T0dHRVFXT09PTPPfccyf+4oQyJxiMeQEnl9cggzEvOJo58dohiAMAnCS7du1qfvrTnzbbt29/yT8079u3r+ns7GyqqrnyyiubpmmaHTt2NGPGjGmqqvngBz/YNE3T9Pb2to751a9+tWmapvnMZz7T+tq6deuapmmayy+/vKmqpru7u9mzZ09z4MCB5sILL2yqqjnvvPOapmmap59+uhk6dGhTVc2f/umfNk1z5Ifttra2pqqav/mbv3lVrk8ic4LBmBdwcnkNMhjzgqOZE68dlkwBADhJxo8fXx0dHS9rn4cffrh27dpVVVVXXnllVVV1dXXVwoULq6rqvvvuq6qqr3/961VV1dHRUe9617sGjH9h3MGDB1t/PvmOd7yjxowZU+3t7XXFFVdUVdV///d/V19fX61ataoOHDgw4Bjnn39+zZo1a8Bz8sqZEwzGvICTy2uQwZgXHM2ceO0QxAEAXkOefPLJ1uMJEya0Hk+cOLGqqp544okB48aPH19DhgwZMOaFcbt27arnn3/+uMd6YdxLfU5ODnOCwZgXcHJ5DTIY84KjmRMnhyAOAHAKaJrmhIx5NcZxcpgTDMa8gJPLa5DBmBcczZx4dQniAACvIWeddVbr8c6dO495PG3atAHjdu3aVYcPHz5m/LRp06qzs7P1Z52DHeuFcS/1OTk5zAkGY17AyeU1yGDMC45mTpwcgjgAwK+wJUuWVE9PT910001VVbVgwYIaP358VVX19vZWVVVfX1+tXr26qqouvfTSAf/+7Gc/q3/7t38bMP6F7e3t7bVkyZKqqrr//vtr7969dfDgwbr33nurquq8886rrq6uWrJkSbW3tw84xqOPPlpbtmwZ8Fz8cpgTDMa8gJPLa5DBmBcczZz4FfHLe/9OAABerLe3t5k5c2Yzffr01jvEv+51r2tmzpzZvPvd726apmltu+aaa1r7/cM//ENr/IwZM5rTTz+9qaqms7Oz2bFjR9M0TXPw4MFm8eLFTVU1Q4cObXp6epohQ4Y0VdU6dtM0zSOPPNJ0dHS09p8yZUpTVc1pp53WfP3rX2+Nu+mmm1rPOXv27NY+55xzTvOTn/zkl3PBApgTDMa8gJPLa5DBmBcczZx47RDEAQBOki9+8YutH0SP/rjooouaphn8h+amaZrbb7+9mTdvXjN8+PBm7NixzfLly5tNmzYNGLN79+7m+uuvb7q6upqhQ4c23d3dzUc/+tFm//79A8Z95zvfad7+9rc3o0ePbkaMGNEsWrSo+cY3vjFgzOHDh5tPf/rTTU9PTzN06NCms7Ozueaaa5qnnnrqhF+XZOYEgzEv4OTyGmQw5gVHMydeO9qaJmjFdAAAAAAAYllDHAAAAACACII4AAAAAAARBHEAAAAAACII4gAAAAAARBDEAQAAAACIIIgDAAAAABBBEAcAAAAAIIIgDgAAAABABEEcAAAAAIAIgjgAAAAAABEEcQAAAAAAIgjiAAAAAABEEMQBAAAAAIggiAMAAAAAEEEQBwAAAAAggiAOAAAAAEAEQRwAAAAAgAiCOAAAAAAAEQRxAAAAAAAiCOIAAAAAAEQQxAEAAAAAiCCIAwAAAAAQQRAHAAAAACCCIA4AAAAAQARBHAAAAACACII4AAAAAAARBHEAAAAAACII4gAAAAAARBDEAQAAAACIIIgDAAAAABBBEAcAAAAAIIIgDgAAAABABEEcAAAAAIAIgjgAAAAAABEEcQAAAAAAIgjiAAAAAABEEMQBAAAAAIggiAMAAAAAEEEQBwAAAAAggiAOAAAAAEAEQRwAAAAAgAiCOAAAAAAAEQRxAAAAAAAiCOIAAAAAAEQQxAEAAAAAiCCIAwAAAAAQQRAHAAAAACCCIA4AAAAAQARBHAAAAACACII4AAAAAAARBHEAAAAAACII4gAAAAAARBDEAQAAAACIIIgDAAAAABBBEAcAAAAAIIIgDgAAAABABEEcAAAAAIAIgjgAAAAAABEEcQAAAAAAIgjiAAAAAABEEMQBAAAAAIggiAMAAAAAEEEQBwAAAAAggiAOAAAAAEAEQRwAAAAAgAiCOAAAAAAAEQRxAAAAAAAiCOIAAAAAAEQQxAEAAAAAiCCIAwAAAAAQQRAHAAAAACCCIA4AAAAAQARBHAAAAACACII4AAAAAAARBHEAAAAAACII4gAAAAAARBDEAQAAAACIIIgDAAAAABBBEAcAAAAAIIIgDgAAAABABEEcAAAAAIAIgjgAAAAAABEEcQAAAAAAIgjiAAAAAABEEMQBAAAAAIggiAMAAAAAEEEQBwAAAAAggiAOAAAAAEAEQRwAAAAAgAiCOAAAAAAAEQRxAAAAAAAiCOIAAAAAAEQQxAEAAAAAiCCIAwAAAAAQQRAHAAAAACCCIA4AAAAAQARBHAAAAACACII4AAAAAAARBHEAAAAAACII4gAAAAAARBDEAQAAAACIIIgDAAAAABBBEAcAAAAAIIIgDgAAAABABEEcAAAAAIAIgjgAAAAAABEEcQAAAAAAIgjiAAAAAABEEMQBAAAAAIggiAMAAAAAEEEQBwAAAAAggiAOAAAAAEAEQRwAAAAAgAiCOAAAAAAAEQRxAAAAAAAiCOIAAAAAAEQQxAEAAAAAiCCIAwAAAAAQQRAHAAAAACCCIA4AAAAAQARBHAAAAACACII4AAAAAAARBHEAAAAAACII4gAAAAAARBDEAQAAAACIIIgDAAAAABBBEAcAAAAAIIIgDgAAAABABEEcAAAAAIAIgjgAAAAAABEEcQAAAAAAIgjiAAAAAABEEMQBAAAAAIggiAMAAAAAEEEQBwAAAAAggiAOAAAAAEAEQRwAAAAAgAiCOAAAAAAAEQRxAAAAAAAiCOIAAAAAAEQQxAEAAAAAiCCIAwAAAAAQQRAHAAAAACCCIA4AAAAAQARBHAAAAACACII4AAAAAAARBHEAAAAAACII4gAAAAAARBDEAQAAAACIIIgDAAAAABBBEAcAAAAAIIIgDgAAAABABEEcAAAAAIAIgjgAAAAAABEEcQAAAAAAIgjiAAAAAABEEMQBAAAAAIggiAMAAAAAEEEQBwAAAAAggiAOAAAAAEAEQRwAAAAAgAiCOAAAAAAAEQRxAAAAAAAiCOIAAAAAAEQQxAEAAAAAiCCIAwAAAAAQQRAHAAAAACCCIA4AAAAAQARBHAAAAACACII4AAAAAAARBHEAAAAAACII4gAAAAAARBDEAQAAAACIIIgDAAAAABBBEAcAAAAAIIIgDgAAAABABEEcAAAAAIAIgjgAAAAAABEEcQAAAAAAIgjiAAAAAABEEMQBAAAAAIggiAMAAAAAEEEQBwAAAAAggiAOAAAAAEAEQRwAAAAAgAiCOAAAAAAAEQRxAAAAAAAiCOIAAAAAAEQQxAEAAAAAiCCIAwAAAAAQQRAHAAAAACCCIA4AAAAAQARBHAAAAACACII4AAAAAAARBHEAAAAAACII4gAAAAAARBDEAQAAAACIIIgDAAAAABBBEAcAAAAAIIIgDgAAAABABEEcAAAAAIAIgjgAAAAAABEEcQAAAAAAIgjiAAAAAABEEMQBAAAAAIggiAMAAAAAEEEQBwAAAAAggiAOAAAAAEAEQRwAAAAAgAiCOAAAAAAAEQRxAAAAAAAiCOIAAAAAAEQQxAEAAAAAiCCIAwAAAAAQQRAHAAAAACCCIA4AAAAAQARBHAAAAACACII4AAAAAAARBHEAAAAAACII4gAAAAAARBDEAQAAAACIIIgDAAAAABBBEAcAAAAAIIIgDgAAAABABEEcAAAAAIAIgjgAAAAAABEEcQAAAAAAIgjiAAAAAABEEMQBAAAAAIggiAMAAAAAEEEQBwAAAAAggiAOAAAAAEAEQRwAAAAAgAiCOAAAAAAAEQRxAAAAAAAiCOIAAAAAAEQQxAEAAAAAiCCIAwAAAAAQQRAHAAAAACCCIA4AAAAAQARBHAAAAACACII4AAAAAAARBHEAAAAAACII4gAAAAAARBDEAQAAAACIIIgDAAAAABBBEAcAAAAAIIIgDgAAAABABEEcAAAAAIAIgjgAAAAAABEEcQAAAAAAIgjiAAAAAABEEMQBAAAAAIggiAMAAAAAEEEQBwAAAAAggiAOAAAAAEAEQRwAAAAAgAiCOAAAAAAAEQRxAAAAAAAiCOIAAAAAAEQQxAEAAAAAiCCIAwAAAAAQQRAHAAAAACCCIA4AAAAAQARBHAAAAACACII4AAAAAAARBHEAAAAAACII4gAAAAAARBDEAQAAAACIIIgDAAAAABBBEAcAAAAAIIIgDgAAAABABEEcAAAAAIAIgjgAAAAAABEEcQAAAAAAIgjiAAAAAABEEMQBAAAAAIggiAMAAAAAEEEQBwAAAAAggiAOAAAAAEAEQRwAAAAAgAiCOAAAAAAAEQRxAAAAAAAiCOIAAAAAAEQQxAEAAAAAiCCIAwAAAAAQQRAHAAAAACCCIA4AAAAAQARBHAAAAACACII4AAAAAAARBHEAAAAAACII4gAAAAAARBDEAQAAAACIIIgDAAAAABBBEAcAAAAAIIIgDgAAAABABEEcAAAAAIAIgjgAAAAAABEEcQAAAAAAIgjiAAAAAABEEMQBAAAAAIggiAMAAAAAEEEQBwAAAAAggiAOAAAAAEAEQRwAAAAAgAiCOAAAAAAAEQRxAAAAAAAiCOIAAAAAAEQQxAEAAAAAiCCIAwAAAAAQQRAHAAAAACCCIA4AAAAAQARBHAAAAACACII4AAAAAAARBHEAAAAAACII4gAAAAAARBDEAQAAAACIIIgDAAAAABBBEAcAAAAAIIIgDgAAAABABEEcAAAAAIAIgjgAAAAAABEEcQAAAAAAIgjiAAAAAABEEMQBAAAAAIggiAMAAAAAEEEQBwAAAAAggiAOAAAAAEAEQRwAAAAAgAiCOAAAAAAAEQRxAAAAAAAiCOIAAAAAAEQQxAEAAAAAiCCIAwAAAAAQQRAHAAAAACCCIA4AAAAAQARBHAAAAACACII4AAAAAAARBHEAAAAAACII4gAAAAAARBDEAQAAAACIIIgDAAAAABBBEAcAAAAAIIIgDgAAAABABEEcAAAAAIAIgjgAAAAAABEEcQAAAAAAIgjiAAAAAABEEMQBAAAAAIggiAMAAAAAEEEQBwAAAAAggiAOAAAAAEAEQRwAAAAAgAiCOAAAAAAAEQRxAAAAAAAiCOIAAAAAAEQQxAEAAAAAiCCIAwAAAAAQQRAHAAAAACCCIA4AAAAAQARBHAAAAACACII4AAAAAAARBHEAAAAAACII4gAAAAAARBDEAQAAAACIIIgDAAAAABBBEAcAAAAAIIIgDgAAAABABEEcAAAAAIAIgjgAAAAAABEEcQAAAAAAIgjiAAAAAABEEMQBAAAAAIggiAMAAAAAEEEQBwAAAAAggiAOAAAAAEAEQRwAAAAAgAiCOAAAAAAAEQRxAAAAAAAiCOIAAAAAAEQQxAEAAAAAiCCIAwAAAAAQQRAHAAAAACCCIA4AAAAAQARBHAAAAACACII4AAAAAAARBHEAAAAAACII4gAAAAAARBDEAQAAAACIIIgDAAAAABBBEAcAAAAAIIIgDgAAAABABEEcAAAAAIAIgjgAAAAAABEEcQAAAAAAIgjiAAAAAABEEMQBAAAAAIggiAMAAAAAEEEQBwAAAAAggiAOAAAAAEAEQRwAAAAAgAiCOAAAAAAAEQRxAAAAAAAiCOIAAAAAAEQQxAEAAAAAiCCIAwAAAAAQQRAHAAAAACCCIA4AAAAAQARBHAAAAACACII4AAAAAAARBHEAAAAAACII4gAAAAAARBDEAQAAAACIIIgDAAAAABBBEAcAAAAAIIIgDgAAAABABEEcAAAAAIAIgjgAAAAAABEEcQAAAAAAIgjiAAAAAABEEMQBAAAAAIggiAMAAAAAEEEQBwAAAAAggiAOAAAAAEAEQRwAAAAAgAiCOAAAAAAAEQRxAAAAAAAiCOIAAAAAAEQQxAEAAAAAiCCIAwAAAAAQQRAHAAAAACCCIA4AAAAAQARBHAAAAACACII4AAAAAAARBHEAAAAAACII4gAAAAAARBDEAQAAAACIIIgDAAAAABBBEAcAAAAAIIIgDgAAAABABEEcAAAAAIAIgjgAAAAAABEEcQAAAAAAIgjiAAAAAABEEMQBAAAAAIggiAMAAAAAEEEQBwAAAAAggiAOAAAAAEAEQRwAAAAAgAiCOAAAAAAAEQRxAAAAAAAiCOIAAAAAAEQQxAEAAAAAiCCIAwAAAAAQQRAHAAAAACCCIA4AAAAAQARBHAAAAACACII4AAAAAAARBHEAAAAAACII4gAAAAAARBDEAQAAAACIIIgDAAAAABBBEAcAAAAAIIIgDgAAAABABEEcAAAAAIAIgjgAAAAAABEEcQAAAAAAIgjiAAAAAABEEMQBAAAAAIggiAMAAAAAEEEQBwAAAAAggiAOAAAAAEAEQRwAAAAAgAiCOAAAAAAAEQRxAAAAAAAiCOIAAAAAAEQQxAEAAAAAiCCIAwAAAAAQQRAHAAAAACCCIA4AAAAAQARBHAAAAACACII4AAAAAAARBHEAAAAAACII4gAAAAAARBDEAQAAAACIIIgDAAAAABBBEAcAAAAAIIIgDgAAAABABEEcAAAAAIAIgjgAAAAAABEEcQAAAAAAIgjiAAAAAABEEMQBAAAAAIggiAMAAAAAEEEQBwAAAAAggiAOAAAAAEAEQRwAAAAAgAiCOAAAAAAAEQRxAAAAAAAiCOIAAAAAAEQQxAEAAAAAiCCIAwAAAAAQQRAHAAAAACCCIA4AAAAAQARBHAAAAACACII4AAAAAAARBHEAAAAAACII4gAAAAAARBDEAQAAAACIIIgDAAAAABBBEAcAAAAAIIIgDgAAAABABEEcAAAAAIAIgjgAAAAAABEEcQAAAAAAIgjiAAAAAABEEMQBAAAAAIggiAMAAAAAEEEQBwAAAAAggiAOAAAAAEAEQRwAAAAAgAiCOAAAAAAAEQRxAAAAAAAiCOIAAAAAAEQQxAEAAAAAiCCIAwAAAAAQQRAHAAAAACCCIA4AAAAAQARBHAAAAACACII4AAAAAAARBHEAAAAAACII4gAAAAAARBDEAQAAAACIIIgDAAAAABBBEAcAAAAAIIIgDgAAAABABEEcAAAAAIAIgjgAAAAAABEEcQAAAAAAIgjiAAAAAABEEMQBAAAAAIggiAMAAAAAEEEQBwAAAAAggiAOAAAAAEAEQRwAAAAAgAiCOAAAAAAAEQRxAAAAAAAiCOIAAAAAAEQQxAEAAAAAiCCIAwAAAAAQQRAHAAAAACCCIA4AAAAAQARBHAAAAACACII4AAAAAAARBHEAAAAAACII4gAAAAAARBDEAQAAAACIIIgDAAAAABBBEAcAAAAAIIIgDgAAAABABEEcAAAAAIAIgjgAAAAAABEEcQAAAAAAIgjiAAAAAABEEMQBAAAAAIggiAMAAAAAEEEQBwAAAAAggiAOAAAAAEAEQRwAAAAAgAiCOAAAAAAAEQRxAAAAAAAiCOIAAAAAAEQQxAEAAAAAiCCIAwAAAAAQQRAHAAAAACCCIA4AAAAAQARBHAAAAACACII4AAAAAAARBHEAAAAAACII4gAAAAAARBDEAQAAAACIIIgDAAAAABBBEAcAAAAAIIIgDgAAAABABEEcAAAAAIAIgjgAAAAAABEEcQAAAAAAIgjiAAAAAABEEMQBAAAAAIggiAMAAAAAEEEQBwAAAAAggiAOAAAAAEAEQRwAAAAAgAiCOAAAAAAAEQRxAAAAAAAiCOIAAAAAAEQQxAEAAAAAiCCIAwAAAAAQQRAHAAAAACCCIA4AAAAAQARBHAAAAACACII4AAAAAAARBHEAAAAAACII4gAAAAAARBDEAQAAAACIIIgDAAAAABBBEAcAAAAAIIIgDgAAAABABEEcAAAAAIAIgjgAAAAAABEEcQAAAAAAIgjiAAAAAABEEMQBAAAAAIggiAMAAAAAEEEQBwAAAAAggiAOAAAAAEAEQRwAAAAAgAiCOAAAAAAAEQRxAAAAAAAiCOIAAAAAAEQQxAEAAAAAiCCIAwAAAAAQQRAHAAAAACCCIA4AAAAAQARBHAAAAACACII4AAAAAAARBHEAAAAAACII4gAAAAAARBDEAQAAAACIIIgDAAAAABBBEAcAAAAAIIIgDgAAAABABEEcAAAAAIAIgjgAAAAAABEEcQAAAAAAIgjiAAAAAABEEMQBAAAAAIggiAMAAAAAEEEQBwAAAAAggiAOAAAAAEAEQRwAAAAAgAiCOAAAAAAAEQRxAAAAAAAiCOIAAAAAAEQQxAEAAAAAiCCIAwAAAAAQQRAHAAAAACCCIA4AAAAAQARBHAAAAACACII4AAAAAAARBHEAAAAAACII4gAAAAAARBDEAQAAAACIIIgDAAAAABBBEAcAAAAAIIIgDgAAAABABEEcAAAAAIAIgjgAAAAAABEEcQAAAAAAIgjiAAAAAABEEMQBAAAAAIggiAMAAAAAEEEQBwAAAAAggiAOAAAAAEAEQRwAAAAAgAiCOAAAAAAAEQRxAAAAAAAiCOIAAAAAAEQQxAEAAAAAiCCIAwAAAAAQQRAHAAAAACCCIA4AAAAAQARBHAAAAACACII4AAAAAAARBHEAAAAAACII4gAAAAAARBDEAQAAAACIIIgDAAAAABBBEAcAAAAAIIIgDgAAAABABEEcAAAAAIAIgjgAAAAAABEEcQAAAAAAIgjiAAAAAABEEMQBAAAAAIggiAMAAAAAEEEQBwAAAAAggiAOAAAAAEAEQRwAAAAAgAiCOAAAAAAAEQRxAAAAAAAiCOIAAAAAAEQQxAEAAAAAiCCIAwAAAAAQQRAHAAAAACCCIA4AAAAAQARBHAAAAACACII4AAAAAAARBHEAAAAAACII4gAAAAAARBDEAQAAAACIIIgDAAAAABBBEAcAAAAAIIIgDgAAAABABEEcAAAAAIAIgjgAAAAAABEEcQAAAAAAIgjiAAAAAABEEMQBAAAAAIggiAMAAAAAEEEQBwAAAAAggiAOAAAAAEAEQRwAAAAAgAiCOAAAAAAAEQRxAAAAAAAiCOIAAAAAAEQQxAEAAAAAiCCIAwAAAAAQQRAHAAAAACCCIA4AAAAAQARBHAAAAACACII4AAAAAAARBHEAAAAAACII4gAAAAAARBDEAQAAAACIIIgDAAAAABBBEAcAAAAAIIIgDgAAAABABEEcAAAAAIAIgjgAAAAAABEEcQAAAAAAIgjiAAAAAABEEMQBAAAAAIggiAMAAAAAEEEQBwAAAAAggiAOAAAAAEAEQRwAAAAAgAiCOAAAAAAAEQRxAAAAAAAiCOIAAAAAAEQQxAEAAAAAiCCIAwAAAAAQQRAHAAAAACCCIA4AAAAAQARBHAAAAACACII4AAAAAAARBHEAAAAAACII4gAAAAAARBDEAQAAAACIIIgDAAAAABBBEAcAAAAAIIIgDgAAAABABEEcAAAAAIAIgjgAAAAAABEEcQAAAAAAIgjiAAAAAABEEMQBAAAAAIggiAMAAAAAEEEQBwAAAAAggiAOAAAAAEAEQRwAAAAAgAiCOAAAAAAAEQRxAAAAAAAiCOIAAAAAAEQQxAEAAAAAiCCIAwAAAAAQQRAHAAAAACCCIA4AAAAAQARBHAAAAACACII4AAAAAAARBHEAAAAAACII4gAAAAAARBDEAQAAAACIIIgDAAAAABBBEAcAAAAAIIIgDgAAAABABEEcAAAAAIAIgjgAAAAAABEEcQAAAAAAIgjiAAAAAABEEMQBAAAAAIggiAMAAAAAEEEQBwAAAAAggiAOAAAAAEAEQRwAAAAAgAiCOAAAAAAAEQRxAAAAAAAiCOIAAAAAAEQQxAEAAAAAiCCIAwAAAAAQQRAHAAAAACCCIA4AAAAAQARBHAAAAACACII4AAAAAAARBHEAAAAAACII4gAAAAAARBDEAQAAAACIIIgDAAAAABBBEAcAAAAAIIIgDgAAAABABEEcAAAAAIAIgjgAAAAAABEEcQAAAAAAIgjiAAAAAABEEMQBAAAAAIggiAMAAAAAEEEQBwAAAAAggiAOAAAAAEAEQRwAAAAAgAiCOAAAAAAAEQRxAAAAAAAiCOIAAAAAAEQQxAEAAAAAiCCIAwAAAAAQQRAHAAAAACCCIA4AAAAAQARBHAAAAACACII4AAAAAAARBHEAAAAAACII4gAAAAAARBDEAQAAAACIIIgDAAAAABBBEAcAAAAAIIIgDgAAAABABEEcAAAAAIAIgjgAAAAAABEEcQAAAAAAIgjiAAAAAABEEMQBAAAAAIggiAMAAAAAEEEQBwAAAAAggiAOAAAAAEAEQRwAAAAAgAiCOAAAAAAAEQRxAAAAAAAiCOIAAAAAAEQQxAEAAAAAiCCIAwAAAAAQQRAHAAAAACCCIA4AAAAAQARBHAAAAACACII4AAAAAAARBHEAAAAAACII4gAAAAAARBDEAQAAAACIIIgDAAAAABBBEAcAAAAAIIIgDgAAAABABEEcAAAAAIAIgjgAAAAAABEEcQAAAAAAIgjiAAAAAABEEMQBAAAAAIggiAMAAAAAEEEQBwAAAAAggiAOAAAAAEAEQRwAAAAAgAiCOAAAAAAAEQRxAAAAAAAiCOIAAAAAAEQQxAEAAAAAiCCIAwAAAAAQQRAHAAAAACCCIA4AAAAAQARBHAAAAACACII4AAAAAAARBHEAAAAAACII4gAAAAAARBDEAQAAAACIIIgDAAAAABBBEAcAAAAAIIIgDgAAAABABEEcAAAAAIAIgjgAAAAAABEEcQAAAAAAIgjiAAAAAABEEMQBAAAAAIggiAMAAAAAEEEQBwAAAAAggiAOAAAAAEAEQRwAAAAAgAiCOECwO+64oy644ILq6OiocePG1VVXXVVbt279uftt37693vOe99TkyZNr2LBhNXHixFq6dGnt3r27NaatrW3Qj4985COtMV/96ldr2bJl1d3dXR0dHTVx4sR6xzveUf/5n/854Pk+/vGPH/d4Bw8ePHEXBAAAADiltZ/sEwDg5Ljtttvqve99b1VVzZgxo/r7+6u3t7cefPDBWr9+fU2aNGnQ/TZt2lSLFi2q/v7+GjlyZM2ZM6f2799fK1eurL1799bYsWMHjJ83b14NHz689flZZ53Vetzb21v33HNPTZ06tWbNmlXf+973auXKlfXAAw/Ugw8+WG95y1sGHKuzs7Nmzpw54GttbW2v6DoAAAAAOQRxgED79++vG2+8saqqrrzyyvrKV75SfX191dPTUzt37qybb765PvOZzwy67/XXX1/9/f118cUX15133llnnHFGVVU9//zzNXTo0GPG33XXXdXd3T3osd761rfWBz7wgXrzm99cVVX33HNPLVu2rA4dOlR33HHHMUF86dKltWLFil/smwYAAADiWTIFINDDDz9cu3btqqojQbyqqqurqxYuXFhVVffdd9+g+z377LN1//33V1XVmWeeWfPnz68xY8bUwoUL69vf/na1tx/7e9b58+fXyJEj6/Wvf33dcssttW/fvta2P/zDP2zF8KojgfwFL76r/AW9vb3V0dFRkydPrl//9V+v7373uy/3WwcAAACCCeIQ5GSvF/3UU0/Vb//2b9eMGTNa23/nd37nhJ4rL82TTz7ZejxhwoTW44kTJ1ZV1RNPPDHofps3b66maaqq6s4776zDhw/XiBEjas2aNXXZZZfVmjVrBow/88wza+rUqTV8+PB67LHH6qabbqrf//3fP+55/f3f/31VHYnhR4877bTTatKkSdXd3V1PP/10fe1rX6u3vOUtojgAAADwkgniEOK2226r3/3d363vfve7NXny5Dp06FD19vbWokWL6umnnz7ufps2baoFCxbUl770pdqzZ0/NmTOnxo0b11ov+mjz5s2rCy+8sPXx4vWif/jDH9aXv/zlamtrqxEjRpzwc+WVeyF2H8+L38DybW97W23durW2bNlS48aNq0OHDtWtt97a2r569erq7++vRx55pHbs2FGXXHJJVVV9+ctfHhDkX/CXf/mX9ed//uc1dOjQ+ud//ud6wxve0Nr27ne/u3bu3FmbN2+uDRs2tO5g37dvX33uc597Rd8zAAAAkEMQhwBHrxe9bdu22rBhQ40ZM6a1XvTxvHi96B07dtT69etrw4YNtXv37kHfdPGuu+6q1atXtz7e9773tbade+65tWvXrtq2bVvrTuQTea68dC/+RcXOnTuPeTxt2rRB95syZUrr8fz586utra3Gjh1bs2fPrqqqxx9/vLX9wgsvbL3h5ciRI+s3fuM3WtteHMQPHDhQ1157bX3sYx+r0aNH1z333FO/9Vu/NeB5Z8+eXePGjWt9/s53vrPGjx9fVce/mx0AAADgaII4BPhVWS+6o6OjFTFP9Lny8ixYsKD1f9Hb21tVVX19fbV69eqqqrr00kurqqqnp6d6enrqs5/9bFVVTZ8+vc4555yqqlq3bl01TVN79uypTZs2VVW1tn3rW9+qr3zlK3Xo0KGqqvrZz35W99xzT+v5p0+fXlVVu3fvrssuu6xWrFhRU6ZMqQcffLAuu+yyY873r//6rweE75UrV1Z/f39V1XHfsBMAAADgaII4BPhVXS/6RJ4rL8+wYcNad9v39vbW2WefXXPmzKm9e/dWZ2dn6y79jRs31saNG1u/pKiquuWWW6qtra1WrlxZs2bNqlmzZtWPfvSjGjVqVH34wx+uqqpt27bVb/7mb9bYsWPr/PPPr66urlq1alVVVV177bWtO81vuOGG+uY3v1lVR9YNf//7318LFy6shQsX1gc+8IHWc956663V3d1d06dPr7lz59Y73/nOqqoaNWpU/fEf//Gre7EAAACAU4YgDsFO5nrRJ/pcefmuu+66uv3222vevHnV19dXbW1ttXz58nrooYeqq6vruPstX7687r777lqwYEH19fXVkCFDatmyZbV27dqaM2dOVVUtXry43v/+99e0adNq+/btdfjw4XrTm95Un//85+sLX/hC61gv/guCbdu21Zo1a1ofjz32WGvbn/3Zn9WSJUvqwIEDtW3btpo+fXpdffXVtW7dupo7d+6rcHUAAACAU9Gx6x0Ap5xXY73o1atXH7Ne9AteWC/6gQceqKojd32/+BxejXPlF3P11VfX1Vdffdztx/tFxBVXXFFXXHHFcfebNWvWgF+YHM+KFStqxYoVP3fcddddV9ddd93PHQcAAADw/3GHOAT4VVkv+kSeKwAAAAC8XG2NdQggwhe+8IV63/veV1VVM2bMqP7+/tqzZ091dnbW+vXrq6urq9ra2qqq6mMf+1h9/OMfr6oja4dfddVV1TRNnX322bV379565plnatSoUfXwww/XnDlzasWKFXXttdfWqFGj6uyzz64f/OAH9eyzz1bVkfWi/+mf/qmqqnbs2FEXXXRRVVX97//+bx08eLBGjx7dWh98y5YtL/lcAQAAAODlcoc4hPhVWC/6wIEDtXXr1tq6dWtrffKf/OQnra+90nMFAAAAgP+PO8QBAAAAAIjgDnEAAAAAACII4gAAAAAARBDEAQAAAACIIIgDAAAAABBBEAcAAAAAIIIgDgAAAABABEEcAAAAAIAIgjgAAAAAABEEcQAAAAAAIgjiAAAAAABEEMQBAAAAAIggiAMAAAAAEEEQBwAAAAAggiAOAAAAAEAEQRwAAAAAgAiCOAAAAAAAEQRxAAAAAAAiCOIAAAAAAEQQxAEAAAAAiCCIAwAAAAAQQRAHAAAAACCCIA4AAAAAQARBHAAAAACACII4AAAAAAARBHEAAAAAACII4gAAAAAARBDEAQAAAACIIIgDAAAAABBBED+F3XHHHXXBBRdUR0dHjRs3rq666qraunXrz91v+/bt9Z73vKcmT55cw4YNq4kTJ9bSpUtr9+7dVVW1Y8eOWrp0aU2dOrWGDx9eZ5xxRr3xjW+sT3ziE3X48OHWcVasWFFtbW2DfmzZsqU17plnnqkPfehDNXPmzBoxYkR1d3fXTTfdVPv27TvxFwUAAAAAiNV+sk+AV8dtt91W733ve6uqasaMGdXf31+9vb314IMP1vr162vSpEmD7rdp06ZatGhR9ff318iRI2vOnDm1f//+WrlyZe3du7fGjh1bzzzzTD3wwAM1ffr0mjRpUj3++OP16KOP1g033FCHDh2qG2+8ccAxx4wZU3Pnzh3wtREjRlRV1b59++qtb31rbdy4sYYPH149PT21cePGuuWWW+r73/9+3XXXXa/C1QEAAAAAErlD/BS0f//+VpS+8sora9u2bbVhw4YaM2ZM7dy5s26++ebj7nv99ddXf39/XXzxxbVjx45av359bdiwoXbv3t2K6G94wxtq79699f3vf7/Wrl1b27dvr5EjR1ZV1X/9138dc8wLLrigVq9ePeBj6tSpVVX1zW9+szZu3FhVVb29vfXII4/UvffeW1VVd999dz300EMn7sIAAAAAANEE8VPQww8/XLt27aqqI0G8qqqrq6sWLlxYVVX33XffoPs9++yzdf/991dV1Zlnnlnz58+vMWPG1MKFC+vb3/52tbcf+YOC9vb2am9vr6VLl9b8+fNrxowZ9dOf/rSqqhYvXnzMcb/zne/U6NGjq7Ozsy6++OL693//99a2Fy+xMmTIkAH/VlWtWrXqF7sIAAAAAABHEcRPQU8++WTr8YQJE1qPJ06cWFVVTzzxxKD7bd68uZqmqaqqO++8sw4fPlwjRoyoNWvW1GWXXVZr1qwZMH7dunW1bt266u/vr6qqG264oW644YYBY9ra2mrixInV3d1dP/7xj+s//uM/asmSJfW1r32tqo4E9MmTJ1dV1fLly+vXfu3X6vLLL2/tv2PHjl/oGgAAAAAAHE0QD/JC7D6egwcPth6/7W1vq61bt9aWLVtq3LhxdejQobr11lsHjH/66afrueeeq3/913+t0aNH1yc/+cm67bbbWtsvueSS+sEPflDbt2+v//mf/6m1a9dWR0dHNU1Tn/rUp6qq6owzzqhVq1bV5ZdfXqNGjarHH3+8li1bVmeccUZVVQ0dOvQEffcAAAAAQDpB/BR01llntR7v3LnzmMfTpk0bdL8pU6a0Hs+fP7/a2tpq7NixNXv27Kqqevzxx4/ZZ+TIkbV06dJ6+9vfXocPH66PfvSjrW3Tpk2rrq6u1ufz5s1rvbnmi+9Snzt3bt177721a9euevbZZ+uTn/xk/fjHP66qqnPPPfelftsAAAAAAP8vQfwUtGDBgho/fnxVHXmjyqqqvr6+Wr16dVVVXXrppVVV1dPTUz09PfXZz362qqqmT59e55xzTlUdWQ6laZras2dPbdq0qaqqte3uu+9ufa3qSGhfu3ZtVVU999xzra9/7nOfq8cee6z1+aOPPtr6vLu7u/X11atX1759+6qq6vnnn68PfvCDVXXk7vDly5e/4usBAAAAAFAliJ+Shg0bVjfffHNVHQniZ599ds2ZM6f27t1bnZ2ddeONN1ZV1caNG2vjxo2tN+Csqrrllluqra2tVq5cWbNmzapZs2bVj370oxo1alR9+MMfrqojQfzcc8+tKVOm1Bvf+MaaPn16a93ya665pnWsf/mXf6nXv/711dXVVeedd1696U1vqueff77a29tb51BV9Vd/9VfV2dlZ559/fk2ePLnuvPPOqqr6xCc+MeCudQAAAACAV0IQP0Vdd911dfvtt9e8efOqr6+v2traavny5fXQQw8NWMbkaMuXL6+77767FixYUH19fTVkyJBatmxZrV27tubMmVNVR9YXX7RoUe3bt6++973v1dChQ+vNb35z/e3f/m19+tOfbh3rj/7oj+ryyy+v0047rTZv3lwTJ06sK664oh566KG65JJLWuMuuuiimjRpUm3evLkOHjxYixcvrrvuuqs+9KEPvWrXBwAAAADI09b8vHdaBAAAAACAU4A7xAEAAAAAiCCIAwAAAAAQQRAHAAAAACCCIA4AAAAAQARBHAAAAACACII4AAAAAAARBHEAAAAAACII4gAAAAAARBDEAQAAAACIIIgDAAAAABBBEAcAAAAAIIIgDgAAAABABEEcAAAAAIAIgjgAAAAAABEEcQAAAAAAIgjiAAAAAABEEMQBAAAAAIggiAMAAAAAEEEQBwAAAAAggiAOAAAAAEAEQRwAAAAAgAiCOAAAAAAAEQRxAAAAAAAiCOIAAAAAAEQQxAEAAAAAiCCIAwAAAAAQQRAHAAAAACCCIA4AAAAAQARBHAAAAACACII4AAAAAAARBHEAAAAAACII4gAAAAAARBDEAQAAAACIIIgDAAAAABBBEAcAAAAAIIIgDgAAAABABEEcAAAAAIAIgjgAAAAAABEEcQAAAAAAIgjiAAAAAABEEMQBAAAAAIggiAMAAAAAEEEQBwAAAAAggiAOAAAAAEAEQRwAAAAAgAiCOAAAAAAAEQRxAAAAAAAiCOIAAAAAAEQQxAEAAAAAiCCIAwAAAAAQQRAHAAAAACCCIA4AAAAAQARBHAAAAACACII4AAAAAAARBHEAAAAAACII4gAAAAAARBDEAQAAAACIIIgDAAAAABBBEAcAAAAAIIIgDgAAAABABEEcAAAAAIAIgjgAAAAAABEEcQAAAAAAIgjiAAAAAABEEMQBAAAAAIggiAMAAAAAEEEQBwAAAAAggiAOAAAAAEAEQRwAAAAAgAiCOAAAAAAAEQRxAAAAAAAiCOIAAAAAAEQQxAEAAAAAiCCIAwAAAAAQQRAHAAAAACCCIA4AAAAAQARBHAAAAACACII4AAAAAAARBHEAAAAAACII4gAAAAAARBDEAQAAAACIIIgDAAAAABBBEAcAAAAAIIIgDgAAAABABEEcAAAAAIAIgjgAAAAAABEEcQAAAAAAIgjiAAAAAABEEMQBAAAAAIggiAMAAAAAEEEQBwAAAAAggiAOAAAAAEAEQRwAAAAAgAiCOAAAAAAAEQRxAAAAAAAiCOIAAAAAAEQQxAEAAAAAiCCIAwAAAAAQQRAHAAAAACCCIA4AAAAAQARBHAAAAACACII4AAAAAAARBHEAAAAAACII4gAAAAAARBDEAQAAAACIIIgDAAAAABBBEAcAAAAAIIIgDgAAAABABEEcAAAAAIAIgjgAAAAAABEEcQAAAAAAIgjiAAAAAABEEMQBAAAAAIggiAMAAAAAEEEQBwAAAAAggiAOAAAAAEAEQRwAAAAAgAiCOAAAAAAAEQRxAAAAAAAiCOIAAAAAAEQQxAEAAAAAiCCIAwAAAAAQQRAHAAAAACCCIA4AAAAAQARBHAAAAACACII4AAAAAAARBHEAAAAAACII4gAAAAAARBDEAQAAAACIIIgDAAAAABBBEAcAAAAAIIIgDgAAAABABEEcAAAAAIAIgjgAAAAAABEEcQAAAAAAIgjiAAAAAABEEMQBAAAAAIggiAMAAAAAEEEQBwAAAAAggiAOAAAAAEAEQRwAAAAAgAiCOAAAAAAAEQRxAAAAAAAiCOIAAAAAAEQQxAEAAAAAiCCIAwAAAAAQQRAHAAAAACCCIA4AAAAAQARBHAAAAACACII4AAAAAAARBHEAAAAAACII4gAAAAAARBDEAQAAAACIIIgDAAAAABBBEAcAAAAAIIIgDgAAAABABEEcAAAAAIAIgjgAAAAAABEEcQAAAAAAIgjiAAAAAABEEMQBAAAAAIggiAMAAAAAEEEQBwAAAAAggiAOAAAAAEAEQRwAAAAAgAiCOAAAAAAAEQRxAAAAAAAiCOIAAAAAAEQQxAEAAAAAiCCIAwAAAAAQQRAHAAAAACCCIA4AAAAAQARBHAAAAACACII4AAAAAAARBHEAAAAAACII4gAAAAAARBDEAQAAAACIIIgDAAAAABBBEAcAAAAAIIIgDgAAAABABEEcAAAAAIAIgjgAAAAAABEEcQAAAAAAIgjiAAAAAABEEMQBAAAAAIggiAMAAAAAEEEQBwAAAAAggiAOAAAAAEAEQRwAAAAAgAiCOAAAAAAAEQRxAAAAAAAiCOIAAAAAAEQQxAEAAAAAiCCIAwAAAAAQQRAHAAAAACCCIA4AAAAAQARBHAAAAACACII4AAAAAAARBHEAAAAAACII4gAAAAAARBDEAQAAAACIIIgDAAAAABBBEAcAAAAAIIIgDgAAAABABEEcAAAAAIAIgjgAAAAAABEEcQAAAAAAIgjiAAAAAABEEMQBAAAAAIggiAMAAAAAEEEQBwAAAAAggiAOAAAAAEAEQRwAAAAAgAiCOAAAAAAAEQRxAAAAAAAiCOIAAAAAAEQQxAEAAAAAiCCIAwAAAAAQQRAHAAAAACCCIA4AAAAAQARBHAAAAACACII4AAAAAAARBHEAAAAAACII4gAAAAAARBDEAQAAAACIIIgDAAAAABBBEAcAAAAAIIIgDgAAAABABEEcAAAAAIAIgjgAAAAAABEEcQAAAAAAIgjiAAAAAABEEMQBAAAAAIggiAMAAAAAEEEQBwAAAAAggiAOAAAAAEAEQRwAAAAAgAiCOAAAAAAAEQRxAAAAAAAiCOIAAAAAAEQQxAEAAAAAiCCIAwAAAAAQQRAHAAAAACCCIA4AAAAAQARBHAAAAACACII4AAAAAAARBHEAAAAAACII4gAAAAAARBDEAQAAAACIIIgDAAAAABBBEAcAAAAAIIIgDgAAAABABEEcAAAAAIAIgjgAAAAAABEEcQAAAAAAIgjiAAAAAABEEMQBAAAAAIggiAMAAAAAEEEQBwAAAAAggiAOAAAAAEAEQRwAAAAAgAiCOAAAAAAAEQRxAAAAAAAiCOIAAAAAAEQQxAEAAAAAiCCIAwAAAAAQQRAHAAAAACCCIA4AAAAAQARBHAAAAACACII4AAAAAAARBHEAAAAAACII4gAAAAAARBDEAQAAAACIIIgDAAAAABBBEAcAAAAAIIIgDgAAAABABEEcAAAAAIAIgjgAAAAAABEEcQAAAAAAIgjiAAAAAABEEMQBAAAAAIggiAMAAAAAEEEQBwAAAAAggiAOAAAAAEAEQRwAAAAAgAiCOAAAAAAAEQRxAAAAAAAiCOIAAAAAAEQQxAEAAAAAiCCIAwAAAAAQQRAHAAAAACCCIA4AAAAAQARBHAAAAACACII4AMD/sXffYVLVd8OHv7uwdJBebKCIAkrsLRasKKiPYkRJLIBKHnslMWoUEmN5LbGbGIkYEzUKJKICdjBEYyTEggIaFbD3RgCp5/2Da88zsx1EUH/3fV17sTNz2pw5zJn57JkzAAAAJEEQBwAAAAAgCYI4AAAAAABJEMQBAAAAAEiCIA4AAAAAQBIEcQAAAAAAkiCIAwAAAACQBEEcAAAAAIAkCOIAAAAAACRBEAcAAAAAIAmCOAAAAAAASRDEAQAAAABIgiAOAAAAAEASBHEAAAAAAJIgiAMAAAAAkARBHAAAAACAJAjiAAAAAAAkQRAHAAAAACAJgjgAAAAAAEkQxAEAAAAASIIgDgAAAABAEgRxAAAAAACSIIgDAAAAAJAEQRwAAAAAgCQI4gAAAAAAJEEQBwAAAAAgCYI4AAAAAABJEMQBAAAAAEiCIA4AAAAAQBIEcQAAAAAAkiCIAwAAAACQBEEcAAAAAIAkCOIAAAAAACRBEAcAAAAAIAmCOAAAAAAASRDEAQAAAABIgiAOAAAAAEASBHEAAAAAAJIgiAMAAAAAkARBHAAAAACAJAjiAAAAAAAkQRAHAAAAACAJgjgAAAAAAEkQxAEAAAAASIIgDgAAAABAEgRxAAAAAACSIIgDAAAAAJAEQRwAAAAAgCQI4gAAAAAAJEEQBwAAAAAgCYI4AAAAAABJEMQBAAAAAEiCIA4AAAAAQBIEcQAAAAAAkiCIAwAAAACQBEEcAAAAAIAkCOIAAAAAACRBEAcAAAAAIAmCOAAAAAAASRDEAQAAAABIgiAOAAAAAEASBHEAAAAAAJIgiAMAAAAAkARBHAAAAACAJAjiAAAAAAAkQRAHAAAAACAJgjgAAAAAAEkQxAEAAAAASIIgDgAAAABAEgRxAAAAAACSIIgDAAAAAJAEQRwAAAAAgCQI4gAAAAAAJEEQBwAAAAAgCYI4AAAAAABJEMQBAAAAAEiCIA4AAAAAQBIEcQAAAAAAkiCIAwAAAACQBEEcAAAAAIAkCOIAAAAAACRBEAcAAAAAIAmCOAAAAAAASRDEAQAAAABIgiAOAAAAAEASBHEAAAAAAJIgiAMAAAAAkARBHAAAAACAJAjiAAAAAAAkQRAHAAAAACAJgjgAAAAAAEkQxAEAAAAASIIgDgAAAABAEgRxAAAAAACSIIgDAAAAAJAEQRwAAAAAgCQI4gAAAAAAJEEQBwAAAAAgCYI4AAAAAABJEMQBAAAAAEiCIA4AAAAAQBIEcQAAAAAAkiCIAwAAAACQBEEcAAAAAIAkCOIAAAAAACRBEAcAAAAAIAmCOAAAAAAASRDEAQAAAABIgiAOAAAAAEASBHEAAAAAAJIgiAMAAAAAkARBHAAAAACAJAjiAAAAAAAkQRAHAAAAACAJgjgAAAAAAEkQxAEAAAAASIIgDgAAAABAEgRxAAAAAACSIIgDAAAAAJAEQRwAAAAAgCQI4gAAAAAAJEEQBwAAAAAgCYI4AAAAAABJEMQBAAAAAEiCIA4AAAAAQBIEcQAAAAAAkiCIAwAAAACQBEEcAAAAAIAkCOIAAAAAACRBEAcAAAAAIAmCOAAAAAAASRDEAQAAAABIgiAOAAAAAEASBHEAAAAAAJIgiAMAAAAAkARBHAAAAACAJAjiAAAAAAAkQRAHAAAAACAJgjgAAAAAAEkQxAEAAAAASIIgDgAAAABAEgRxAAAAAACSIIgDAAAAAJAEQRwAAAAAgCQI4gAAAAAAJEEQBwAAAAAgCYI4AAAAAABJEMQBAAAAAEiCIA4AAAAAQBIEcQAAAAAAkiCIAwAAAACQBEEcAAAAAIAkCOIAAAAAACRBEAcAAAAAIAmCOAAAAAAASRDEAQAAAABIgiAOAAAAAEASBHEAAAAAAJIgiAMAAAAAkARBHAAAAACAJAjiAAAAAAAkQRAHAAAAACAJgjgAAAAAAEkQxAEAAAAASIIgDgAAAABAEgRxAAAAAACSIIgDAAAAAJAEQRwAAAAAgCQI4gAAAAAAJEEQBwAAAAAgCYI4AAAAAABJEMQBAAAAAEiCIA4AAAAAQBIEcQAAAAAAkiCIAwAAAACQBEEcAAAAAIAkCOIAAAAAACRBEAcAAAAAIAmCOAAAAAAASRDEAQAAAABIgiAOAAAAAEASBHEAAAAAAJIgiAMAAAAAkARBHAAAAACAJAjiAAAAAAAkQRAHAAAAACAJgjgAAAAAAEkQxAEAAAAASIIgDgAAAABAEgRxAAAAAACSIIgDAAAAAJAEQRwAAAAAgCQI4gAAAAAAJEEQBwAAAAAgCYI4AAAAAABJEMQBAAAAAEiCIA4AAAAAQBIEcQAAAAAAkiCIAwAAAACQBEEcAAAAAIAkCOIAAAAAACRBEAcAAAAAIAmCOAAAAAAASRDEAQAAAABIgiAOAAAAAEASBHEAAAAAAJIgiAMAAAAAkARBHAAAAACAJAjiAAAAAAAkQRAHAAAAACAJgjgAAAAAAEkQxAEAAAAASIIgDgAAAABAEgRxAAAAAACSIIgDAAAAAJAEQRwAAAAAgCQI4gAAAAAAJEEQBwAAAAAgCYI4AAAAAABJEMQBAAAAAEiCIA4AAAAAQBIEcQAAAAAAkiCIAwAAAACQBEEcAAAAAIAkCOIAAAAAACRBEAcAAAAAIAmCOAAAAAAASRDEAQAAAABIgiAOAAAAAEASBHEAAAAAAJIgiAMAAAAAkARBHAAAAACAJAjiAAAAAAAkQRAHAAAAACAJgjgAAAAAAEkQxAEAAAAASIIgDgAAAABAEgRxAAAAAACSIIgDAAAAAJAEQRwAAAAAgCQI4gAAAAAAJEEQBwAAAAAgCYI4AAAAAABJEMQBAAAAAEiCIA4AAAAAQBIEcQAAAAAAkiCIAwAAAACQBEEcAAAAAIAkCOIAAAAAACRBEAcAAAAAIAmCOAAAAAAASRDEAQAAAABIgiAOAAAAAEASBHEAAAAAAJIgiAMAAAAAkARBHAAAAACAJAjiAAAAAAAkQRAHAAAAACAJgjgAAAAAAEkQxAEAAAAASIIgDgAAAABAEgRxAAAAAACSIIgDAAAAAJAEQRwAAAAAgCQI4gAAAAAAJEEQBwAAAAAgCYI4AAAAAABJEMQBAAAAAEiCIA4AAAAAQBIEcQAAAAAAkiCIAwAAAACQBEEcAAAAAIAkCOIAAAAAACRBEAcAAAAAIAmCOAAAAAAASRDEAQAAAABIgiAOAAAAAEASBHEAAAAAAJIgiAMAAAAAkARBHAAAAACAJAjiAAAAAAAkQRAHAAAAACAJgjgAAAAAAEkQxAEAAAAASIIgDgAAAABAEgRxAAAAAACSIIgDAAAAAJAEQRwAAAAAgCQI4gAAAAAAJEEQBwAAAAAgCYI4AAAAAABJEMQBAAAAAEiCIA4AAAAAQBIEcQAAAAAAkiCIAwAAAACQBEEcAAAAAIAkCOIAAAAAACRBEAcAAAAAIAmCOAAAAAAASRDEAQAAAABIgiAOAAAAAEASBHEAAAAAAJIgiAMAAAAAkARBHAAAAACAJAjiAAAAAAAkQRAHAAAAACAJgjgAAAAAAEkQxAEAAAAASIIgDgAAAABAEgRxAAAAAACSIIgDAAAAAJAEQRwAAAAAgCQI4gAAAAAAJEEQBwAAAAAgCYI4AAAAAABJEMQBAAAAAEiCIA4AAAAAQBIEcQAAAAAAkiCIAwAAAACQBEEcAAAAAIAkCOIAAAAAACRBEAcAAAAAIAmCOAAAAAAASRDEAQAAAABIgiAOAAAAAEASBHEAAAAAAJIgiAMAAAAAkARBHAAAAACAJAjiAAAAAAAkQRAHAAAAACAJgjgAAAAAAEkQxAEAAAAASIIgDgAAAABAEgRxAAAAAACSIIgDAAAAAJAEQRwAAAAAgCQI4gAAAAAAJEEQBwAAAAAgCYI4AAAAAABJEMQBAAAAAEiCIA4AAAAAQBIEcQAAAAAAkiCIAwAAAACQBEEcAAAAAIAkCOIAAAAAACRBEAcAAAAAIAmCOAAAAAAASRDEAQAAAABIgiAOAAAAAEASBHEAAAAAAJIgiAMAAAAAkARBHAAAAACAJAjiAAAAAAAkQRAHAAAAACAJgjgAAAAAAEkQxAEAAAAASIIgDgAAAABAEgRxAAAAAACSIIgDAAAAAJAEQRwAAAAAgCQI4gAAAAAAJEEQBwAAAAAgCYI4AAAAAABJEMQBAAAAAEiCIA4AAAAAQBIEcQAAAAAAkiCIAwAAAACQBEEcAAAAAIAkCOIAAAAAACRBEAcAAAAAIAmCOAAAAAAASRDEAQAAAABIgiAOAAAAAEASBHEAAAAAAJIgiAMAAAAAkARBHAAAAACAJAjiAAAAAAAkQRAHAAAAACAJgjgAAAAAAEkQxAEAAAAASIIgDgAAAABAEgRxAAAAAACSIIgDAAAAAJAEQRwAAAAAgCQI4gAAAAAAJEEQBwAAAAAgCYI4AAAAAABJEMQBAAAAAEiCIA4AAAAAQBIEcQAAAAAAkiCIAwAAAACQBEEcAAAAAIAkCOIAAAAAACRBEAcAAAAAIAmCOAAAAAAASRDEAQAAAABIgiAOAAAAAEASBHEAAAAAAJIgiAMAAAAAkARBHAAAAACAJAjiAAAAAAAkQRAHAAAAACAJgjgAAAAAAEkQxAEAAAAASIIgDgAAAABAEgRxAAAAAACSIIgDAAAAAJAEQRwAAAAAgCQI4gAAAAAAJEEQBwAAAAAgCYI4AAAAAABJEMQBAAAAAEiCIA4AAAAAQBIEcQAAAAAAkiCIAwAAAACQBEEcAAAAAIAkCOIAAAAAACRBEAcAAAAAIAmCOAAAAAAASRDEAQAAAABIgiAOAAAAAEASBHEAAAAAAJIgiAMAAAAAkARBHAAAAACAJAjiAAAAAAAkQRAHAAAAACAJgjgAAAAAAEkQxAEAAAAASIIgDgAAAABAEgRxAAAAAACSIIgDAAAAAJAEQRwAAAAAgCQI4gAAAAAAJEEQBwAAAAAgCYI4AAAAAABJEMQBAAAAAEiCIA4AAAAAQBIEcQAAAAAAkiCIAwAAAACQBEEcAAAAAIAkCOIAAAAAACRBEAcAAAAAIAmCOAAAAAAASRDEAQAAAABIgiAOAAAAAEASBHEAAAAAAJIgiAMAAAAAkARBHAAAAACAJAjiAAAAAAAkQRAHAAAAACAJgjgAAAAAAEkQxAEAAAAASIIgDgAAAABAEgRxAAAAAACSIIgDAAAAAJAEQRwAAAAAgCQI4gAAAAAAJEEQBwAAAAAgCYI4AAAAAABJEMQBAAAAAEiCIA4AAAAAQBIEcQAAAAAAkiCIAwAAAACQBEEcAAAAAIAkCOIAAAAAACRBEAcAAAAAIAmCOAAAAAAASRDEAQAAAABIgiAOAAAAAEASBHEAAAAAAJIgiAMAAAAAkARBHAAAAACAJAjiAAAAAAAkQRAHAAAAACAJgjgAAAAAAEkQxAEAAAAASIIgDgAAAABAEgRxAAAAAACSIIgDAAAAAJAEQRwAAAAAgCQI4gAAAAAAJEEQBwAAAAAgCYI4AAAAAABJEMQBAAAAAEiCIA4AAAAAQBIEcQAAAAAAkiCIAwAAAACQBEEcAAAAAIAkCOIAAAAAACRBEAcAAAAAIAmCOAAAAAAASRDEAQAAAABIgiAOAAAAAEASBHEAAAAAAJIgiAMAAAAAkARBHAAAAACAJAjiAAAAAAAkQRAHAAAAACAJgjgAAAAAAEkQxAEAAAAASIIgDgAAAABAEgRxAAAAAACSIIgDAAAAAJAEQRwAAAAAgCQI4gAAAAAAJEEQBwAAAAAgCYI4AAAAAABJEMQBAAAAAEiCIA4AAAAAQBIEcQAAAAAAkiCIAwAAAACQBEEcAAAAAIAkCOIAAAAAACRBEAcAAAAAIAmCOAAAAAAASRDEAQAAAABIgiAOAAAAAEASBHEAAAAAAJIgiAMAAAAAkARBHAAAAACAJAjiAAAAAAAkQRAHAAAAACAJgjgAAAAAAEkQxAEAAAAASIIgDgAAAABAEgRxAAAAAACSIIgDAAAAAJAEQRwAAAAAgCQI4gAAAAAAJEEQBwAAAAAgCYI4AAAAAABJEMQBAAAAAEiCIA4AAAAAQBIEcQAAAAAAkiCIAwAAAACQBEEcAAAAAIAkCOIAAAAAACRBEAcAAAAAIAmCOAAAAAAASRDEAQAAAABIgiAOAAAAAEASBHEAAAAAAJIgiAMAAAAAkARBHAAAAACAJAjiAAAAAAAkQRAHAAAAACAJgjgAAAAAAEkQxAEAAAAASIIgDgAAAABAEgRxAAAAAACSIIgDAAAAAJAEQRwAAAAAgCQI4gAAAAAAJEEQBwAAAAAgCYI4AAAAAABJEMQBAAAAAEiCIA4AAAAAQBIEcQAAAAAAkiCIAwAAAACQBEEcAAAAAIAkCOIAAAAAACRBEAcAAAAAIAmCOAAAAAAASRDEAQAAAABIgiAOAAAAAEASBHEAAAAAAJIgiAMAAAAAkARBHAAAAACAJAjiAAAAAAAkQRAHAAAAACAJgjgAAAAAAEkQxAEAAAAASIIgDgAAAABAEgRxAAAAAACSIIgDAAAAAJAEQRwAAAAAgCQI4gAAAAAAJEEQBwAAAAAgCYI4AAAAAABJEMQBAAAAAEiCIA4AAAAAQBIEcQAAAAAAkiCIAwAAAACQBEEcAAAAAIAkCOIAAAAAACRBEAcAAAAAIAmCOAAAAAAASRDEAQAAAABIgiAOAAAAAEASBHEAAAAAAJIgiAMAAAAAkARBHAAAAACAJAjiAAAAAAAkQRAHAAAAACAJgjgAAAAAAEkQxAEAAAAASIIgDgAAAABAEgRxAAAAAACSIIgDAAAAAJAEQRwAAAAAgCQI4gAAAAAAJEEQBwAAAAAgCYI4AAAAAABJEMQBAAAAAEiCIA4AAAAAQBIEcQAAAAAAkiCIAwAAAACQBEEcAAAAAIAkCOIAAAAAACRBEAcAAAAAIAmCOAAAAAAASRDEAQAAAABIgiAOAAAAAEASBHEAAAAAAJIgiAMAAAAAkARBHAAAAACAJAjiAAAAAAAkQRAHAAAAACAJgjgAAAAAAEkQxAEAAAAASIIgDgAAAABAEgRxAAAAAACSIIgDAAAAAJAEQRwAAAAAgCQI4gAAAAAAJEEQBwAAAAAgCYI4AAAAAABJEMQBAAAAAEiCIA4AAAAAQBIEcQAAAAAAkiCIAwAAAACQBEEcAAAAAIAkCOIAAAAAACRBEAcAAAAAIAmCOAAAAAAASRDEAQAAAABIgiAOAAAAAEASBHEAAAAAAJIgiAMAAAAAkARBHAAAAACAJAjiAAAAAAAkQRAHAAAAACAJgjgAAAAAAEkQxAEAAAAASIIgDgAAAABAEgRxAAAAAACSIIgDAAAAAJAEQRwAAAAAgCQI4gAAAAAAJEEQBwAAAAAgCYI4AAAAAABJEMQBAAAAAEiCIA4AAAAAQBIEcQAAAAAAkiCIAwAAAACQBEEcAAAAAIAkCOIAAAAAACRBEAcAAAAAIAmCOAAAAAAASRDEAQAAAABIgiAOAAAAAEASBHEAAAAAAJIgiAMAAAAAkARBHAAAAACAJAjiAAAAAAAkQRAHAAAAACAJgjgAAAAAAEkQxAEAAAAASIIgDgAAAABAEgRxAAAAAACSIIgDAAAAAJAEQRwAAAAAgCQI4gAAAAAAJEEQBwAAAAAgCYI4AAAAAABJEMQBAAAAAEiCIA4AAAAAQBIEcQAAAAAAkiCIAwAAAACQBEEcAAAAAIAkCOIAAAAAACRBEAcAAAAAIAmCOAAAAAAASRDEAQAAAABIgiAOAAAAAEASBHEAAAAAAJIgiAMAAAAAkARBHAAAAACAJAjiAAAAAAAkQRAHAAAAACAJgjgAAAAAAEkQxAEAAAAASIIgDgAAAABAEgRxAAAAAACSIIgDAAAAAJAEQRwAAAAAgCQI4gAAAAAAJEEQBwAAAAAgCYI4AAAAAABJEMQBAAAAAEiCIA4AAAAAQBIEcQAAAAAAkiCIAwAAAACQBEEcAAAAAIAkCOIAAAAAACRBEAcAAAAAIAmCOAAAAAAASRDEAQAAAABIgiAOAAAAAEASBHEAAAAAAJIgiAMAAAAAkARBHAAAAACAJAjiAAAAAAAkQRAHAAAAACAJgjgAAAAAAEkQxAEAAAAASIIgDgAAAABAEgRxAAAAAACSIIgDAAAAAJAEQRwAAAAAgCQI4gAAAAAAJEEQBwAAAAAgCYI4AAAAAABJEMQBAAAAAEiCIA4AAAAAQBIEcQAAAAAAkiCIAwAAAACQBEEcAAAAAIAkCOIAAAAAACRBEAcAAAAAIAmCOAAAAAAASRDEAQAAAABIgiAOAAAAAEASBHEAAAAAAJIgiAMAAAAAkARBHAAAAACAJAjiAAAAAAAkQRAHAAAAACAJgjgAAAAAAEkQxAEAAAAASIIgDgAAAABAEgRxAAAAAACSIIgDAAAAAJAEQRwAAAAAgCQI4gAAAAAAJEEQBwAAAAAgCYI4AAAAAABJEMQBAAAAAEiCIA4AAAAAQBIEcQAAAAAAkiCIAwAAAACQBEEcAAAAAIAkCOIAAAAAACRBEAcAAAAAIAmCOAAAAAAASRDEAQAAAABIgiAOAAAAAEASBHEAAAAAAJIgiAMAAAAAkARBHAAAAACAJAjiAAAAAAAkQRAHAAAAACAJgjgAAAAAAEkQxAEAAAAASIIgDgAAAABAEgRxAAAAAACSIIgDAAAAAJAEQRwAAAAAgCQI4gAAAAAAJEEQBwAAAAAgCYI4AAAAAABJEMQBAAAAAEiCIA4AAAAAQBIEcQAAAAAAkiCIAwAAAACQBEEcAAAAAIAkCOIAAAAAACRBEAcAAAAAIAmCOAAAAAAASRDEAQAAAABIgiAOAAAAAEASBHEAAAAAAJIgiAMAAAAAkARBHAAAAACAJAjiAAAAAAAkQRAHAAAAACAJgjgAAAAAAEkQxAEAAAAASIIgDgAAAABAEgRxAAAAAACSIIgDAAAAAJAEQRwAAAAAgCQI4gAAAAAAJEEQBwAAAAAgCYI4AAAAAABJEMQBAAAAAEiCIA4AAAAAQBIEcQAAAAAAkiCIAwAAAACQBEEcAAAAAIAkCOIAAAAAACRBEAcAAAAAIAmCOAAAAAAASRDEAQAAAABIgiAOAAAAAEASBHEAAAAAAJIgiAMAAAAAkARBHAAAAACAJAjiAAAAAAAkQRAHAAAAACAJgjgAAAAAAEkQxAEAAAAASIIgDgAAAABAEgRxAAAAAACSIIgDAAAAAJAEQRwAAAAAgCQI4gAAAAAAJEEQBwAAAAAgCYI4AAAAAABJEMQBAAAAAEiCIA4AAAAAQBIEcQAAAAAAkiCIAwAAAACQBEEcAAAAAIAkCOIAAAAAACRBEAcAAAAAIAmCOAAAAAAASRDEAQAAAABIgiAOAAAAAEASBHEAAAAAAJIgiAMAAAAAkARBHAAAAACAJAjiAAAAAAAkQRAHAAAAACAJgjgAAAAAAEkQxAEAAAAASIIgDgAAAABAEgRxAAAAAACSIIgDAAAAAJAEQRwAAAAAgCQI4gAAAAAAJEEQBwAAAAAgCYI4AAAAAABJEMQBAAAAAEiCIA4AAAAAQBIEcQAAAAAAkiCIAwAAAACQBEEcAAAAAIAkCOIAAAAAACRBEAcAAAAAIAmCOAAAAAAASRDEAQAAAABIgiAOAAAAAEASBHEAAAAAAJIgiAMAAAAAkARBHAAAAACAJAjiAAAAAAAkQRAHAAAAACAJgjgAAAAAAEkQxAEAAAAASIIgDgAAAABAEgRxAAAAAACSIIgDAAAAAJAEQRwAAAAAgCQI4gAAAAAAJEEQBwAAAAAgCYI4AAAAAABJEMQBAAAAAEiCIA4AAAAAQBIEcQAAAAAAkiCIAwAAAACQBEEcAAAAAIAkCOIAAAAAACRBEAcAAAAAIAmCOAAAAAAASRDEAQAAAABIgiAOAAAAAEASBHEAAAAAAJIgiAMAAAAAkARBHAAAAACAJAjiAAAAAAAkQRAHAAAAACAJgjgAAAAAAEkQxAEAAAAASIIgDgAAAABAEgRxAAAAAACSIIgDAAAAAJAEQRwAAAAAgCQI4gAAAAAAJEEQBwAAAAAgCYI4AAAAAABJEMQBAAAAAEiCIA4AAAAAQBIEcQAAAAAAkiCIAwAAAACQBEEcAAAAAIAkCOIAAAAAACRBEAcAAAAAIAmCOAAAAAAASRDEAQAAAABIgiAOAAAAAEASBHEAAAAAAJIgiAMAAAAAkARBHAAAAACAJAjiAAAAAAAkQRAHAAAAACAJgjgAAAAAAEkQxAEAAAAASIIgDgAAAABAEgRxAAAAAACSIIgDAAAAAJAEQRwAAAAAgCQI4gAAAAAAJEEQBwAAAAAgCYI4AAAAAABJEMQBIHGTJ0+OkpKS/GfOnDlre5FYjb7q41vT+IMHD86v32OPPYrGKxzntttu+8r349ugpvXxbTRnzpyix3Hy5Mlre5Gq9W1aVlaf79r/OQBgzRDEAeA7omK4LPxp1qxZ9OzZM0499dR4/fXX1/airjUVo1lVP/Xr119t87vtttsqTf+0006rctibb7650rAjRoxYbctSFX8MWfvqsk2mHvu+i7H7/fffj4suuih69+4dHTp0iAYNGkTTpk1j8803j+OOOy4mTpwYWZat7cUEAPhOWn3v+ACAb6z58+fHzJkzY+bMmXHrrbfGuHHjYp999lnbi5Wk2267LS6++OJo3rx50fXXXXfdWlqimnXt2jWuuOKK/HLr1q3rNF7hONtvv/1qXy4o1Lp166JtrmvXrmtxaWp20003xdlnnx1ffvll0fVLliyJGTNmxIwZM+LWW2+N2bNnR5cuXdbOQn5LDBw4MLbYYouIiNhggw3W8tIAAN8WgjgAfEcdccQRsd1228XixYvjH//4RzzwwAMREbFgwYI4+uijY86cOdGwYcO1vJRrz8YbbxwnnnhipetLS7/eD9DNmzcvRo0aVXSk+KOPPhozZsz4Wue7qjbYYIMYNmzYSo+3KuMQse+++0afPn0qXS/21axFixbfim3u8ssvj3POOSe/XK9evTjggANi2223jZKSknj11VfjoYceivfff38tLuU33xdffBEtWrSI/fffP/bff/+1vTgAwLeMU6YAwHfU/vvvH8OGDYvzzjsv7r///jjyyCPz295777148sknqxwvy7IYOXJkbLXVVtGoUaNo3759HH/88fHpp58WDffJJ5/ET3/609h7772jS5cu0bx582jQoEF06NAh9t133/jjH/9Y5Uf+77vvvth///2jQ4cOUVZWFi1atIiuXbvGIYccEpdeemksX768aPhFixbFDTfcELvvvnu0bt06GjRoEJ06dYoBAwbEP/7xj1VeP+Wht+LPWWedVWnYESNGFJ2yYVWVx/YbbrihaN1ce+21EbEijlWnttObdOnSZaVOtVJSUhJ77rln0XUbbbRRPo3BgwfXab41Tb+qc4hXPI3MokWL4uKLL45NN900GjZsGOuvv34MGzYsFi1aVGmaH3/8cZx44onRsWPHaNy4cWy33XYxevToGpdxjz32qHSfqluWQpMnT47jjjsuttlmm+jUqVM0bNgwmjRpEptsskkMGTIkpk+fXqf1sLK+//3vV7ldHnHEERER8eqrr9Z6+pAdd9wxv33o0KEREbF06dK44IILol+/ftG1a9do2bJllJWVRZs2bWK33XaL66+/PpYsWVLn5azp3M01PR7PPfdcnHTSSbHjjjvGeuutF40bN45GjRpF586d44gjjoi///3vRdPq0qVLbLTRRkXX7bnnnpXmXZfTqowdOzYOOOCA6NixYzRo0CBatWoV3//+9+Oqq66KBQsWVBq+4jb8yCOPxJ577hnNmjWL5s2bR9++feOll16q8zqbMWNGnHfeefnl9u3bx9SpU2PcuHFx4YUXxgUXXBB/+MMf4s0334zf/e530aRJk6Lx33777fjJT34SvXr1imbNmkWjRo2iS5cucdRRR8UzzzxTaX6Fz1tdunSJd999NwYNGhRt27aNFi1axEEHHRSvvPJKRET8+9//jv333z+aN28erVq1igEDBsSbb75ZNL2Kj+vrr78e11xzTfTs2TMaNWoU6623Xpx11lkxb968ovFWZV9RcV6vvvpqXHnlldGjR49o2LBhHHPMMRFR83Y4ffr0OOqoo6JLly7RsGHDaNy4cWy44Yax1157xbnnnhtvv/12pXW2trcRAGANyQCA74RJkyZlEZH/jBo1quj2G264oej2O+64o8rx9ttvv6LL5T+777570fSmT59e5XCFP0OGDCkaZ9SoUbWOs3Dhwnz4Dz74INtqq62qHba0tDS75ppr6ryOZs+enY/bvHnzrEOHDln9+vWztm3bZvvss0925513Vjne8OHDi+ZbVxXv7yGHHJL/Pn78+CzLsuzVV1/NSktLs4jI+vfvXzT88OHD82lVfJxmz55dNK/OnTuv1Hi1PQ6DBg2qdb6DBg3Kr+/du3fR8lS3LVZcJ7vuumuV8z/66KOLpvfpp59m3bt3r3LYgw46qNpl7N27d6X7VN2yFDr77LNrXD8NGjTIHnnkkaJxalof1SncJis+dtXZbbfd8uF//OMfF9326quvFk3vqaeeyrIsy+bNm1frY77PPvtkS5curXbZJk2aVKf7WtM2c/3119e4DCUlJUXbS+F2XdVP+bxrWtalS5dmhx9+eI3T6dGjR/bOO+8U3Y/C23fZZZespKSk0nht2rTJPvjgg1ofsyzLshNOOKFo3LFjx9ZpvCzLsieeeCJr1apVtctfWlqaXXXVVUXjFD5vtW7dOuvSpUul8dq1a5f99a9/zRo2bFjptm7duhU9H1d8XPfaa68ql2X77bcvGm9V9hUV51W4zUdEdvDBB2dZVv12+NJLL2VNmjSpcZ4TJ07Mh/+mbCMAwJrhlCkAkIiKR1N37NixyuEeeuih2HvvveP73/9+3HvvvfmRsH/729/i6aefjp122ikiVhzt3KNHj9hhhx2iY8eO0bJly/jyyy/j2Wefjfvvvz+yLItRo0bFCSecEDvssENERPzmN7/J57P99tvHgQceGEuXLo0333wz/vnPf8bMmTOLluXoo4+O5557LiIimjdvHj/60Y9i/fXXjyeffDIefPDBWL58eZx55pmx3XbbxS677LJS62PevHn5kYwfffRRPProo/Hoo4/GuHHj4s477/xaTp1y4oknxvjx42PJkiVx3XXXRb9+/eKGG27Ij4o/7bTT4q9//etqn29Vrrjiinjttdfit7/9bX7deeedF61atYqIyM/L+3X7+9//Hv3794+ePXvGHXfckR9NfMcdd8Rll10W6667bkRE/PznP49Zs2bl4+26666x5557xpQpU+L+++9f7cvVtGnT6N27d/Tq1Stat24djRs3jo8//jjGjx8fM2fOjMWLF8dpp5222k9189RTT8WVV15Z6fq+ffvG5ptvHhERQ4YMiSlTpkRExJgxY+KGG26IsrKyiIi466678nG6d+8eO++8c0SsOJJ14403jp122inWW2+9aNWqVSxZsiRmzZoVo0ePjqVLl8ajjz4aY8eOjcMPP3y13qdCDRs2jJ122im22mqraNOmTTRr1iw+//zzeOyxx2Lq1KmRZVmcffbZccQRR0Tjxo3j/PPPjzlz5sQll1yST+OEE07IzxFel1PJXHLJJXHPPffkl3faaafo06dPzJw5M0aPHh0RETNnzowjjzwyHn/88Sqn8eSTT0b37t3j0EMPjeeeey4mTJgQESs+tfD73/8+fvazn9W6HI899lj+e6tWreKQQw6pdZyIiM8++ywOPfTQ/FM6jRs3jiFDhkSLFi3irrvuirlz58by5ctj2LBhse2220bv3r0rTeOTTz6JhQsXxumnnx7z58+PkSNHRkTEhx9+GP37949mzZrFKaecEnPnzo0xY8ZERMR//vOfuPfee2PgwIFVLtfjjz8eBx98cGy55ZYxceLEmDp1akRETJ06NS6//PK48MILI2LV9hUVTZkyJTbffPM46KCDIsuyGj9NExHxhz/8IT+ie/3114+jjjoqmjZtGm+99Va8+OKL8fTTTxcN/03ZRgCANUMQB4DvqAcffDA++uijWLx4cTz99NNF0bBDhw7x/e9/v8rx+vfvH2PHjo2SkpI444wzon379rFs2bKIWBE6yoN4z549Y8aMGfHGG2/E1KlT47333ouysrLYbbfdYtq0afnH0R966KE8chR+idx1112XT6vcnDlzokGDBhER8cILL8RDDz2U3zZu3LiiU3wccMABMWHChMiyLK666qo6B/GSkpLYcccdY5tttomOHTvGnDlz4q677oqFCxdGRMTdd98du+22W5x88sl1mt7KWHfddWPAgAFx5513xsMPPxzTpk2LW2+9NSIivve971X6yP/XadiwYTF58uSiID506NA1/iV+Z5xxRlx99dURETFgwIDYaqutIiJi+fLlMW3atFh33XVj6dKl8Yc//CEf5/vf/35Mnjw56tWrF8uXL4999tknJk2atFqX6xe/+EUsX748/vWvf8XMmTPjs88+iw4dOkTfvn3zP9zMnDkz3nzzzdV6fu9HHnkkHnnkkUrXt23bNg/ihx9+eJx22mnx3//+Nz755JN46KGH4sADD4yI4iA+ZMiQ/PemTZvGa6+9Fh988EE8/fTT8fbbb8eCBQtim222ienTp8eLL74YESv+v36dQXzo0KExdOjQeOGFF2L69Onx8ccfR/369ePggw/Og+onn3wS//rXv2K33XaLoUOHVgriRxxxRJ3/ryxfvjyuueaa/PLOO+8cU6ZMyYPqOeecE5dffnlEREyaNCmee+65fBsstMEGG8QzzzyTfxnuNttsE88++2xERL7ctSk8Rcemm25a5z+63XbbbfHxxx/nl8eOHRt9+/aNiIgzzzwzunbtGv/9738jy7K4+uqrqwziERG33HJLfuqsl156qeiPpKNGjYrDDjsssiyL9ddfP9555538vlUXxIcOHRq/+93vImLFH6y23nrr/PQgt9xySx7EV2VfUdFOO+0UkyZNikaNGtVpnRXua04++eRKMbrwFGDfpG0EAFgzBHEA+I66++674+677650faNGjeIPf/hDtWHhxBNPzM+n3Lp162jbtm3+BW+FEeHjjz+OQYMGxfjx42tcjrfeeiv/fbfddosXXnghIlZ8eeDOO+8c3bp1i549e8buu+8evXr1yoeteI7zvfbaq9p5PPXUUzUuQ7kOHTrEnDlzYsMNNyy6/vTTT48dd9wxjyijRo0qCuIjRoyo03m56+L000+PO++8M7Isi4MPPji++OKLiIg49dRTV8v0v21OOumk/PfNNtus6Lby7W3WrFnx3//+N7/+yCOPzGNVaWlpDBo0aLUH8UceeSSOP/74eOONN2oc7q233lrjX3jZtGnTGDBgQIwaNSoiVkTwAw88MF544YX8iPV69erF0UcfnY+zcOHCOOmkk+L222+vdJ7+QoX/X78O//73v+OYY46p9bzKq2s5Xn755fjkk0/yy0cddVTR0cWDBg3KY2fEik/SVBU7jz766Dx0RqwI2uWxs+L3K6xuheG6Xbt2eQyPWHEe8r59++ZHMVf3vQr169fPz0MfseLc7OXDlpWVRf/+/SNixR8MN9poozyI13TfCrevsrKyOPzww2P48OERseLxe//996NDhw6rtK+oaNiwYXWO4REr9jXXXXddRKyI9ffdd1907949Nttss9hxxx1jt912y7eD78I2AgCsHF+qCQAJaNy4cXTv3j1OOumkmD59euy3337VDlvxCOGGDRvmvxeGtOOOO67WwBERRV+OeMkll+Qx57///W888sgjcdNNN8Upp5ySHyE9f/78iIiiQFGbDz/8sE7DlX+pWkUVj86ueOqW1WmHHXaIHXfcMSL+74jRNm3aFH3paV1kFb6Erqovofw2KNzeCre1iP/b3j777LOi6yue7qe60/9UVNd19s4778QhhxxSawyvaRqravjw4ZFlWaWfil8Ieuyxx+a/jxs3LhYsWBB33nlnfl3fvn2jU6dO+eVzzz03brvtthpjeMSq3Z+6rteFCxfGgQceWKcvGVxd67Xi80iHDh1qvFxduKzr82JN1ltvvfz3V155pcovHa5K4X2ouLwVr6tu+du3bx/16//fsVDln8Qpv60wABcOV9N9a9++fbXLEfF//29XZV9RUffu3Wsdv9Bhhx0Ww4YNi4YNG8ayZcviH//4R4waNSp+9rOfxZ577hldu3bNt8Nv0jYCAKwZgjgAfEeNGjUqj2kLFiyImTNnxo033hibbLJJjeOVn4u4XPnR4oXmz58fDzzwQH557733jtdeey2WLl0aWZbF9ttvX+W0W7RoERMmTIg333wzRo8eHRdffHEceeSR0aRJk4iIeOKJJ/Ij8Vq3bl007i9/+cu44oorqvz5f//v/9W+QlZCVfd5dTr99NOLLg8dOjQaN25c4zgVT69QfoqXiIgvvvgiP4r/26Zwe6tuvbds2bLo8gcffFB0+b333qt2+oXrrXCdRaw4R3JV7r///vz8wxERV111VXz22WeRZVmdYu6asOuuu0a3bt0iYsX/x3HjxsWf//zn/PbC06VERNGnRXr16hUvvvhiLFmyJLIsiwEDBqz0/Fdlvf7tb3+Ld999N7989tlnx4cffhhZluV/CFvdKj6PVPx/UvFy+Tn0K6rL82Jt9t577/z3Tz/9NMaNG1en8QrvQ1X/zwuvq+vyFyoM4Cuj4v/DisvWsmXLVd5XVNS0adOVXr4rrrgi3n///ZgwYUL8+te/jhNOOCH/ToK5c+fmn075Jm0jAMCaIYgDACvt888/z88rHrHifN4bb7xx1KtXL15++eX8tCgVlUe49ddfPw477LA477zz4k9/+lMcf/zx+TD//ve/IyIqneO8bdu2MWzYsEo/ffv2rXQu8upcfvnl8fe//73S9dOnT4/JkyfnlwtP3RKx4pQpJSUl+c9Xddhhh+Vhpn79+kWnDalOxShc+KVwl156aZ2PNi1UMeAURuBvku7du0ezZs3yy3fffXd+f7MsKzq/eEWF6+3ZZ5+NxYsXR8SKo/OrG6/wfM0RK+LyOuusExFR9MV7a1th9D7//PNj7ty5EbHi/8pBBx1UNGzhfdpzzz1j8803j/r168eHH35YtO3XVeF6ffnll/OjgT///PO48cYbqxyn4no98sgjo23bthFR83r9KtvpZpttVhQ8//SnPxU9d1XcBqr7boXV4ZRTTik6EvvEE0+M559/vtJwS5YsiZEjR+bBuXCZPvzww5g4cWJ++YMPPii6/HUuf0V//OMf89+XLFlS9Biut9560aFDh1XeV3xVs2fPjs8++yzWWWed6Nu3b5x55pnxm9/8Jm644YZ8mPJ9zTdpGwEA1gznEAcAVlr79u2jZcuWeQT71a9+FR988EEsXbo0br311mo/+j5s2LB45plnYu+9944NNtgg2rVrF++8805+LuSI/wttW265Zey77775FwyecsopMXHixNh2222jtLQ05s6dG0899VTMnDkzhg8fHrvuumuty/3UU0/FOeecE1tssUXstdde0b59+3j99dfjrrvuKvoStroE6q+irKws7r///njjjTdinXXWqdM5qLt37x7NmzePefPm5cv4wAMPxHvvvVfteYNrU3gKh4gVXz633377Rf369eN//ud/YtNNN12l6a5u9evXj8GDB+cxa/LkybHXXnvF7rvvHn/7299qDLrbb799/PWvf42IiFdffTW22Wab6NGjR0yaNKlSoC1X8VzmBxxwQPTt2zdeeOGFGDNmzOq5U9V46qmn4sorr6zytmHDhhVdPuaYY+KCCy6IZcuWxezZs/PrjzrqqEoRebPNNsu/OPOWW26J0tLSaNKkSfzxj3+s8ymHChUe2fvFF1/E1ltvHTvssEM8+eSTRV8eWXEZCh111FFxxBFHxJw5c4riakXt2rWLsrKyWLJkSUSsiP/PP/98lJWVxR577BHbbbddteOWlpbGmWeeGRdccEFErDj/86677hp9+vSJWbNmFUXcPffcM7bccsva7/wq2nzzzeOiiy6K8847LyJWfLJhu+22iwMPPDC23nrrKCkpiVdffTUeeuiheP/992OfffaJiBXnsL7ooovy7fUHP/hBHHvssdGiRYu488478/Prl38R8ppyyy23xIcffhjf+973YuLEiUWfnhg6dGhErPq+4qu6++67Y/jw4bHHHntEt27dolOnTjF//vyiL50t39d8k7YRAGANyQCA74RJkyZlEZH/jBo1apXGmz17dtHtnTt3zm8bPnx4fv1ll11WNF75zxZbbJFtu+22+eVBgwbl4+y3335VjlP+06hRo+yZZ57Jh3///fezrbbaqsZxKi5XTQ4++OBap3XmmWdWGm/48OFFw9TVqFGjisabPn16rePUdL9+/vOfV7nM2223Xda+ffsqx6vt8d16662rnObo0aNrHX/QoEH59b179672fhRuixXXSU33v3C8Tz/9NOvevXuVy9q3b9+iy3Pnzs3He//997M2bdpUGqe0tLTS9lhu8eLFWa9evaqcV+F9johs0qRJdVof1Zk9e3at22RN213F+x4R2QsvvFBpuLvuuqvKaXbq1Cnbd999q1zuistWeF8XLlyYdevWrcpp9uvXr9ptZv/996/Teq34/NW/f/8qx7viiitqXdalS5dmAwYMqHHd9ujRI3v77beL5lnT8qzKY13u2muvzRo2bFjr41243p544omsZcuW1Q5bWlqaXXnllUXzKXze6ty5c7XLX/G23r17Fz0u5So+FxxwwAFVLsu2226bLViwIB9vVfYVtT1vVXU/Ch+HSy+9tNb1e9111+XDf9O2EQDg6+WUKQDAKjnnnHPixhtvjE033TTKysqiY8eOMXTo0HjiiSeKTm9R6Cc/+UmcfvrpsdNOO8V6660XDRo0iIYNG8bGG28cgwYNimeeeaboyNP27dvHP//5z/jNb34Te+21V7Rt2zbq1asXTZs2je7du8dRRx0Vd9xxR/zkJz+p0zJfe+21cc0118R+++0XXbt2jWbNmkWDBg1igw02iCOOOCIef/zx+PWvf71a1s/X4Ze//GVccsklsdFGG0VZWVl07tw5zj333HjiiSdqPQd5df7yl79E//79o3Xr1t/oc962bNkypkyZEv/7v/8b7du3j4YNG8aWW24Zt99+exxzzDGVhi3Xvn37eOKJJ6Jv377RrFmzaNq0aey1114xefLkGDhwYJXzKisri8cffzwGDx4cbdq0iYYNG8YWW2wRv/vd72LEiBFf471ceRXPFb7ttttWOuVPRMTAgQPjnnvuiS233DLKysqiTZs2ccQRR8TTTz+dn75nZTRq1Cgee+yxOPzww6Nly5bRqFGj2HHHHeOvf/1rjf8fx44dG2eccUZ06tQpGjRoEJtssklccskl8fvf/77G+d1yyy0xaNCg6NChQ6Xz6demXr16cc8998To0aOjX79++RdMrrPOOrHjjjvGFVdcEVOnTl2l9bAqTjvttJg9e3aMGDEidt1112jXrl3Ur18/mjRpEj169IgTTzwxJk+eHJ07d87H2X333ePFF1+Ms88+OzbffPNo0qRJNGjQIDbccMM48sgj46mnnoqzzz57jSx/ueuvvz5uuOGG6NmzZzRs2DA6deoUp59+ejz++ONFz0ersq/4qg455JC48MILY5999okuXbpEkyZNon79+tGpU6c44IAD4r777otTTz01H/6bto0AAF+vkixbhRNOAgDAGrZw4cIqw/9hhx0WY8eOjYiIbt26xSuvvLKmFw2+8yZPnhx77rlnfnn27NnRpUuXtbdAAACryDnEAQD4Vthss81iv/32ix122CHWXXfd+OCDD2LMmDExYcKEfJjTTjttLS4hAADwTSeIAwDwrfDFF1/EyJEjY+TIkVXePnTo0Dj55JPX8FIBAADfJoI4AADfCueee248+OCDMWvWrPjkk0+itLQ0OnXqFDvttFMcd9xxsffee6/tRQQAAL7hnEMcAAAAAIAkrNxXtAMAAAAAwLeUIA4AAAAAQBIEcQAAAAAAkiCIAwAAAACQBEEcAAAAAIAkCOIAAAAAACRBEAcAAAAAIAmCOAAAAAAASRDE4Ws2Z86cKCkpiZKSkthjjz3W+Pxvu+22fP4jRozIr99jjz3y6+fMmbNGl2ltr5OqjB49OkpKSqJ+/foxd+7ctb04lZSvry5duuTXPfnkk/n1U6dOXXsLB/A1uOaaa6J79+7RsGHDKCkpia222uprmc/gwYPz59LJkyd/LfOoSZcuXfL5l5s8eXJ+3eDBg9f4Mq3tdVJRlmXRq1evKCkpiaFDh67txfnOu+OOO6KkpCQaNWoUb7311tpeHIBvjBEjRuT7x9tuu21tL06Rb/r72W8S76OJEMT5DincOX1dbx4LI3JJSUk0aNAg2rVrF9tss02cfPLJ8eKLL672ec6ZMydGjBgRI0aMiHvvvXe1T//rctttt+XL/dlnn63txanR8uXL8z8W9O/fPzp37lwUI2r7KYzUtSmMDCUlJVFWVhatW7eOXr16xZAhQ+Kpp56q87R22WWX2H777SMi4sILL1yZuwx8B73//vtx7rnnxpZbbhnNmzePxo0bx8YbbxxDhgyJ559//itPf03uj/785z/HmWeeGS+//HIsXry4TuNUfN6uV69eNGvWLDbaaKPo27dv3HLLLfHll1+u9mX9Nu3vyn3bXlvcfffd+WusM844Y7VPv+J+vap98UEHHVQ0zM9+9rMqp3XCCScUDXfZZZdVOVzF1wPlrwnWXXfdOPTQQ+Ppp5+udnlffvnlOPnkk6N79+7RrFmzaNGiRfTq1StOOumkKt/Yv/7663HqqadG9+7do2nTptG0adPo3r17nHLKKfH6669XGv7www+PddddNxYtWhQXX3xxtcsBpKnw4Kbaftb0gVer4tNPP42zzz47unXrFg0bNozmzZtHly5dok+fPnHeeefF/Pnz19iyXHPNNfn+eWVU9X62XOEf3iv+kXtNNJRvIu+jiYiIDL4jhg8fnkVEFhHZoEGDvpZ59O7dO59HVT8lJSXZhRdeWDTOl19+mU2ZMiWbMmVK9sILL6z0PCdNmvSV7tf777+fz3/u3LlV3pfZs2ev9HRrU9P0v+o6Wd3uv//+fFkffPDBLMuK13ttP507d67zvAYNGlTr9I4//vhs8eLFReOVr6+pU6cWXX/zzTfn402fPv0rrwvg2+mJJ57IWrduXe3zSmlpaXbttdd+pXl81f3RyjjyyCPzeV144YXZlClTsmeffbbOy1fdz2abbZbNmjWraLxXXnklf4797LPPVnpZv+r+dOrUqfn8q7ovX8e6rm36X3WdrG7bbrttFhHZTjvt9LVMv+J2MmTIkKLb33rrraxevXpFw5xzzjmVprN48eKsTZs2RcNtueWWVc6zttcDDRo0yJ555plK411//fVZ/fr1qx2v4vxGjx6dNWrUqNrhGzVqlI0ePbrSfM4999x8OT7++OO6r0zgO2/27Nl1fp/01ltvre3FrdGCBQuynj171ngf3nzzzXz4wuYwatSo1b48nTt3zqe/Mqp6P1vVNCdNmlR025poKN9U3kdTP4BVct5558V+++0Xb7/9dtxzzz1x7733RpZl8ctf/jJatWqVH8HUsGHD2HXXXdf48i1evDhKS0ujffv20b59+zU+/5qsrXVSnVGjRkVERKtWrWKvvfaKiIitt946pkyZkg/z7LPPxmmnnRYRER07dozRo0fntzVq1GiV5jtkyJAYMmRIfPDBB3H//ffH7bffHlmWxciRI6Np06ZxzTXX5MNWt74OOeSQOPHEE2P58uVx2223xZVXXrlKywJ8e7311ltxyCGHxKeffhoREbvttlucfvrp0axZs7jnnnvi1ltvjeXLl8cZZ5wRm2yySfTr128tL3Ht3nnnnfz3wYMHx0YbbbRS45c/T8+fPz+mTZsW1113Xbz//vvx8ssvx/777x/PPvtstGzZMiIiunXrFt26dVudi18n8+fPj6ZNm8Z22223xuddm7W1Tqoyffr0mDZtWkRE/OAHP1gj87znnnvi2muvjebNm0dExK233hrLli2rdbxHHnkkPv7446Lrnn/++Zg1a1Z079692vGGDBkSxx57bLz11lvxs5/9LObOnRuLFy+Om2++OT+CLSJizJgxceqpp+aX+/TpE8cee2y0a9cu5s6dG2PGjCn6v/Pss8/GkUcemX/K4n/+53/yU86MHDkyxo0bF19++WUcddRRsckmmxSdlujQQw+NSy+9NBYvXhx33nlnnHLKKbXefyANnTp1KnqfVO6TTz6JgQMHxsKFCyMi4sc//nGst956q3Xe5fvO1eVPf/pTzJgxIyIittlmm/jpT38abdu2jTfeeCOeffbZGDNmzGqb19epqvez1Mz7aBwhzndGdX/dLLz+1ltvza6++uqsa9euWYMGDbLvfe972WOPPVbneRQeBVbxL8Jnn312flvz5s2zTz/9NMuy4r+g9+7dOx9+wYIF2bBhw7JNNtkka9CgQdakSZOsS5cuWf/+/bO//OUvleZX8af8PhYeYTRhwoTsrLPOyjp27JiVlJRks2fPzkaNGpXfPnz48Crvy0svvZSddtppWbt27bImTZpkBxxwQPbqq68W3b/yYSseDV3xyLjajtCbPXt2tesky7Ls888/z84777yse/fuWaNGjbJmzZplO+ywQ/bb3/42W758ebXL9Morr2QHHXRQ1rRp06xVq1bZ//7v/2YLFy6s9TFdtGhRfuRU//79qx2u8H4VroOjjjoqv/7xxx8vGueMM87IbxszZkyWZcWPV+HjkWUrjvoqv620tDR7+eWXq7yvFW211VZZRGQbb7xxrfcX+O459dRTi46A/vLLL4tuHzx4cH57r1698uurO8qpqqOH67I/qs1//vOfbPDgwdn666+flZWVZa1bt8769u2bPfroo1XOe2XnU93zdJZl2Ztvvpmts846+e0///nP89sKn5cLj5yaNGlStvfee2etWrXK6tevn7Vt2zbbfvvts9NOOy377LPPVml/98QTT2Q77bRT1qhRo/z+VHU0WMXH4LHHHsu23377rGHDhlmXLl2yq6++uuj+re7Hsrp1kmVZ9thjj2X9+vXL2rRpk5WVlWXrr79+NmjQoOyVV16pdpm+yuuvX/ziF/l0nn/++WrnMXLkyGzEiBFZx44ds+bNm2cDBw7MPv300+zjjz/OjjrqqKxFixbVvj4oXAfNmzfPIiK7+eabsyzLsmXLluWPUfltEVUfIX700Ufntw8cOLDa/X3FdVx4+1VXXZVf36dPn/z6JUuWZBtuuGF+22GHHVbpdVGWZdmMGTPy3w866KB8+D333LNo+OXLl2d77rlnfvtBBx1UaVqtWrXKIiLba6+9Kt0GUFH//v3z55SePXtmCxYsKLp93rx52fDhw7PNN988a9SoUda8efOsd+/e2YQJE4qGq8u+M8uybNq0adlhhx2WdejQISsrK8s6dOiQ/eAHP8j+9a9/1XmZTzjhhHxe9913X6XbFy9enC1ZsiS/XHF/e+ONN+bv56vbt9Xl9U/he/aqfmpS2/vZVTlCfGX34bNnz85++MMfZp06dcrq16+frbPOOlmPHj2ywYMHV9p3P//889nAgQOzjh07ZmVlZdm6666bHXfccUVH4pdb1W3mmWeeyfbYY4+scePGWYcOHbLzzz8/W7ZsWaXpex+dNkGc74y6PJlvvPHGlXYuzZs3zz755JM6zaOmID5v3rz8jUNEZH/84x+zLKs+iB977LHV7vCOPPLISvOry5vWivevrkH8e9/7XqXpr7feetlHH32UD19dZFidQfyTTz7JunfvXu24AwcOLJp3+fUtWrSo9BHliMjOP//8Wh/Tp556Kh/+oosuqna46kJL4fXHHXdc0Thdu3bNl6/8zXdNQXzZsmXZZpttVuXyVLf+s6x4W3r33Xdrvc/Ad8v666+fPwfccMMNlW6fPn160XPja6+9lmXZmg3i//znP4tiYuFPSUlJdtNNN1Wa98rOp6YgnmVZ9qtf/Sq/vWvXrvn1VcXfWbNmZY0bN652Wf7zn/+s9P5u3XXXLTp1RV2DeI8ePbKysrJK07/00kvz4ddUEL/xxhuzkpKSKsdt3rx50Sk+Vtfrrz59+mQRK07tURglKs6jfJ9b+LP//vtnO+ywQ62vDwpvGzp0aBYR2fbbb59lWZZNnDgxi4isXr162XHHHZcPVzGIL1y4MN/G27Vrl7333nv5qU0222yzSverutcDV155ZX794MGD8+v/9re/5deXlpZmr7/+eo3rbcGCBVmDBg3ycR544IFKwxR+xL5BgwaV/lCw1157ZRGRNW3aNFu6dGmN8wPS9tvf/jZ/PmnUqFGl02J+9tlnWa9evard/9x44435sHXZd44bN67KfWNEZGVlZdm4cePqtNw/+clP8vF22WWX7OGHH87mz59f7fCF+50ePXrUum+r6+ufrxLEa3s/+1WDeG378CVLlmSbbrpptct+yy235NOdMGFC1rBhwyqH69ixY9G+bVW3mU6dOlX5Gq5wOcp5H502X6pJUl5//fU455xz4r777ostt9wyIiLmzZsXd95551eedrNmzWKLLbbILz/33HM1Dj9u3LiIiOjcuXOMGTMmHn744fj9738fxxxzTLRq1SoiIq6//vq47rrr8nH69u0bU6ZMiSlTpsT5559faZqvv/56nHbaafHggw/GzTffnH/UtzbvvPNOjBo1KkaPHh0bb7xxRES8/fbbcckll9Rp/ELlpxop/Njt6NGj8+Xu1KlTteOed955MWvWrIiI6NWrV/zlL3+JkSNH5uvjz3/+c9x9992Vxvviiy+iXbt2MXbs2Ljooovy62+++eZal3fmzJn575tsskmtw1fUu3fv6Nq1a0REjB07NhYtWhQRES+99FK89tprEbHii03qclqV0tLS2GGHHfLLtW1D5QqXu/wjf0Aa5s2bF2+99VZ+ufC5t9zmm28eZWVl+eVVeZ5Y2f1RoSzLYsiQITFv3ryIiDjssMNi/PjxccEFF0RpaWlkWRZnnHFGvPnmmzXuQ2qbT2123nnn/PfXXnst/vvf/1Y77COPPJJ/5Pv000+Pxx57LMaMGRO/+tWvYrvttouSkpKV3t+98847sf7668ef/vSnmDBhQhxyyCF1Wu6ZM2fGgAEDYvz48XHmmWfm148YMSI++uijOk2j0Ko+lm+++WaceeaZkWVZlJaWxs9//vMYP358DBgwICJWbIuDBw+OLMsqjftVXn+V76c7d+4c9etXf7bHOXPmxOWXXx533313/vrnwQcfjBkzZsTIkSPjN7/5TT5sTa8Pjj/++IiImDp1akyfPj1uueWWiIjYb7/9Yv311692vAceeCDfxg855JDo0KFD7LHHHhGx4kswn3322WrHfeONN+Lvf/973H333fljU69evXxZIqLoi3HXW2+9Wk8j9OqrrxZ9IW1Vzw2F1y1evDheffXVotvLX1/Mnz8/5s6dW+P8gHTNnDkzzjrrrPzyVVddFb169Soa5vzzz4/p06dHRES/fv1i/Pjxcfvtt0fHjh0jIuLMM8+MN998s9K0q9p3zp8/P4477rhYsmRJRESceOKJMWHChDjppJMiImLJkiVx3HHH1enLMPfZZ5/89yeffDL69OkTLVq0iO222y5+8Ytf1LifnTlzZo37tpV5/dOvX7+YMmVKvj4iIt83V3V6morLUW5V3s/WprZ9+KxZs+KVV16JiBXr88EHH4wHHnggrr/++ujbt280bNgwIiIWLFgQgwYNikWLFkX9+vXj4osvjocffjh++tOfRkTEe++9lz+GEau+zbz77ruxzTbbxLhx4/JTnkZUve/3PjptziFOUg4++OC47LLLImLFE/LAgQMjIvI3AJ9//nn+pFuuUaNGdT6/Z+Gb388//7zGYcvjRMuWLaNr167Ro0ePaNiwYRx77LH5ML169So6F2X79u1rPPf2j370o7j22mvrtKyFLr300vxbpVu2bBn77rtvRETce++9cdVVV63UtNZZZ53YddddY5111smv22677aJLly41jrd8+fKi2H3nnXfmf2BYuHBhfs7Mu+66K4444ohK4991112x1VZbxaGHHhp33HFHzJo1Kz766KP4/PPPi5alosIXOeXhfWWUlJTEscceG+eff3589tlnMX78+Dj00EPj/vvvz4f54Q9/WOfprcw2VK5wuVcljgDfXl988UXR5Xbt2lUapqSkJNq0aRPvvfdeRNT9uaVQbfujRYsWxdSpUyuNt+uuu8Zzzz2Xv8no2LFj3HnnnVFWVhb9+vWLGTNmxNixY2Px4sUxduzYOOOMM2rch0yfPr3S8m+66aZ1+q6MioH6888/j2bNmlU5bOEfEDbaaKPo2bNn/gasMBqvzP6utLQ0Hnjggdhss81qXdZCG264Ydx+++1Rr1696NevXzzzzDPx5JNPxqJFi2LixIlx9NFHr9T0Vva1RbkxY8bkgbV///75H6D33XffmDJlSrz33nsxY8aMeP755yvF19pef9WkfL9W2z76iCOOiJ/85CcREXH77bfH+PHjI2LFG+bjjjsuIiJuuOGGeOmll2p8ffC9730vtt9++5g6dWr86le/yvfnxx9/fFGUrujPf/5z/vthhx2W//voo4/mt2+99dZVjjtq1Kj8/K8RERtvvHFcf/31scsuu+TXFW736667bg1rYoW6PDdUvK7i/62Kry/KD5oAKLdo0aL44Q9/GAsWLIiIFX8QLIyaESve55XH0wYNGsRZZ50VDRs2jBYtWsShhx4aN910UyxevDjuueeeOPvss4vGrWrf+de//jXfN2y77bZx0003RcSKP/D+85//jGnTpsVHH30UjzzySBxyyCHxr3/9K7788sui6fbq1SvWWWed6NOnT5xzzjlx+eWX53/QXbZsWUybNi2mTZsWN954Y/zjH//ID4AqVNu+bWVf/7Rv3z6PxxHVf4dURV/1/Wxtarufha+ZOnXqFN26dYsuXbpEaWlp0fdPPPzww/Hhhx9GxIrXDrvvvntERBx00EFxzz33xJw5c+Khhx6Kjz76KFq3br3K20yDBg1i7Nix0aFDhzjwwANj5MiRsWDBgipfc3gfnTZHiJOU3r1757+3adMm//2zzz6LiBVfPrTbbrsV/ZS/qamLt99+O/+9pggbEfmbs+effz623nrraNq0afTs2TPOOuusePfdd+s8z0IHHXTQKo2344475r8XHqE8Z86cKo/0+jp8+OGH+RfCNWnSpOho+8JlKv/rc6EWLVoUvfmu6rGti1W9r4MHD4569epFRMQdd9wRERH33XdfRKwIDXvvvXedp7Uy21C5NfUYAd88LVq0KLpc/kajUJZlRQG0rs8tK+Pdd9+ttP/cbbfdIqL4eXubbbYpeuNU2/N7RaeeemqleUyYMKFOy1j4/BpR83o4+OCD833JGWecEZ06dYrWrVtH3759i75UeWV069ZtpWN4xIrIXr6PiSheZ6+//voqLcuqKHx8Cl83lJWVFYXeqh7H2l5/1UVt+7rC9dK6dev898KDGtq2bVuneZd/8eQ999wTS5YsiY4dO9b4GmvevHl5gG/dunX+hWaHHnpo/tjdfffddd5fv/HGG5Ue28LttfCLM6tTl+eGitdV/D/h9QVQm5/+9Kf5Hws32GCD+P3vf19pmI8++ih/n7d48eLYZ5998n14ecyOKD7SuVxV+87q9kcRVb+uOOywwyq9dij81M5ll10WL7zwQlxwwQWx4447Fn0a6cMPP4wLLrigyvte275tdb7+qauqnrdLSkqqvb3wcmlp1XmwtvvZrVu3/DXfH//4x+jatWs0a9Ysdt5557jiiivyT1AX3s+JEycWPR5z5szJl6f8wLZV3Wa6d+8eHTp0yO9TefSuar9vP5c2QZykFP4FsHBHtzqeCL/44ot48cUX88tVfTS10EUXXRR33XVXDBgwIDbbbLMoKSmJmTNnxtVXXx19+vSJpUuXrvQylD/xfxWFO8yqLFu2rOjy1/GX1IrLUNsyVfxL+Mo8toVvjst3uitr3XXXjf333z8iIsaPHx+vvPJK/POf/4yIiAEDBtT4Ee9Cy5Yty8eLqH0bKle43IX3B/jua968edFpHKo61dKMGTPyjxVHRPTs2TMiip9bC5/b1+QRMrU9v69OTz75ZP57+Zu16nTs2DGmTZsW55xzTuy6667Rpk2b+PTTT+PBBx+Mww8/vOho4LpaHfvoiKrX2dp+LFdmP72yr7/K92u17aMLY27hm/qKYbgu8x44cGA0bdo0vzxo0KAa9+X33ntvfvThJ598EmVlZVFSUhLt27fPH4+5c+fGP/7xjyrHHz58eCxatChuv/32KC0tjaVLl8YZZ5xR9P+5/GPqESv+uFMeD6qzySabRIMGDfLLVT03FB7x3qBBg0oftff6AqjJ+PHji07zdMcddxT9QXJlVXWKk5Xdd67q64otttgifvnLX8bTTz8dH330UZx88sn5bf/+97+rHOer7NtW5+uf2t7PFp5GteLrgsLL1Z1utbb7WVpaGhMmTIirrroq9t9//9hwww1j4cKF8fTTT8dPf/rTOP3001fq/tTlVDc1DVtTG6jIfi5tgjgU2GOPPSJb8WWz+U9tbzjKXXjhhflHTZs1axYHHHBAreMMHDgw7rnnnpg1a1bMmzcvPxr9xRdfzP+CWvimbvny5TVOb1V3rM8880z+e2GQ7dKlSz7N8jeaH3/8cR5W5syZk5/zu6KVWe6IFR/bbdmyZUSs2LG99NJLVS7TpptuWuu0VkaPHj3y3+vy0e3qlB/xv2jRojj22GPz+7wyp0u5/vrr82UoLS3Nz8tam8LlLg9dQDoKz0V94403Fp03OCLi17/+df57r1698tMeFAbE8tOpRKw473JVanpe79KlS6X9Z/kbpcLn7WeffbboD74r+/w+efLkSvMoP+VXTd54442i9VDVqbcKZVkWnTt3jssuuyymTJkSH330UdEpYf7yl7/kv9d1f7eq++hp06YVTbdwnX0dj2V1Ch+fwtcNS5YsKTrS7uvaT8+dO3eVDhZYFc2bNy/aRsr38dW566676jTdmv6Q0qBBgzj66KPjmGOOiYgVf9gYMWJEfvvOO+8cG264YUSseMx+9rOfVTmd8qPlGjduHH369Mmvv/rqq4siTZZlcfXVV+eX99tvv0rfd1L++qJp06bRuXPnutxFIBHvvfdeDBkyJL98wQUX5EcJV9S2bds8UjZr1izmzZtXaV++bNmyolNHlatq31nd/qji5fLhyj/1XPhT/h0PzzzzTKVIvM4668SPf/zj/HLFA8LqalVe/6zK/rm297OFR9g//PDD+e/Lli2Lxx57LL/cvXv3Os2voizLolmzZnHWWWfFxIkTY+7cufHBBx/k33VR/pqp8H4OGjSoyteN8+fPj/322+8rbTMrw/votDmHOKyi//znP/G3v/0t3nnnnbjrrrvyU2RERPziF7+o9fxdu+yyS2y99daxww47xHrrrRfz5s0r+iKH8o8WFU7n73//e0ycODGaN29e53Om1sW5554b9evXj6ZNm8a5556bX3/wwQfnv2+yySYxbdq0WLhwYfzoRz+K3XffPW666aZqXyAULvctt9wS/fr1i8aNG1d7PvbS0tIYOHBg/Pa3v42IiCOPPDKGDx8en376aQwfPjwfbmUCc11s+//Zu+/wKMr1jeP3bkIqhJ5ESgioNFF65wBqKIqFIwpWihyxRdEoYgBFRA+oyEEBRT1iORY4iiAIB8UoSlN6bxYkCoYEERICqfv+/sDsjyxJCGR3Z5P9fq6LS3f23Zln2JfcmWd3Ztq2VUhIiLKysor99L80rrnmGkVGRio1NdX5LcSYmBh16dKl2NckJydrxYoVSk1N1cKFC/Wf//zH+dz9999f6lPrCxoRjRo1KnQjFgD+4bHHHtN7772no0ePateuXerVq5dGjhyp8PBwffzxx5o9e7Zz7Ok3Sz7926BTp05V5cqV9eOPPxYaf7rzzaNWrVqpWbNm2rVrl37//XfddtttGjp0qL7//nvNnz9f0qlm4IABA87778BVdna2Vq5cqRMnTmjdunV6+eWXnddUbtCggR599NESX//hhx9q1qxZ6t+/vxo2bKiqVavqq6++KrT+Auead+dq//79GjJkiG699VYlJSU5MyY4ONh5dpI33ssbb7xRo0ePVm5urj755BONHz9enTp10jvvvOO81Fvz5s0LfZPZHbp27aovvvhC2dnZ2rFjh9vXX5xRo0apfv36qlWrli6++OJix/3xxx9atmyZpFONdNcbkufk5Divb/rRRx9p2rRpxZ6WLkmjR4/WO++8I2OMFi5cqN27d6tp06YKDAzUlClTNHDgQEmnLsFy7NgxDRs2TLVr19b+/fv18ccf68CBA87fC5566il9/vnnys3NVVJSkm644QYNHz5cNptNb775prMREhQUVKj5XqDgW+UdO3YsdNkeAP7NGKMhQ4Y4L7vUoEED9ezZUytXrjxjbEGu3HLLLXrllVd0/Phx9e7dWw8++KBq1aql3377Tdu3b9cnn3yi2bNnOxvVJendu7dq1qypP/74Q+vXr1d8fLz69eunJUuWaP369ZJONeEL7otVkoULF+pf//qX/v73v+vKK69UgwYNdOzYMU2bNs05pn379qX7i3FxPr//VK9eXfv27ZN06stSbdu2VdWqVc+4SenpznY8e9NNN+njjz+WJP373//W0aNH1bRpU3355Zfas2ePpFOXP7vuuuvOaz8PHDiguLg4DRw4UM2bN1dUVJT27dvnnB8FvzP16tVLtWvXVlpamt59913VqFFDvXr1Un5+vn755RetWrVKW7Zs0c6dO2W32906Z4rDcbSfM0AFMX78eCPJSDJDhgwpcvlbb73lXP71118XOb4kPXr0cL6mqD82m8088cQThV6zb98+5/M9evRwLr/wwguLXU/z5s1NXl6eMcaY3NxcEx0dfcaYgn0ZMmSIc9nXX399Rs1vvfWW8/nx48cXuS8XX3zxGeu/4IILTGpqqnP8a6+9dsaYypUrm3r16jkf79u3zzl++vTpZ4xv0KBBiX8nf/zxh2natGmxfy8333yzcTgczvGu6y1q306vqTgDBgwwkkz16tVNbm5ukWNOny+u2yvw6KOPFqr3scceO2PM6e9XcX+GDx9ucnJyCr2uuG0fOnTI2O12I8k8+uijZ91XABXTV199ZapVq1bszxW73W6mTp1a6DU5OTkmJibmjLHNmjUrMh/Plkcl+f77702VKlWKzc5XXnml0Phz/TluTOGf08X9ufjii83u3bsLva6oHP3Pf/5T4no+/PBD5+vPJ+9O16BBA+eYovalUaNGzp/zp/955plnnOPd/V4W97vFzJkzjc1mK/LvpEqVKmbt2rXOse76/Wvbtm3O8VOmTCn0XHHbKK7+4ubV6ftx8uTJYms5fXujR482xhgza9Ys57IBAwYU+bpWrVo5x3z55Zdn1Hj672fGGNOvXz/nc//4xz8KPTd9+nQTGBhY7Nxs2bJlofEffvihCQkJKXZ8SEiImTNnzhk1r1u3zjlmxowZxf6dAPA/K1euPGveuv5s/vPPP82ll15a4tiCn9elyc4FCxaYSpUqFbmeSpUqmU8//bRU+zJ27NgSa6pcubLZtm2bc/y5Ztu5/v7zyCOPnDGuuL+D05V0POtwOMz1119f4n66/o54Lvv566+/lrjuu+++2/n6xYsXm+Dg4GLHnn6s6645U9TvWcZwHA1juGQKUAaBgYGqUaOGWrZsqbvvvlubNm3S008/XarXJiYm6vrrr1eDBg0UFhamSpUqKTY2Vvfcc4+++uor5zdxAgMDtXDhQnXr1q3Y63qV1UcffaQRI0aoZs2aCg0N1VVXXaVvv/1WtWvXdo75xz/+ocTEREVGRio0NFRXXHGFVqxYUeQdtyXp7rvv1ujRoxUTE1PiN6FOV6NGDX333XdKTExUkyZNFBwcrPDwcLVv316vvvqqPvjgA49cb7bgdL8///xTX3/99Xmvx/WU6tJ8mz0gIEDVqlVT8+bNdccdd+ibb77Rv//970I3XSnJggULnKfTleayAQAqpssvv1y7du3S6NGj1aJFC4WHhys4OFixsbEaMmSI1q9fr4cffrjQaypVqqQFCxaoc+fOCgoKUr169TRhwgTn9UBdlSWPOnTooA0bNmjIkCGqW7euAgMDVb16dfXt21dffPGF7r333vPe9+LYbDaFhYWpQYMG6t27t1599VVt2bKlVGffdO7cWSNHjlSbNm1Uq1YtBQQEqGrVqvrb3/6muXPn6uabb3aOPZ+8Oxd/+9vftHDhQrVu3VrBwcFq0KCBXnzxRY0dO9Y5xlvv5X333adly5bpqquuUo0aNRQYGKg6depo8ODB2rBhw3l/i64kLVq0cH7b/vRL1fiK0y+XUty3606/IWdprj9f8I1y6dQNyk6/DE58fLy2bdume++9V02aNFFYWJgqV66spk2basSIEXr99dcLrevmm2/W9u3bdd9996lx48YKDQ1VaGioGjdurPvuu0/btm0r8hJCBX/XwcHBbj87D0D5dvp9SUqrWrVqWrNmjSZOnKiWLVsqNDRUYWFhuvjii3XjjTfqww8/VKdOnUq9vuuvv15r1qzRjTfeqMjISAUGBqp27dq64YYbtHr16lJ/2/mee+7R9OnTde2116px48aqUqWKKlWqpJiYGN1xxx1at26dWrRocc77W+Bcf/8ZP368RowYoTp16pzTcW9Jx7M2m03z5s3TzJkz1blzZ0VERDj/vvr166elS5ee8TviuahRo4bGjx+vHj166IILLlClSpUUGhqqyy67TM8884ymT5/uHHv11Vdr/fr1uuOOO1SvXj1VqlRJtWrVUqtWrZSQkFDoxuXunjOuOI6GzRhuqwrAvzkcDl122WXasWOHBg4cqLlz5573uho1aqR9+/apWbNmhS6B4ykdOnTQunXrdNVVV2nJkiUe3x4AAN52+ocQO3bs4DqfHpabm6vY2FgdPHhQ9957r1555RWrSwIAlMCdx7P+guNo8A1xAH7Pbrc7r1M+b948JScnn9Pr8/LylJ6ero8//th5zbeCm2J50qpVq5w3eZswYYLHtwcAgBUGDhzo/Ibe6TeChGf897//1cGDBxUcHKwxY8ZYXQ4A4CzKejzrbziOhsQ3xAGgzN5+++1Cd1mPjIzUnj17VK1aNeuKAgAAAAAAwBn4hjgAuElISIi6deum//3vfzTDAQAAAAAAfBDfEAcAAAAAAAAA+AW+IQ4AAAAAAAAA8As0xAEAAAAAAAAAfiHQ6gJ8lcPh0MGDB1WlShXZbDarywEAVDDGGGVkZKhOnTqy2/l8+nyR1wAATyOz3YPMBgB40rnkNQ3xYhw8eFD169e3ugwAQAX366+/ql69elaXUW6R1wAAbyGzy4bMBgB4Q2nymoZ4MapUqSLp1F9iREREmdY1YMAAHf7lF9WSNO/2291QHTxhwHvv6bCkWrGxmjdvnme3NWCAfk75XXlVKuual6d4dFs4f589+KgCM46rUfQF3pkTB1OUExahvv+c4dFtoWyWjolX0Il0NaoTXaZ5kZ6ervr16zvzBueHvPZP3sps8rr88FZmk9flh7vyWiKz3cVdmU1elx8cY8MVx9hwZVVe0xAvRsEpXBEREWU+wK5UqZICAgJUSVJESIgbqoMnVAoIUIBOvV9lfc/Puq2/5oQjMFDBlSt7dFs4f/bAwFP/dr00J+wBAbIHBioonDnhy+yBgbK7cV5wynDZkNf+yVuZTV6XH97KbPK6/HB3Xktkdlm5K7PJ6/KDY2y44hgbrqzKay6ABgAAAAAAAADwCzTEAQAAAAAAAAB+gYY4AAAAAAAAAMAv0BAHAAAAAAAAAPgFGuIAAAAAAAAAAL9AQxwAAAAAAAAA4BdoiAMAAAAAAAAA/AINcQAAAAAAAACAX6AhDgAAAAAAAADwCzTEAQAAAAAAAAB+gYY4AAAAAAAAAMAv0BAHAAAAAAAAAPgFGuIAAAAAAAAAAL9AQxwAAAAAAAAA4BdoiAMAAAAAAAAA/AINcQAAAAAAAACAX6AhDgAAAAAAAADwCzTEAQAAAAAAAAB+gYY4AAAAAAAAAMAv+ERDfObMmYqNjVVISIg6duyotWvXFjt2x44dGjBggGJjY2Wz2TRt2rQS1z158mTZbDY99NBD7i0aAAA/RGYDAOD7yGsAAIpneUN87ty5SkhI0Pjx47Vx40a1bNlSffr0UWpqapHjT5w4oUaNGmny5MmKjo4ucd3r1q3Ta6+9pssuu8wTpQMA4FfIbAAAfB95DQBAySxviE+dOlV33XWXhg0bpubNm2vWrFkKCwvT7Nmzixzfvn17vfDCC7r55psVHBxc7HqPHz+u2267TW+88YaqV6/uqfIBAPAbZDYAAL6PvAYAoGSBVm48JydHGzZsUGJionOZ3W5XXFyc1qxZU6Z133///erXr5/i4uL0zDPPnHV8dna2srOznY/T09MlSQ6HQw6Ho0y12Gw22ex22SSVbU3wpIL3yGazlfk9P+u2bDbZ7XbZbTbJGI9uC+fP/tf75O05YWNO+DR3zQtPzyl385XMJq8heS+zyevyw1uZTV6XH+6cE+Ups30lryXPZTZ5XX5wjA1XHGPDlVV5bWlD/PDhw8rPz1dUVFSh5VFRUdq9e/d5r3fOnDnauHGj1q1bV+rXTJo0SRMmTDhjeVpamrKyss67FkmKiYlRRFCQqklKrVy5TOuC58Q0aaIISdWio4s9ndBt24qJUWB4uPLDQlUz86RHt4Xz16xhIwWcOKk6NWt6Z06EhSsvJFy1co57dFsom+YXNlRgVqbq1CrbvMjIyHBjVZ7nK5lNXkPyXmaT1+WHtzKbvC4/3JXXUvnKbF/Ja8lzmU1elx8cY8MVx9hwZVVeW9oQ94Rff/1VI0eO1LJlyxQSElLq1yUmJiohIcH5OD09XfXr11ft2rUVERFRppqSk5OVum+fIiVFdupUpnXBc5L37FGqpMicHEVGRnp2W8nJ+un3g8qtUlmNw0M9ui2cv137flaljOPKy8z0ypz48cDvygmLUMMgfrH3ZTt/2qegE+nKO1G2eXEuGVVRnU9mk9eQvJfZ5HX54a3MJq/LD3fltURm+9oxNnldfnCMDVccY8OVVXltaUO8Vq1aCggI0KFDhwotP3To0Flv5lGcDRs2KDU1VW3atHEuy8/P17fffqsZM2YoOztbAQEBZ7wuODi4yOul2e122e1lu9S6MUbG4ZCRD1y0HcUqeI+MMWV+z8+6LWNOnSpojGSzeXRbOH+Ov94nb88Jw5zwae6aF56eU+7mK5lNXkPyXmaT1+WHtzKbvC4/3DknylNm+0peS57LbPK6/OAYG644xoYrq/La0vwICgpS27ZtlZSU5FzmcDiUlJSkzp07n9c6r7zySm3btk2bN292/mnXrp1uu+02bd68ucigBgAAJSOzAQDwfeQ1AABnZ/klUxISEjRkyBC1a9dOHTp00LRp05SZmalhw4ZJkgYPHqy6detq0qRJkk7dJGTnzp3O/z9w4IA2b96sypUr66KLLlKVKlXUokWLQtsIDw9XzZo1z1gOAABKj8wGAMD3kdcAAJTM8ob4oEGDlJaWpieffFIpKSlq1aqVli5d6rwJSHJycqGvvB88eFCtW7d2Pp4yZYqmTJmiHj16aPny5d4uHwAAv0FmAwDg+8hrAABKZnlDXJLi4+MVHx9f5HOuARwbGytjzDmtnxAHAMA9yGwAAHwfeQ0AQPG4BwUAAAAAAAAAwC/QEAcAAAAAAAAA+AUa4gAAAAAAAAAAv0BDHAAAAAAAAADgF2iIAwAAAAAAAAD8Ag1xAAAAAAAAAIBfoCEOAAAAAAAAAPALNMQBAAAAAAAAAH6BhjgAAAAAAAAAwC/QEAcAAAAAAAAA+AUa4gAAAAAAAAAAv0BDHAAAAAAAAADgF2iIAwAAAAAAAAD8Ag1xAAAAAAAAAIBfoCEOAAAAAAAAAPALNMQBAAAAAAAAAH6BhjgAAAAAAAAAwC/QEAcAAAAAAAAA+AUa4gAAAAAAAAAAv0BDHAAAAAAAAADgF2iIAwAAAAAAAAD8Ag1xAAAAAAAAAIBfoCEOAAAAAAAAAPALNMQBAAAAAAAAAH6BhjgAAAAAAAAAwC/QEAcAAAAAAAAA+AUa4gAAAAAAAAAAv0BDHAAAAAAAAADgF2iIAwAAAAAAAAD8Ag1xAAAAAAAAAIBfoCEOAAAAAAAAAPALNMQBAAAAAAAAAH6BhjgAAAAAAAAAwC/QEAcAAAAAAAAA+AUa4gAAAAAAAAAAv0BDHAAAAAAAAADgF2iIAwAAAAAAAAD8Ag1xAAAAAAAAAIBfoCEOAAAAAAAAAPALNMQBAAAAAAAAAH7BJxriM2fOVGxsrEJCQtSxY0etXbu22LE7duzQgAEDFBsbK5vNpmnTpp0xZtKkSWrfvr2qVKmiyMhI9e/fX3v27PHgHgAA4B/IbAAAfB95DQBA8SxviM+dO1cJCQkaP368Nm7cqJYtW6pPnz5KTU0tcvyJEyfUqFEjTZ48WdHR0UWO+eabb3T//ffru+++07Jly5Sbm6vevXsrMzPTk7sCAECFRmYDAOD7yGsAAEoWaHUBU6dO1V133aVhw4ZJkmbNmqXFixdr9uzZevzxx88Y3759e7Vv316SinxekpYuXVro8dtvv63IyEht2LBB3bt3d/MeAADgH8hsAAB8H3kNAEDJLG2I5+TkaMOGDUpMTHQus9vtiouL05o1a9y2nWPHjkmSatSoUeyY7OxsZWdnOx+np6dLkhwOhxwOR5m2b7PZZLPbZZNUtjXBkwreI5vNVub3/Kzbstlkt9tlt9kkYzy6LZw/+1/vk7fnhI054dPcNS88PafczVcym7yG5L3MJq/LD29lNnldfrhzTpSnzPaVvJY8l9nkdfnBMTZccYwNV1bltaUN8cOHDys/P19RUVGFlkdFRWn37t1u2YbD4dBDDz2krl27qkWLFsWOmzRpkiZMmHDG8rS0NGVlZZWphpiYGEUEBamapNTKlcu0LnhOTJMmipBULTq62NMJ3batmBgFhocrPyxUNTNPenRbOH/NGjZSwImTqlOzpnfmRFi48kLCVSvnuEe3hbJpfmFDBWZlqk6tss2LjIwMN1bleb6S2eQ1JO9lNnldfngrs8nr8sNdeS2Vr8z2lbyWPJfZ5HX5wTE2XHGMDVdW5bXll0zxtPvvv1/bt2/XypUrSxyXmJiohIQE5+P09HTVr19ftWvXVkRERJlqSE5OVuq+fYqUFNmpU5nWBc9J3rNHqZIic3IUGRnp2W0lJ+un3w8qt0plNQ4P9ei2cP527ftZlTKOKy8z0ytz4scDvysnLEINg/jF3pft/Gmfgk6kK+9E2eZFSEiIG6uqGEqT2eQ1JO9lNnldfngrs8nr8sNdeS2R2a6sPsYmr8sPjrHhimNsuLIqry1tiNeqVUsBAQE6dOhQoeWHDh0q9mYe5yI+Pl6fffaZvv32W9WrV6/EscHBwQoODj5jud1ul91etnuPGmNkHA4Z+cBdTFGsgvfIGFPm9/ys2zLm1KmCxkg2m0e3hfPn+Ot98vacMMwJn+aueeHpOeVuvpLZ5DUk72U2eV1+eCuzyevyw51zojxltq/kteS5zCavyw+OseGKY2y4siqvLc2PoKAgtW3bVklJSc5lDodDSUlJ6ty583mv1xij+Ph4zZ8/X1999ZUaNmzojnIBAPBbZDYAAL6PvAYA4Owsv2RKQkKChgwZonbt2qlDhw6aNm2aMjMznXfEHjx4sOrWratJkyZJOnWTkJ07dzr//8CBA9q8ebMqV66siy66SNKpU7g++OADffrpp6pSpYpSUlIkSVWrVlVoKKfOAABwPshsAAB8H3kNAEDJLG+IDxo0SGlpaXryySeVkpKiVq1aaenSpc6bgCQnJxf6yvvBgwfVunVr5+MpU6ZoypQp6tGjh5YvXy5JevXVVyVJPXv2LLStt956S0OHDvXo/gAAUFGR2QAA+D7yGgCAklneEJdOXYcsPj6+yOcKArhAbGysjDElru9szwMAgPNDZgMA4PvIawAAisc9KAAAAAAAAAAAfoGGOAAAAAAAAADAL9AQBwAAAAAAAAD4BRriAAAAAAAAAAC/QEMcAAAAAAAAAOAXaIgDAAAAAAAAAPwCDXEAAAAAAAAAgF+gIQ4AAAAAAAAA8As0xAEAAAAAAAAAfoGGOAAAAAAAAADAL9AQBwAAAAAAAAD4BRriAAAAAAAAAAC/QEMcAAAAAAAAAOAXaIgDAAAAAAAAAPwCDXEAAAAAAAAAgF+gIQ4AAAAAAAAA8As0xAEAAAAAAAAAfoGGOAAAAAAAAADAL9AQBwAAAAAAAAD4BRriAAAAAAAAAAC/QEMcAAAAAAAAAOAXaIgDAAAAAAAAAPwCDXEAAAAAAAAAgF+gIQ4AAAAAAAAA8As0xAEAAAAAAAAAfoGGOAAAAAAAAADAL9AQBwAAAAAAAAD4BRriAAAAAAAAAAC/QEMcAAAAAAAAAOAXaIgDAAAAAAAAAPwCDXEAAAAAAAAAgF+gIQ4AAAAAAAAA8As0xAEAAAAAAAAAfoGGOAAAAAAAAADAL9AQBwAAAAAAAAD4BRriAAAAAAAAAAC/QEMcAAAAAAAAAOAXaIgDAAAAAAAAAPwCDXEAAAAAAAAAgF+gIQ4AAAAAAAAA8As+0RCfOXOmYmNjFRISoo4dO2rt2rXFjt2xY4cGDBig2NhY2Ww2TZs2rczrBAAApUNmAwDg+8hrAACKZ3lDfO7cuUpISND48eO1ceNGtWzZUn369FFqamqR40+cOKFGjRpp8uTJio6Odss6AQDA2ZHZAAD4PvIaAICSWd4Qnzp1qu666y4NGzZMzZs316xZsxQWFqbZs2cXOb59+/Z64YUXdPPNNys4ONgt6wQAAGdHZgMA4PvIawAAShZo5cZzcnK0YcMGJSYmOpfZ7XbFxcVpzZo1Xl1ndna2srOznY/T09MlSQ6HQw6H47xqKWCz2WSz22WTVLY1wZMK3iObzVbm9/ys27LZZLfbZbfZJGM8ui2cP/tf75O354SNOeHT3DUvPD2n3M1XMpu8huS9zCavyw9vZTZ5XX64c06Up8z2lbyWPJfZ5HX5wTE2XHGMDVdW5bWlDfHDhw8rPz9fUVFRhZZHRUVp9+7dXl3npEmTNGHChDOWp6WlKSsr67xqKRATE6OIoCBVk5RauXKZ1gXPiWnSRBGSqkVHe/zUv5iYGAWGhys/LFQ1M096dFs4f80aNlLAiZOqU7Omd+ZEWLjyQsJVK+e4R7eFsml+YUMFZmWqTq2yzYuMjAw3VuV5vpLZ5DUk72U2eV1+eCuzyevyw115LZWvzPaVvJY8l9nkdfnBMTZccYwNV1bltaUNcV+SmJiohIQE5+P09HTVr19ftWvXVkRERJnWnZycrNR9+xQpKbJTpzJWCk9J3rNHqZIic3IUGRnp2W0lJ+un3w8qt0plNQ4P9ei2cP527ftZlTKOKy8z0ytz4scDvysnLEINg/jF3pft/Gmfgk6kK+9E2eZFSEiIG6vyH+Q1JO9lNnldfngrs8nr8sNdeS2R2efLU5lNXpcfHGPDFcfYcGVVXlvaEK9Vq5YCAgJ06NChQssPHTpU7M08PLXO4ODgIq+XZrfbZbeX7VLrxhgZh0NGPnDRdhSr4D0yxpT5PT/rtow5daqgMZLN5tFt4fw5/nqfvD0nDHPCp7lrXnh6Trmbr2Q2eQ3Je5lNXpcf3sps8rr8cOecKE+Z7St5LXkus8nr8oNjbLjiGBuurMprS/MjKChIbdu2VVJSknOZw+FQUlKSOnfu7DPrBADA35HZAAD4PvIaAICzs/ySKQkJCRoyZIjatWunDh06aNq0acrMzNSwYcMkSYMHD1bdunU1adIkSadu6LFz507n/x84cECbN29W5cqVddFFF5VqnQAA4NyR2QAA+D7yGgCAklneEB80aJDS0tL05JNPKiUlRa1atdLSpUudN+xITk4u9JX3gwcPqnXr1s7HU6ZM0ZQpU9SjRw8tX768VOsEAADnjswGAMD3kdcAAJTM8oa4JMXHxys+Pr7I5woCuEBsbKyMMWVaJwAAOD9kNgAAvo+8BgCgeNyDAgAAAAAAAADgF2iIAwAAAAAAAAD8Ag1xAAAAAAAAAIBfoCEOAAAAAAAAAPALNMQBAAAAAAAAAH6BhjgAAAAAAAAAwC/QEAcAAAAAAAAA+AUa4gAAAAAAAAAAv0BDHAAAAAAAAADgF2iIAwAAAAAAAAD8Ag1xAAAAAAAAAIBfoCEOAAAAAAAAAPALNMQBAAAAAAAAAH6BhjgAAAAAAAAAwC/QEAcAAAAAAAAA+AUa4gAAAAAAAAAAv0BDHAAAAAAAAADgF2iIAwAAAAAAAAD8Ag1xAAAAAAAAAIBfoCEOAAAAAAAAAPALNMQBAAAAAAAAAH6BhjgAAAAAAAAAwC/QEAcAAAAAAAAA+AUa4gAAAAAAAAAAvxB4vi/ct2+fUlNTZbPZVLt2bTVs2NCddQEAADchswEA8H3kNQAA3nFO3xA/fPiw4uPjVbNmTV100UXq0qWLOnfurIsuukg1a9bUAw88oMOHD3uqVgAAUEpkNgAAvo+8BgDA+0r9DfGDBw+qa9euSk5OljHmjOf//PNPvfLKK1q8eLFWrVqlCy64wK2FAgCA0iGzAQDwfeQ1AADWKHVDfOzYsdq/f78kqXHjxmratKkiIiJkjFFGRoZ2796tvXv3av/+/Ro7dqxmz57tsaIBAEDxyGwAAHwfeQ0AgDVK3RD/3//+J5vNpjfffFNDhw4tcsxbb72l4cOHa8mSJe6qDwAAnCMyGwAA30deAwBgjVJfQ/zYsWOSpGuvvbbYMQXPFYwFAADeR2YDAOD7yGsAAKxR6oZ4o0aNJEnDhw/X2rVrlZ6e7nzu2LFjWrt2rYYPHy5JuvDCC91cJgAAKC0yGwAA30deAwBgjVJfMuUf//iHHnnkES1atEiLFi0qdpzNZtNdd93lluIAAMC5I7MBAPB95DUAANYo9TfEH3roIY0YMULGmBL/jBgxQiNHjvRkzQAAoARkNgAAvo+8BgDAGqX+hrjNZtOsWbN055136v3339fGjRuVlpYmSapdu7batGmj2267TR06dPBYsQAA4OzIbAAAfB95DQCANUrdEC/QoUMHAhkAgHKAzAYAwPeR1wAAeNc5N8RLkpOTozlz5kiSBg8e7M5VAwAANyKzAQDwfeQ1AADu59aGeEZGhoYOHSq73U5YAwDgw8hsAAB8H3kNAID7lfqmmufCGOOJ1QIAADcjswEA8H3kNQAA7lPqb4jXqVPnrGMIaQAArEdmAwDg+8hrAACsUeqGeEpKimw2G4EMAICPI7MBAPB95DUAANY452uI161bV4GBRb/M4XDo119/LXNRAACg7MhsAAB8H3kNAIB3lfoa4hdeeKEk6Z133tG+ffuK/LNhw4bzKmLmzJmKjY1VSEiIOnbsqLVr15Y4/qOPPlLTpk0VEhKiSy+9VEuWLCn0/PHjxxUfH6969eopNDRUzZs316xZs86rNgAAyhsyGwAA30deAwBgjVI3xDt37ixjjFavXl3sGJvNds4FzJ07VwkJCRo/frw2btyoli1bqk+fPkpNTS1y/OrVq3XLLbdo+PDh2rRpk/r376/+/ftr+/btzjEJCQlaunSp3nvvPe3atUsPPfSQ4uPjtXDhwnOuDwCA8obMBgDA95HXAABYo9QN8ZEjR+pf//qX2rVrV+yYKlWq6K233tLs2bNLXcDUqVN11113adiwYc5PmcPCwopdx0svvaS+fftq1KhRatasmSZOnKg2bdpoxowZzjGrV6/WkCFD1LNnT8XGxmrEiBFq2bLlWT8VBwCgIiCzAQDwfeQ1AADWKPU1xNu2bau2bduWOCYoKEhDhgwp9cZzcnK0YcMGJSYmOpfZ7XbFxcVpzZo1Rb5mzZo1SkhIKLSsT58+WrBggfNxly5dtHDhQt15552qU6eOli9frr179+pf//pXsbVkZ2crOzvb+Tg9PV3SqWu2ORyOUu9TUWw2m2x2u2ySyrYmeFLBe2Sz2cr8np91Wzab7Ha77DabxE10fJb9r/fJ23PCxpzwae6aF56cUxU5s8lrSN7LbPK6/PBWZpPX5Yc754Sn5lRFzmvJc5lNXpcfHGPDFcfYcGVVXp/zTTXd6fDhw8rPz1dUVFSh5VFRUdq9e3eRr0lJSSlyfEpKivPx9OnTNWLECNWrV0+BgYGy2+1644031L1792JrmTRpkiZMmHDG8rS0NGVlZZ3Lbp0hJiZGEUFBqiYptXLlMq0LnhPTpIkiJFWLji72dEK3bSsmRoHh4coPC1XNzJMe3RbOX7OGjRRw4qTq1KzpnTkRFq68kHDVyjnu0W2hbJpf2FCBWZmqU6ts8yIjI8ONVXmer2Q2eQ3Je5lNXpcf3sps8rr8cFdeS+Urs30lryXPZTZ5XX5wjA1XHGPDlVV5fd4N8YMHD+q9997TunXrlJGRoQsuuED9+vXTjTfeeL6rdJvp06fru+++08KFC9WgQQN9++23uv/++1WnTh3FxcUV+ZrExMRCn4qnp6erfv36ql27tiIiIspUT3JyslL37VOkpMhOncq0LnhO8p49SpUUmZOjyMhIz24rOVk//X5QuVUqq3F4qEe3hfO3a9/PqpRxXHmZmV6ZEz8e+F05YRFqGMQv9r5s50/7FHQiXXknyjYvQkJC3FhVySpSZpPXkLyX2eR1+eGtzCavyw935bXkvcyuSHkteS6zyevyg2NsuOIYG66syuvzaojPnDlTjz32mPLz89WxY0dFR0drzZo1evfdd9W3b18tXLhQAQEBZ11PrVq1FBAQoEOHDhVafujQIUVHRxf5mujo6BLHnzx5UmPGjNH8+fPVr18/SdJll12mzZs3a8qUKcWGdXBwsIKDg89YbrfbZbeX+lLrRTLGyDgcMjqHi7bD6wreI2NMmd/zs27LmFOnChojnceNcuAdjr/eJ2/PCcOc8GnumheenlMFKlpmk9eQvJfZ5HX54a3MJq/LD3fOCW9kdkXLa8lzmU1elx8cY8MVx9hwZVVen/OWJk2apAcffFAtW7bUjh079M0332ju3LnavXu3HnroIS1dulQvvvii9u7dq+Tk5BLXFRQUpLZt2yopKcm5zOFwKCkpSZ07dy7yNZ07dy40XpKWLVvmHJ+bm6vc3Nwz/hICAgI8fn0iAAB8CZkNAIDvI68BAPCuc/qG+JYtWzR+/HjFxMTo1ltv1apVq7Rq1Srn8zExMTLG6L333lNqaqqWLFmiTZs2FfmpcIGEhAQNGTJE7dq1U4cOHTRt2jRlZmZq2LBhkqTBgwerbt26mjRpkqRTd+Lu0aOHXnzxRfXr109z5szR+vXr9frrr0uSIiIi1KNHD40aNUqhoaFq0KCBvvnmG7377ruaOnXqOf8FAQBQHpHZAAD4PvIaAADvO6eG+MyZM5Wfn6/ExETdc889shVzysGPP/6oqVOnaurUqXrppZf02GOPFbvOQYMGKS0tTU8++aRSUlLUqlUrLV261HlTj+Tk5EKfRHfp0kUffPCBxo0bpzFjxujiiy/WggUL1KJFC+eYOXPmKDExUbfddpuOHDmiBg0a6Nlnn9U999xzLrsLAEC5RWYDAOD7yGsAALzvnBriX331lSTpqquu0htvvKExY8aobt26Gjp0qIwxeuedd3TgwAE9++yzatKkiSTpvffeKzGsJSk+Pl7x8fFFPrd8+fIzlt1000266aabil1fdHS03nrrrVLuFQAAFQ+ZDQCA7yOvAQDwvnNqiB88eFDSqTB8/vnndfjwYe3YsUO1atWSJN12222KjIzUCy+8oCFDhkg69Uk2AADwLjIbAADfR14DAOB953RTzYiICEnS77//rrS0NEnSkiVLnM8X/P/hw4eVmZkpSapcubJbCgUAAKVHZgMA4PvIawAAvO+cGuIdO3aUJK1Zs0ajR4+WMUbDhg1TrVq1VLNmTedNOkaNGuW8EUi7du3cXDIAADgbMhsAAN9HXgMA4H3ndMmUO++8U4sWLdLLL7+sVatWqU2bNnr99df1448/yhijK6+8UiNGjFBcXJzi4uJks9mcp3UBAADvIbMBAPB95DUAAN53Tg3x66+/Xr1799ayZcs0evRoPffcc+rVq9cZ45566il99dVX6tmzpwYNGuS2YgEAQOmQ2QAA+D7yGgAA7zunS6ZI0ty5c9W5c2e98MIL6tu3r7766itlZGToxIkTWrFihfr376+nn35a7du317x58zxRMwAAKAUyGwAA30deAwDgXef0DXFJqlq1qpYvX66pU6dq6tSpztO2JMkYo5o1a2rixIkaNWqUgoKC3F4wAAAoHTIbAADfR14DAOBd59wQl6TAwEA99thjGjVqlDZu3Kh9+/ZJkmJjY9WmTRvZ7ef8xXMAAOABZDYAAL6PvAYAwHvOqyFewGazqW3btmrbtm2h5X/88Ydq1qxZpsIAAID7kNkAAPg+8hoAAM9z68fMR48e1dixY9WwYUN3rhYAALgZmQ0AgO8jrwEAcL9zaojPmzdPvXr1UtOmTdW9e3dNnz7d+dyUKVPUsGFDTZ48WZmZmW4vFAAAlB6ZDQCA7yOvAQDwvlJfMuWjjz7SzTff7Hz8ww8/aNWqVdq/f78yMjL073//W9Kpm35ERES4v1IAAFAqZDYAAL6PvAYAwBqlboi//PLLMsacsXz69OkyxsgYo9DQUN1///0aPXq0W4sEAAClR2YDAOD7yGsAAKxR6kumbNu2TTabTRMnTlR6erqOHTump59+Wrm5ucrPz1dcXJx++OEHPf/889zsAwAAC5HZAAD4PvIaAABrlLohnpGRIUl69NFHVblyZVWpUkWjRo1yPv+f//xHderUcX+FAADgnJDZAAD4PvIaAABrlPqSKcYY2Ww2paamFnlaV05OjpKTk52PY2Ji3FMhAAA4J2Q2AAC+j7wGAMAapW6IF4iNjS302GaznbHcZrMpLy+vTIUBAICyIbMBAPB95DUAAN51zg3xoj65BgAAvofMBgDA95HXAAB4V6kb4t27d3d+Ug0AAHwXmQ0AgO8jrwEAsEapG+LLly/3YBkAAMBdyGwAAHwfeQ0AgDXsnljp0qVLPbFaAADgZmQ2AAC+j7wGAMB9zrkhnpeXp5SUFOXm5p7x3Ndff61u3bqpX79+bikOAACcPzIbAADfR14DAOBdpW6I5+Xl6YEHHlDVqlVVt25dhYWFacCAAfrzzz91+PBhXXPNNYqLi9Pq1as9WS8AADgLMhsAAN9HXgMAYI1SX0P8hRde0MyZM2Wz2WSMUX5+vhYsWKCsrCxlZGRo5cqVzrGdO3f2SLEAAODsyGwAAHwfeQ0AgDVK3RD/4IMPJEl2u10tW7aUMUZbt24tdC2zVq1a6ZlnntHVV1/t/koBAECpkNkAAPg+8hoAAGuU+pIpP/30k2w2m5YuXar169drw4YN+t///idjjCRp1KhR2rBhA0ENAIDFyGwAAHwfeQ0AgDVK3RDPysqSJF1xxRXOZaf//1NPPSWbzebG0gAAwPkgswEA8H3kNQAA1ij1JVMKvPfee85PrE/38ccfF1o+ePDgslUGAADKhMwGAMD3kdcAAHjXOTfEhw4dWuhxwSfWpy+32WyENQAAFiOzAQDwfeQ1AADedU4N8aI+tQYAAL6HzAYAwPeR1wAAeF+pG+JPPvkk1y8DAKAcILMBAPB95DUAANYodUP8qaee8mAZAADAXchsAAB8H3kNAIA1St0Q79KlS6lXarPZtGrVqvMqCAAAlA2ZDQCA7yOvAQCwRqkb4t99951sNpuMMSWe1nW25wEAgGeR2QAA+D7yGgAAa5zTTTUlOQMbAAD4NjIbAADfR14DAOBd9nMZXBDSDRo00IQJE/Trr7/K4XCc8Sc/P98jxQIAgNIhswEA8H3kNQAA3lfqhvi+ffs0duxY1a1bV/v379dTTz2l2NhYXXPNNVqwYAEBDQCAjyCzAQDwfeQ1AADWKHVDvEGDBpo4caJ++eUXLVq0SNdee61sNpv+97//acCAAapXr55ef/11T9YKAABKgcwGAMD3kdcAAFjjnC6ZIkl2u139+vXTggULNH/+fFWrVk2SdOjQIS1dutTd9QEAgPNEZgMA4PvIawAAvOucb6p59OhRvffee3rzzTe1detW5zXPOnXqpGHDhrm9QAAAcH7IbAAAfB95DQCAd5X6G+JJSUm69dZbVadOHY0cOVJbtmxRjRo1NHLkSG3btk2rV6/Wtddee15FzJw5U7GxsQoJCVHHjh21du3aEsd/9NFHatq0qUJCQnTppZdqyZIlZ4zZtWuXrrvuOlWtWlXh4eFq3769kpOTz6s+AADKEzIbAADfR14DAGCNUn9DvFevXrLZbDLGqEGDBho2bJj+/ve/Kzg4WJK0d+/eQuMbN25cqvXOnTtXCQkJmjVrljp27Khp06apT58+2rNnjyIjI88Yv3r1at1yyy2aNGmSrrnmGn3wwQfq37+/Nm7cqBYtWkiSfvrpJ3Xr1k3Dhw/XhAkTFBERoR07digkJKS0uwsAQLlFZgMA4PvIawAArHHOl0yx2WxKTk7WhAkTNGHChGLH5OXllWp9U6dO1V133eU8FWzWrFlavHixZs+erccff/yM8S+99JL69u2rUaNGSZImTpyoZcuWacaMGZo1a5YkaezYsbr66qv1/PPPO1934YUXntN+AgBQ3pHZAAD4PvIaAADvOqeGeMG1zNwlJydHGzZsUGJionOZ3W5XXFyc1qxZU+Rr1qxZo4SEhELL+vTpowULFkiSHA6HFi9erMcee0x9+vTRpk2b1LBhQyUmJqp///7F1pKdna3s7Gzn4/T0dOf6HA7Hee7hKTabTTa7XTZJZVsTPKngPbLZbGV+z8+6LZtNdrtddptNcvO/K7iP/a/3ydtzwsac8GnumheenlMVNbPJa0jey2zyuvzwVmaT1+WHO+eEJ+dURc1ryXOZTV6XHxxjwxXH2HBlVV6XuiE+ZMiQ8yqmJIcPH1Z+fr6ioqIKLY+KitLu3buLfE1KSkqR41NSUiRJqampOn78uCZPnqxnnnlGzz33nJYuXaobbrhBX3/9tXr06FHkeidNmlTkp/FpaWnKyso6n91ziomJUURQkKpJSq1cuUzrgufENGmiCEnVoqOVmprq2W3FxCgwPFz5YaGqmXnSo9vC+WvWsJECTpxUnZo1vTMnwsKVFxKuWjnHPbotlE3zCxsqMCtTdWqVbV5kZGS4sarCKnJmk9eQvJfZ5HX54a3MJq/LD3flteS5zK7IeS15LrPJ6/KDY2y44hgbrqzK61I3xN96663zKsbbCj4NuP766/Xwww9Lklq1aqXVq1dr1qxZxYZ1YmJioU/F09PTVb9+fdWuXVsRERFlqik5OVmp+/YpUlJkp05lWhc8J3nPHqVKiszJKfLaem7dVnKyfvr9oHKrVFbj8FCPbgvnb9e+n1Up47jyMjO9Mid+PPC7csIi1DCIX+x92c6f9inoRLryTpRtXnjympsVObPJa0jey2zyuvzwVmaT1+WHu/Ja8lxmV+S8ljyX2eR1+cExNlxxjA1XVuX1OV9D3J1q1aqlgIAAHTp0qNDyQ4cOKTo6usjXREdHlzi+Vq1aCgwMVPPmzQuNadasmVauXFlsLcHBwc6bl5zObrfLbreXan+KY4yRcThkJJVtTfCkgvfIGFPm9/ys2zLm1KmCxkg2m0e3hfPn+Ot98vacMMwJn+aueeHpOeVuvpLZ5DUk72U2eV1+eCuzyevyw51zojxltq/kteS5zCavyw+OseGKY2y4siqvLc2PoKAgtW3bVklJSc5lDodDSUlJ6ty5c5Gv6dy5c6HxkrRs2TLn+KCgILVv31579uwpNGbv3r1q0KCBm/cAAAD/QGYDAOD7yGsAAM7O0m+IS1JCQoKGDBmidu3aqUOHDpo2bZoyMzOdd8QePHiw6tatq0mTJkmSRo4cqR49eujFF19Uv379NGfOHK1fv16vv/66c52jRo3SoEGD1L17d11++eVaunSpFi1apOXLl1uxiwAAVAhkNgAAvo+8BgCgZJY3xAcNGqS0tDQ9+eSTSklJUatWrbR06VLnTT2Sk5MLfeW9S5cu+uCDDzRu3DiNGTNGF198sRYsWKAWLVo4x/z973/XrFmzNGnSJD344INq0qSJ5s2bp27dunl9/wAAqCjIbAAAfB95DQBAySxviEtSfHy84uPji3yuqE+cb7rpJt10000lrvPOO+/UnXfe6Y7yAADAX8hsAAB8H3kNAEDxuAcFAAAAAAAAAMAv0BAHAAAAAAAAAPgFGuIAAAAAAAAAAL9AQxwAAAAAAAAA4BdoiAMAAAAAAAAA/AINcQAAAAAAAACAX6AhDgAAAAAAAADwCzTEAQAAAAAAAAB+gYY4AAAAAAAAAMAv0BAHAAAAAAAAAPgFGuIAAAAAAAAAAL9AQxwAAAAAAAAA4BdoiAMAAAAAAAAA/AINcQAAAAAAAACAX6AhDgAAAAAAAADwCzTEAQAAAAAAAAB+gYY4AAAAAAAAAMAv0BAHAAAAAAAAAPgFGuIAAAAAAAAAAL9AQxwAAAAAAAAA4BdoiAMAAAAAAAAA/AINcQAAAAAAAACAX6AhDgAAAAAAAADwCzTEAQAAAAAAAAB+gYY4AAAAAAAAAMAv0BAHAAAAAAAAAPgFGuIAAAAAAAAAAL9AQxwAAAAAAAAA4BdoiAMAAAAAAAAA/AINcQAAAAAAAACAX6AhDgAAAAAAAADwCzTEAQAAAAAAAAB+gYY4AAAAAAAAAMAv0BAHAAAAAAAAAPgFGuIAAAAAAAAAAL9AQxwAAAAAAAAA4BdoiAMAAAAAAAAA/AINcQAAAAAAAACAX6AhDgAAAAAAAADwCzTEAQAAAAAAAAB+wWca4jNnzlRsbKxCQkLUsWNHrV27tsTxH330kZo2baqQkBBdeumlWrJkSbFj77nnHtlsNk2bNs3NVQMA4F/IawAAfB95DQBA8XyiIT537lwlJCRo/Pjx2rhxo1q2bKk+ffooNTW1yPGrV6/WLbfcouHDh2vTpk3q37+/+vfvr+3bt58xdv78+fruu+9Up04dT+8GAAAVGnkNAIDvI68BACiZTzTEp06dqrvuukvDhg1T8+bNNWvWLIWFhWn27NlFjn/ppZfUt29fjRo1Ss2aNdPEiRPVpk0bzZgxo9C4AwcO6IEHHtD777+vSpUqeWNXAACosMhrAAB8H3kNAEDJAq0uICcnRxs2bFBiYqJzmd1uV1xcnNasWVPka9asWaOEhIRCy/r06aMFCxY4HzscDt1xxx0aNWqULrnkkrPWkZ2drezsbOfj9PR053ocDse57NIZbDabbHa7bJLKtiZ4UsF7ZLPZyvyen3VbNpvsdrvsNptkjEe3hfNn/+t98vacsDEnfJq75oWn55S7kdfwJd7KbPK6/PBWZpPX5Yc750R5ymxfyWvJc5lNXpcfHGPDFcfYcGVVXlveED98+LDy8/MVFRVVaHlUVJR2795d5GtSUlKKHJ+SkuJ8/NxzzykwMFAPPvhgqeqYNGmSJkyYcMbytLQ0ZWVllWodxYmJiVFEUJCqSUqtXLlM64LnxDRpoghJ1aKjiz2d0G3biolRYHi48sNCVTPzpEe3hfPXrGEjBZw4qTo1a3pnToSFKy8kXLVyjnt0Wyib5hc2VGBWpurUKtu8yMjIcGNVnkdew5d4K7PJ6/LDW5lNXpcf7sprqXxltq/kteS5zCavyw+OseGKY2y4siqvLW+Ie8KGDRv00ksvaePGjbLZbKV6TWJiYqFPxdPT01W/fn3Vrl1bERERZaonOTlZqfv2KVJSZKdOZVoXPCd5zx6lSorMyVFkZKRnt5WcrJ9+P6jcKpXVODzUo9vC+du172dVyjiuvMxMr8yJHw/8rpywCDUM4hd7X7bzp30KOpGuvBNlmxchISFurKp8Iq9xvryV2eR1+eGtzCavyw935bVEZp9PXkuey2zyuvzgGBuuOMaGK6vy2vKGeK1atRQQEKBDhw4VWn7o0CFFR0cX+Zro6OgSx69YsUKpqamKiYlxPp+fn69HHnlE06ZN0y+//HLGOoODgxUcHHzGcrvdLru9bJdaN8bIOBwy8pGLtqNIBe+RMabM7/lZt2XMqVMFjZHO4ZdKeJfjr/fJ23PCMCd8mrvmhafnlLuR1/Al3sps8rr88FZmk9flhzvnRHnKbF/Ja8lzmU1elx8cY8MVx9hwZVVeW54fQUFBatu2rZKSkpzLHA6HkpKS1Llz5yJf07lz50LjJWnZsmXO8XfccYe2bt2qzZs3O//UqVNHo0aN0ueff+65nQEAoIIirwEA8H3kNQAAZ2f5N8QlKSEhQUOGDFG7du3UoUMHTZs2TZmZmRo2bJgkafDgwapbt64mTZokSRo5cqR69OihF198Uf369dOcOXO0fv16vf7665KkmjVrqmbNmoW2UalSJUVHR6tJkybe3TkAACoI8hoAAN9HXgMAUDKfaIgPGjRIaWlpevLJJ5WSkqJWrVpp6dKlzht7JCcnF/rae5cuXfTBBx9o3LhxGjNmjC6++GItWLBALVq0sGoXAACo8MhrAAB8H3kNAEDJfKIhLknx8fGKj48v8rnly5efseymm27STTfdVOr1F3ddMwAAUHrkNQAAvo+8BgCgeJZfQxwAAAAAAAAAAG+gIQ4AAAAAAAAA8As0xAEAAAAAAAAAfoGGOAAAAAAAAADAL9AQBwAAAAAAAAD4BRriAAAAAAAAAAC/QEMcAAAAAAAAAOAXaIgDAAAAAAAAAPwCDXEAAAAAAAAAgF+gIQ4AAAAAAAAA8As0xAEAAAAAAAAAfoGGOAAAAAAAAADAL9AQBwAAAAAAAAD4BRriAAAAAAAAAAC/QEMcAAAAAAAAAOAXaIgDAAAAAAAAAPwCDXEAAAAAAAAAgF+gIQ4AAAAAAAAA8As0xAEAAAAAAAAAfoGGOAAAAAAAAADAL9AQBwAAAAAAAAD4BRriAAAAAAAAAAC/QEMcAAAAAAAAAOAXaIgDAAAAAAAAAPwCDXEAAAAAAAAAgF+gIQ4AAAAAAAAA8As0xAEAAAAAAAAAfoGGOAAAAAAAAADAL9AQBwAAAAAAAAD4BRriAAAAAAAAAAC/QEMcAAAAAAAAAOAXaIgDAAAAAAAAAPwCDXEAAAAAAAAAgF+gIQ4AAAAAAAAA8As0xAEAAAAAAAAAfoGGOAAAAAAAAADAL9AQBwAAAAAAAAD4BRriAAAAAAAAAAC/QEMcAAAAAAAAAOAXaIgDAAAAAAAAAPwCDXEAAAAAAAAAgF/wmYb4zJkzFRsbq5CQEHXs2FFr164tcfxHH32kpk2bKiQkRJdeeqmWLFnifC43N1ejR4/WpZdeqvDwcNWpU0eDBw/WwYMHPb0bAABUaOQ1AAC+j7wGAKB4PtEQnzt3rhISEjR+/Hht3LhRLVu2VJ8+fZSamlrk+NWrV+uWW27R8OHDtWnTJvXv31/9+/fX9u3bJUknTpzQxo0b9cQTT2jjxo365JNPtGfPHl133XXe3C0AACoU8hoAAN9HXgMAUDKfaIhPnTpVd911l4YNG6bmzZtr1qxZCgsL0+zZs4sc/9JLL6lv374aNWqUmjVrpokTJ6pNmzaaMWOGJKlq1apatmyZBg4cqCZNmqhTp06aMWOGNmzYoOTkZG/uGgAAFQZ5DQCA7yOvAQAoWaDVBeTk5GjDhg1KTEx0LrPb7YqLi9OaNWuKfM2aNWuUkJBQaFmfPn20YMGCYrdz7Ngx2Ww2VatWrcjns7OzlZ2d7Xycnp4uSXI4HHI4HKXcm6LZbDbZ7HbZJJVtTfCkgvfIZrOV+T0/67ZsNtntdtltNskYj24L58/+1/vk7TlhY074NHfNC0/PKXcjr+FLvJXZ5HX54a3MJq/LD3fOifKU2b6S15LnMpu8Lj84xoYrjrHhyqq8trwhfvjwYeXn5ysqKqrQ8qioKO3evbvI16SkpBQ5PiUlpcjxWVlZGj16tG655RZFREQUOWbSpEmaMGHCGcvT0tKUlZVVml0pVkxMjCKCglRNUmrlymVaFzwnpkkTRUiqFh1d7OmEbttWTIwCw8OVHxaqmpknPbotnL9mDRsp4MRJ1alZ0ztzIixceSHhqpVz3KPbQtk0v7ChArMyVadW2eZFRkaGG6vyPPIavsRbmU1elx/eymzyuvxwV15L5SuzfSWvJc9lNnldfnCMDVccY8OVVXlteUPc03JzczVw4EAZY/Tqq68WOy4xMbHQp+Lp6emqX7++ateuXWLIl0ZycrJS9+1TpKTITp3KtC54TvKePUqVFJmTo8jISM9uKzlZP/1+ULlVKqtxeKhHt4Xzt2vfz6qUcVx5mZlemRM/HvhdOWERahjEL/a+bOdP+xR0Il15J8o2L0JCQtxYVflHXuNceCuzyevyw1uZTV6XH+7Ka4nMPl1p81ryXGaT1+UHx9hwxTE2XFmV15Y3xGvVqqWAgAAdOnSo0PJDhw4pOjq6yNdER0eXanxBWO/fv19fffVViaEbHBys4ODgM5bb7XbZ7WW71LoxRsbhkJGPXLQdRSp4j4wxZX7Pz7otY06dKmiMZLN5dFs4f46/3idvzwnDnPBp7poXnp5T7kZew5d4K7PJ6/LDW5lNXpcf7pwT5SmzfSWvJc9lNnldfnCMDVccY8OVVXlteX4EBQWpbdu2SkpKci5zOBxKSkpS586di3xN586dC42XpGXLlhUaXxDWP/zwg7788kvVrFnTMzsAAIAfIK8BAPB95DUAAGdn+TfEJSkhIUFDhgxRu3bt1KFDB02bNk2ZmZkaNmyYJGnw4MGqW7euJk2aJEkaOXKkevTooRdffFH9+vXTnDlztH79er3++uuSToX1jTfeqI0bN+qzzz5Tfn6+8/pnNWrUUFBQkDU7CgBAOUZeAwDg+8hrAABK5hMN8UGDBiktLU1PPvmkUlJS1KpVKy1dutR5Y4/k5ORCX3vv0qWLPvjgA40bN05jxozRxRdfrAULFqhFixaSpAMHDmjhwoWSpFatWhXa1tdff62ePXt6Zb8AAKhIyGsAAHwfeQ0AQMl8oiEuSfHx8YqPjy/yueXLl5+x7KabbtJNN91U5PjY2FgZY9xZHgAAEHkNAEB5QF4DAFA8y68hDgAAAAAAAACAN9AQBwAAAAAAAAD4BRriAAAAAAAAAAC/QEMcAAAAAAAAAOAXaIgDAAAAAAAAAPwCDXEAAAAAAAAAgF+gIQ4AAAAAAAAA8As0xAEAAAAAAAAAfoGGOAAAAAAAAADAL9AQBwAAAAAAAAD4BRriAAAAAAAAAAC/QEMcAAAAAAAAAOAXaIgDAAAAAAAAAPwCDXEAAAAAAAAAgF+gIQ4AAAAAAAAA8As0xAEAAAAAAAAAfoGGOAAAAAAAAADAL9AQBwAAAAAAAAD4BRriAAAAAAAAAAC/QEMcAAAAAAAAAOAXaIgDAAAAAAAAAPwCDXEAAAAAAAAAgF+gIQ4AAAAAAAAA8As0xAEAAAAAAAAAfoGGOAAAAAAAAADAL9AQBwAAAAAAAAD4BRriAAAAAAAAAAC/QEMcAAAAAAAAAOAXaIgDAAAAAAAAAPwCDXEAAAAAAAAAgF+gIQ4AAAAAAAAA8As0xAEAAAAAAAAAfoGGOAAAAAAAAADAL9AQBwAAAAAAAAD4BRriAAAAAAAAAAC/QEMcAAAAAAAAAOAXaIgDAAAAAAAAAPwCDXEAAAAAAAAAgF+gIQ4AAAAAAAAA8As0xAEAAAAAAAAAfsFnGuIzZ85UbGysQkJC1LFjR61du7bE8R999JGaNm2qkJAQXXrppVqyZEmh540xevLJJ3XBBRcoNDRUcXFx+uGHHzy5CwAAVHjkNQAAvo+8BgCgeD7REJ87d64SEhI0fvx4bdy4US1btlSfPn2Umppa5PjVq1frlltu0fDhw7Vp0yb1799f/fv31/bt251jnn/+eb388suaNWuWvv/+e4WHh6tPnz7Kysry1m4BAFChkNcAAPg+8hoAgJL5REN86tSpuuuuuzRs2DA1b95cs2bNUlhYmGbPnl3k+Jdeekl9+/bVqFGj1KxZM02cOFFt2rTRjBkzJJ369HratGkaN26crr/+el122WV69913dfDgQS1YsMCLewYAQMVBXgMA4PvIawAAShZodQE5OTnasGGDEhMTncvsdrvi4uK0Zs2aIl+zZs0aJSQkFFrWp08fZxjv27dPKSkpiouLcz5ftWpVdezYUWvWrNHNN998xjqzs7OVnZ3tfHzs2DFJ0tGjR+VwOM57/yQpLy9PDmOUeuKEehfzSwisd+TECTnCwpSXl6ejR496dFt5eXkyxujkn39q/vB7PbotnL+T6ekKtAd4dU5kHT2izx4a5tFtoWyyMo6pUqC9zPMiPT1d0qmDzPKAvIYv8VZmk9flh7cym7wuP9yV11L5ymxfyWvJc5lNXpcfHGPDFcfYcGVVXlveED98+LDy8/MVFRVVaHlUVJR2795d5GtSUlKKHJ+SkuJ8vmBZcWNcTZo0SRMmTDhjeYMGDUq3I6g49u5V9erVra4CPuKQpB+1jTmBQlIl/bRdbpkXGRkZqlq1atmL8jDyGj6JzMZpyGy4cmdeS+Ujs30lryUyG6chr3Ea8hqurMhryxviviIxMbHQp+IOh0NHjhxRzZo1ZbPZLKzMN6Wnp6t+/fr69ddfFRERYXU58AHMCbhiTpTMGKOMjAzVqVPH6lLKFfL63PDvEEVhXsAVc6JkZPb5IbPPDf8O4Yo5AVfMiZKdS15b3hCvVauWAgICdOjQoULLDx06pOjo6CJfEx0dXeL4gv8eOnRIF1xwQaExrVq1KnKdwcHBCg4OLrSsWrVq57IrfikiIoJ/hCiEOQFXzIni+fq3zE5HXpdv/DtEUZgXcMWcKF55yWxfyWuJzD5f/DuEK+YEXDEnilfavLb8pppBQUFq27atkpKSnMscDoeSkpLUuXPnIl/TuXPnQuMladmyZc7xDRs2VHR0dKEx6enp+v7774tdJwAAKB55DQCA7yOvAQA4O8u/IS5JCQkJGjJkiNq1a6cOHTpo2rRpyszM1LBhpy56P3jwYNWtW1eTJk2SJI0cOVI9evTQiy++qH79+mnOnDlav369Xn/9dUmSzWbTQw89pGeeeUYXX3yxGjZsqCeeeEJ16tRR//79rdpNAADKNfIaAADfR14DAFAyn2iIDxo0SGlpaXryySeVkpKiVq1aaenSpc6bdiQnJ8tu//8vs3fp0kUffPCBxo0bpzFjxujiiy/WggUL1KJFC+eYxx57TJmZmRoxYoSOHj2qbt26aenSpQoJCfH6/lVEwcHBGj9+/BmnwMF/MSfgijlR8ZDX5Q//DlEU5gVcMScqFvK6fOLfIVwxJ+CKOeE+NmOMsboIAAAAAAAAAAA8zfJriAMAAAAAAAAA4A00xAEAAAAAAAAAfoGGOAAAAAAAAADAL9AQBwAAAAAAAAD4BRriAIr18ccf68iRI1aXAR/y+uuv6+OPP7a6DADAachruCKvAcA3kdlwRWZbI9DqAgD4pkOHDmnQoEG66qqr9N5776latWpWlwSLpaSkaOnSpdqxY4dCQkJ0zTXXWF0SAPg98hquyGsA8E1kNlyR2dbhG+KQJBljJEnZ2dnKyMiwuBr4gqioKK1bt04bN27UkCFD9Oeff1pdEiwWHR2tMWPGqHPnznr88cf16aefWl0S4JfIbJyOvIYr8hrwDeQ1XJHZcEVmW4eGOGSMkc1m02effaaBAweqdevWuvvuu/Xuu+9aXRosYoyRw+FQmzZttHjxYq1atUoJCQn6448/rC4NFsnPz5cktWvXToMHD1bHjh01atQoffnllxZXBvgXMhunI6/hirwGfAN5DVdkNlyR2daiIQ5nUA8aNEht27bV9OnTlZycrCeeeEKrV6+2ujxYxG63a+HChfrwww9Vt25dvfPOO7rvvvv4FNtP2e2n4mLRokWaPn26fvrpJ/3444+67777tHjxYourA/wHmQ1X5DVOR14DvoG8RlHIbJyOzLaWzRScxwO/ZIxRenq6Bg4cqLi4OI0aNUqZmZm66KKLNGjQIE2bNs3qEmGRZcuW6brrrtOUKVNUt25d/f777xo7dqx69Oih2bNnq3r16laXCC9bvXq1unfvrunTp6tnz57atWuXZs+erX379un5559Xv379rC4RqNDIbBSFvIYr8hqwFnmN4pDZcEVmW4ebavo5m82msLAwHT9+XL169dL+/fvVpUsXXXvttc6gXrp0qWJiYtS8eXNri4VXff755+rVq5fuv/9+57LWrVvr6quv1j333KNXXnlFNWvWtLBCeNuqVavUpUsX3XvvvZKkZs2a6YILLtCECRP00EMPKTQ0VFdccYXFVQIVF5mNopDXcEVeA9Yir1EcMhuuyGzrcMkUP1VwYoDD4VBmZqZOnjypxYsXKy4uTldffbVeffVVSdKBAwf01ltvadeuXVaWCwv8/vvvSk9Pdz7Oy8tTp06dNG7cOH300UcaPny4jh49al2B8LqqVavq119/1YEDB5zLOnfurCFDhuinn37SzTffzKldgAeQ2SgJeQ1X5DVgDfIaZ0NmwxWZbR0a4n6mIKSPHz/ufFytWjXde++9Gj9+vOrXr6833nhDAQEBkqRXX31V27ZtU7t27SyrGda45ZZbtGPHDn300UeSpMDAUyeUREdHq0uXLtq5cyd3S/czTZs2ld1u16JFiwr9InfRRRepZ8+euuOOO9SsWTMLKwQqFjIbpUFewxV5DXgXeY3SIrPhisy2DpdM8TM2m02LFy/WSy+9JLvdrt69e2vw4MG66667tHv3bv3rX//S448/rqCgIKWkpGju3Ln65ptv1KBBA6tLh4cU3AF97969Sk5OVmhoqBo0aKDevXvrqquu0vTp02WM0cCBA5Wfn6+tW7fqiiuu0NixYxUcHGx1+fCAgjmxbt067du3T/v379ftt9+u7t2769Zbb9W4ceOUn5+vvn37KiYmRvPnz1dUVJTGjRvHde8ANyKzcTryGq7Ia8A3kNdwRWbDFZnte7ippp/5/vvv1aNHDz300EPasWOH/vjjD8XExGjmzJmqWbOmXnvtNc2ePVthYWFq2LChHnnkEV1yySVWlw0PKfih/Mknn+iRRx5RlSpVFBYWphMnTug///mPgoOD9cILL2jBggVq2LChQkJCtG3bNq1YsUKXXXaZ1eXDg+bNm6d77rlHHTp00L59+yRJI0aM0EMPPaRHH31US5Ys0R9//KF69eppz549Wr16NXMCcDMyGwXIaxSHvAasR17jdGQ2ikNm+xYa4n5kz549+uyzz+RwODRq1ChJ0ptvvqm3335b0dHRmj59uqKjo5Wenq6IiAjl5uaqUqVKFlcNT1uzZo2uuuoqTZo0Sffee68+/fRT/f3vf9fTTz+tcePG6eDBg9qzZ48++eQTRUZG6sYbb+SUnQpu8+bNuvrqq/XPf/5TQ4cOVUpKiurUqaNnn31WiYmJkqQNGzZo7969yszM1BVXXKFGjRpZXDVQsZDZcEVewxV5DViPvEZRyGy4IrN9kEGFNHnyZPPll186H//444+me/fupk6dOmbGjBnO5Q6Hw7z55pumW7duZuDAgea3334r9BwqvpdeesnceuutxhhjkpOTTUxMjLn//vudz6emplpVGizy6aefmu7duxtjjNm1a5eJjY01//jHP5zPHzhwwKrSgAqJzEZpkNdwRV4D3kVeo7TIbLgis30PN9WsgH755Rft3btXdevWdS6rV6+eevbsqaCgIC1atEgnT56UdOp6Z3feeaeGDx+uXbt2acyYMcrPz3c+h4ovIyNDoaGh+uWXX9SlSxf17dtXL7/8siTp888/1+zZs5WZmWlxlfCmAwcOKCQkRLm5uerTp4969eql1157TZK0ePFivfbaazp27JjFVQIVA5mN0iKv4Yq8BryHvMa5ILPhisz2PTTEK6DY2Fj961//UtOmTbVixQotXrxYwcHBGjdunO6++26lpaVp9OjRhe5ePHToUI0ePVpPP/208+7XqHjMX1dISk5Odt7BuH79+lq5cqW6du2qfv366bXXXpPdbpfD4dD8+fO1b98+fnGrwArmxPbt27Vz505J0tVXX60tW7YoNDRU119/vV5//XXZ7afi4ssvv9TGjRstqxeoaMhsFIW8hivyGrAWeY3ikNlwRWaXE1Z+PR3u9dJLL5kbbrjB+fjw4cPm5ptvNg0aNDD/+9//jDHGZGdnm6efftp06tTJxMfHm4yMDKvKhZcVnJ63YMEC06xZMzN79myTnZ1tjDGmf//+xm63m5UrV5qMjAxz7Ngx8/jjj5uoqCizc+dOK8uGBxXMiXnz5pmLLrrIPPTQQyYlJcVkZ2ebadOmmZiYGDNu3DhjjDF79+41iYmJpnr16mb79u1Wlg1UCGQ2ikNewxV5DViHvEZJyGy4IrPLDxriFUROTo55/fXXTa1atQpdh+ibb74xgwcPNi1atDCLFy82xvx/YHfr1s0MHTqUwPYjS5YsMaGhoebll182P/74o3P58ePHTbdu3Uy9evVMbGysufzyy03dunXNxo0bLawW3rBs2TITGhpq3njjjULXsvv111/Ns88+a6pXr26io6NNixYtTPPmzZkTgBuQ2Tgb8hquyGvA+8hrlAaZDVdkdvlgM+av7/Kj3MvMzNT8+fP12GOPqXfv3nr77bclSatWrdIrr7yirVu36rnnntPVV1+tnJwcjR8/Xhs2bNB//vMfRUVFWVs8PC4rK0s33nijmjdvrueff965PC8vT4GBgZKkefPm6cCBA6pXr57atWunmJgYq8qFhxljlJ+frwceeECBgYGaPn26HA6H7Ha7c07k5uYqNTVVK1asUMOGDdWgQQNFR0dbXTpQIZDZKA55jdOR14C1yGuUhMzG6cjs8iXQ6gLgPuHh4fr73/8uY4xGjx6toUOH6u2331bXrl0lSa+88opGjx4tu92uvn37asKECUpPT1etWrUsrhzekJubqx9++EE33HCDJCk/P18BAQEKDAyUw+FQVlaWBgwYYHGV8BabzabAwEDt3LlTF110kSTJbrfLGOP85e3QoUOqV6+ebr75ZitLBSokMhvFIa9xOvIasBZ5jZKQ2TgdmV2+cFPNCiY8PFz9+/fXc889p6VLl2ro0KGSpK5du+q+++5TmzZtNHz4cC1btkxBQUEEtR+pUqWKqlevrhUrVkiSAgICnHc737lzp9577z3udO1HjDHKyspSTEyMjhw5omPHjsnhcMhms8kYo99++02TJk3SDz/8YHWpQIVFZqMo5DVOR14D1iOvURwyG6cjs8sXGuLlXMEVb/bt26fNmzdr9+7dCgkJ0R133KEXXnhBn3/+eaHAHjZsmPr166cLL7zQwqrhaQXzIisrSydPnnQuu+6667Rlyxa9+uqrkuS82/l//vMf/fvf/1ZOTo41BcPjCuZEWlqaMjMzlZWVpZCQEN12221auHChpk6dqmPHjkk69cn2a6+9ppUrV6py5cpWlg1UKGQ2XJHXcEVeA9Yjr1EUMhuuyOzyjWuIl2PGGNlsNs2fP1+PPPKIqlSpoiNHjuhvf/ubHnjgAXXo0EEffPCBRo8erauuukpvvvmmJOnkyZMKDQ21uHp4SsG8WLRokd544w2lpaVp2LBhGjp0qE6cOKGRI0dqx44datSokdq1a6ctW7bos88+07fffquWLVtaXT486NNPP9WYMWMUGhqqOnXq6JVXXlG9evX01ltvacSIEerdu7eCgoIUFBSkzz//XF9//bVat25tddlAhUBmwxV5jeKQ14B1yGsUhcxGccjs8otviJdjNptNK1as0NChQ/XII49oy5YtevLJJ/Xf//5XW7duVUBAgG644Qa98MIL+s9//qP77rtPkgjqCqrgsy2bzaZvv/1Wt912m+rWraumTZvqvvvu08MPPyy73a7p06dr+PDhOnLkiD755BPl5eVp1apVBHUFVTAvdu3apdtvv12DBw/Wddddp+PHj6t9+/b69ddfNWzYMH3xxRe65JJLZLfbFRMTozVr1hDUgBuR2ShAXqMo5DXgG8hrnI7MRlHI7IqBb4iXUwWfUD7xxBPat2+f3nvvPSUnJ+vyyy9Xr169NGvWLEmn7opdqVIlzZ8/X61bt1bjxo0trhyedvDgQX300UdyOBx6+OGHJUnz58/XsGHDdOutt2rChAmqXbu2JCk7O1t2u12VKlWysmR42HfffafU1FRt3bpV48aNkyTt3r1b9913n3bs2KF169YpJiZGOTk5CgoKct4JG4B7kNkoCnkNV+Q1YC3yGsUhs+GKzC7/eDfKKZvNJkk6ceKEWrZsqYyMDHXp0kW9evVyXrvq008/1aeffqqgoCANHDiQoK7gHA6HkpOTVa9ePT399NM6/bOuv//975o9e7bef/99PfPMM86bOAQHBxPUFdyff/6phx9+WP3799fvv//uXN60aVO98soratGihbp06aL9+/crKChIkghqwM3IbJyOvEZRyGvAeuQ1XJHZKAqZXTHwjpQjBT98U1NTnctq166tyZMnq0mTJrrppps0Y8YM2Ww25efn65NPPtHatWuVnZ3tDHdUXAWn4bz22mv6888/tXXrVh05csT5/A033KB33nlH06dP1xtvvKG8vDwLq4W3VK1aVU8//bQuv/xyLV68WBkZGc7nCgI7OjpavXv3Vn5+vjhpCHAPMhvFIa9RFPIasAZ5jZKQ2SgKmV1BGJQLDofDGGPMZ599Zvr06WM++ugjY4wxWVlZ5oYbbjCVK1c2Bw8eNMYYc/LkSZOYmGguuOACs3v3bstqhnVmzZplbDabmThxovnzzz8LPbdo0SLmRQVW8LPidLm5uWb58uWmTZs2plWrVubYsWOFnt+7d6/55ZdfvFUiUOGR2Sgt8tp/kdeA9chrnAsy23+R2RUT1xAvRz755BPddtttevbZZxUXF6fLLrtMxhitW7dODzzwgPbs2aNLL71UQUFB2rlzp5YsWcIF+ysw89c17rZu3aqUlBRlZmaqX79+zlNyZs6cqQceeEATJkzQgw8+qKpVq1pcMTytYE6sXbtWq1atks1mU/v27dW1a1fl5eVp5cqVGj16tHJzc/XNN9+oSpUqVpcMVFhkNgqQ13BFXgO+g7zG6chsuCKzKzCLGvE4Rz/99JNp0qSJmTVrljHm1CdU+fn5Zu3atSYnJ8ecPHnSvPzyy2b8+PFm1qxZ5ueff7a4YnhSwSeUn3zyiYmKijJt2rQxoaGh5pprrjFJSUnO52fMmGEqVapkHn/8cXP06FErS4aHFbzn8+bNM1FRUaZbt26mb9++pkqVKubjjz82xhiTl5dnvv76a9OlSxcTGxtr0tPTrSwZqLDIbBQgr+GKvAZ8B3mN05HZcEVmV2w0xMuJzZs3mwYNGph9+/aZvLw8M3XqVNOtWzcTFhZm2rZtyz86P/Tll1+aWrVqmX//+9/GGGPWr19vbDab6d27t/n888+d41544QVTrVo1k5aWZlWp8JJVq1aZyMhI89prrxljjNmyZYsJCAgwNpvNOU/y8vLMF198Ya688kp+qQc8hMzG6chruCKvAd9AXsMVmQ1XZHbFxSVTyonffvtNN998s06ePKmjR4/q0ksvVcuWLXXHHXeoXbt2SkxM1OjRoyX9/ykdqLhOnjypCRMmyG6365///Kd++ukn9enTR+3bt9emTZtUuXJl/fOf/1SvXr1ks9n0559/qnr16laXDQ/Kzc3VtGnTdPToUT377LP67bff1K1bN8XFxalatWqaOnWq5syZo4EDByo/P185OTkKDQ21umygQiKzUYC8hivyGvAd5DVOR2bDFZldsdEQ90EFYZuXl6f8/HwFBwdLkr799lt98cUXqly5sm6//XbVrVtXNptNV111lW655RYNHjzY4srhLfn5+Vq5cqUuuOACRUVFqVevXrrsssv073//W2vXrlX37t3Vrl07jR8/Xr169eIXOD+xd+9eHT58WK1atVLv3r3VvHlzvf7669qyZYs6duyonJwcvf322/ysANyIzEZJyGsUhbwGvI+8xtmQ2SgKmV1xBVpdAAor+KG6dOlSvfXWW9q/f7+6d++u+++/X927d1f37t2dY0+ePKnJkydr8+bNmjFjhoVVwxNcP6s6PWwDAgLUsWNHhYSEaPHixcrLy9Pjjz8uSTp27Jg6d+4sY4yaNGlyxmtR/uXl5SkgIEA2m005OTnOm7w0btxYjRs31rZt23Ty5EnFx8dLkiIiIjRgwABddtllat++vZWlAxUKmQ2JvEbxyGvAN5DXKEBmozhktv+xW10ACrPZbPr00081cOBA1apVS3feeafeffddJSQkaPny5c5xn332me655x698cYbWrJkiS688ELrioZHHD16VDabTbm5ubLZbPrmm2/09NNPa+rUqdq7d69CQkIkSWlpacrIyNCJEyckSStWrFCXLl20dOlSxcTEWLkLcLONGzcqLy9PgYGBstls+uKLLzRixAjddddd+uKLL5SdnS3p1C9smzZtUkpKiiTpzTff1MGDB3X//ferWbNmVu4CUKGQ2ZDIa5yJvAZ8C3mNAmQ2XJHZfsybFyzH2e3cudM0bdrUvPLKK8YYY/Lz801kZKSpWrWqueKKK8zKlSuNMcYsW7bMPPXUU2bPnj1WlgsPmTNnjqlcubLZu3evMcaYjz/+2ISHh5uOHTuaZs2ambp165q1a9caY4z54YcfTHR0tLnkkktM+/btTbVq1cymTZssrB6esGDBAtOsWTMzY8YMY4wxK1euNAEBAebOO+80jRs3Nh06dDBPPfWUOX78uDHGmDvvvNPYbDbTsmVLExERwZwAPIDMBnkNV+Q14HvIaxhDZuNMZLZ/4xriFjFFXG/K4XBo27ZtWrRokUaNGqXDhw/rb3/7m6677jrde++9ateunS6//HIlJCSoZ8+ezk+xUPGsXbtW48aN088//6zPPvtMc+fOVUxMjIYNG6bt27frn//8pz755BN9/fXX6ty5s3bu3KkPPvhAAQEBuuWWW9S0aVOrdwFuduTIEd177706cOCAbrvtNiUnJ6tu3bqKj49XXl6eRo8erdWrV6t3794aM2aMgoKCNG/ePB09elRXXHGFGjVqZPUuAOUWmY3ikNdwRV4D1iGvURIyG67IbD9naTveT+Xn5xtjjElLSzPr1683u3fvdn7ilJGRYfbu3WscDoe5/fbbzR133OF8rlevXsZms5lBgwaZEydOWFY/vGPjxo2mb9++pm7duqZr165mzZo1zuf2799vbrnlFhMcHGxWr15tjDEmLy/PqlLhYQXv7Z9//mluvvlmExcXZ1q2bGkWLVrkHHPixAnzyCOPmPbt25unn37a+XMDQNmQ2Tgb8hoFyGvAOuQ1SoPMRgEyG1xD3MscDofsdru2bdumuLg4DRw4UP369dNzzz2nzMxMVa5cWRdffLEcDocOHDigZs2aKTw8XNKpi/n/97//1aRJkxQaGmrxnsBTzF8nbbRu3VoTJ05Uly5dtGbNGudyh8OhmJgYPffcc7rpppvUtWtXbdiwQQEBAVaWDQ8KCAhQXl6eqlWrpldeeUV16tTR7t279c033zjHhIaG6tlnn9Xll1+u9957Ty+99JKMMWfcOAZA6ZHZKAl5DVfkNWAN8hpnQ2bDFZkNGuJelJ+fL7vdri1btqhz586Ki4vTggULdMMNN+jDDz9UZmamc+zRo0d17Ngxbd26VQsWLNDjjz+uefPmqUePHmrYsKGFewFPO/00v3bt2mnUqFHq2bOnBgwYoB9//FF2u13GGNWvX18TJ07U8OHDnb/QoeIpCNuCUzerV6+ul156STfddJOWL1+uWbNmKT8/X5IUHBysCRMmaODAgbr11ltls9m4+zlwnshsnA15jdOR14A1yGuUBpmN05HZkCSuIe5l27ZtU9euXfXggw/qmWeekSRlZmbqb3/7m0aPHi2Hw6FOnTqpYcOGWrVqlW6++WZVrlxZOTk5+vjjj9W6dWuL9wCeYv665t2mTZt08OBBVapUSb1795Ykbd68WaNHj9aePXv05Zdf6qKLLnKO5zp3FVfBe7xy5Up9++23uuCCC9ShQwddcskl+uOPPxQfH6/9+/dr8ODBuuuuu/gGA+BmZDaKQl7DFXkNWIu8RnHIbLgis+HklQuzwBhjTE5OjunRo4cJDg42GRkZzuXjx483lSpVMpdddpmpX7++CQkJMd99950xxpjffvvN7Nu3z6SmplpVNrzok08+MWFhYaZZs2bGZrOZESNGmGPHjhljjNm0aZPp06ePueiii8zu3bstrhTeMn/+fBMWFmbatm1rLr74YtO2bVvz1VdfGWOMOXz4sLn55ptN9+7dzdSpU53XTgRQdmQ2SkJewxV5DViDvMbZkNlwRWbDmFPXvoEXbdu2zcTGxprevXsbY4yZPHmyqV69ulmwYIH5448/zKZNm0z79u1N27ZtCwU6Kq6CH7BHjhwxXbp0MW+//bZJTk42n3/+ualcubIZNGiQOXLkiDHGmM2bN5tOnTqZyy67zOTk5BiHw2Fl6fCQgjmRmppqHnvsMTN79mxjjDHffPONufXWW03Dhg1NUlKSMeZUYF999dWmT58+5s8//7SqZKBCIrNxOvIarshrwDeQ13BFZsMVmQ1XXDLFArt27VJcXJxsNpuys7P14YcfKi4uzvn8vffeq40bN2r16tWcnlEBFdz0peC/kvTFF1/o008/VUZGhqZOnapatWpJkr7//nvFxcWpX79+evXVV1W9enVt27ZNVatWVUxMjJW7ATcqmAunn5q3adMmDR8+XMHBwZo1a5ZatmwpSdq4caNefPFFrVmzRm+++aYuv/xyHTlyRCdPnlTdunWt3A2gQiKz/Rd5DVfkNeC7yGv/RmbDFZmNs+GmmhZo1qyZkpKSVKNGDef1iiQVusNxgwYNlJuba2WZ8ICCH8o7d+7UU089pZMnT0qSjh07pldffVVLlixRRkaGc2zHjh315Zdf6osvvtDtt9+uo0eP6tJLLyWoK5CCObFx40Y98MADzvc/JSVFNWvW1LZt25STk+Mc36ZNGz366KPq1q2b+vfvr2+//VY1atQgqAEPIbP9E3kNV+Q14NvIa/9FZsMVmY3SoCFukaZNm2ru3Lk6cuSIbrzxRqWlpclms2n8+PGaO3euxo8fr5CQEKvLhBsV/FDesmWLWrRoofDwcIWGhkqSbrrpJi1cuFAZGRl66aWXlJOT47zTdceOHbVo0SJt3bq10F3SUf6dPic6deqksLAwValSRZJ01VVX6fHHH1ebNm00fPhwbd261fm61q1b64EHHtCgQYNUp04dq8oH/AaZ7V/Ia7gir4Hygbz2P2Q2XJHZKDXrrtZSMRVclygzM7NU157auXOnqVevnrnuuuvMI488YkJDQ8369es9XSa8rGBebNq0yYSFhZkxY8YUej43N9cYY8x///tfU6lSJfPoo4+anJwcY4xxzqOTJ096sWJ4WsGc2Lx5swkNDTVjx44tctznn39u+vXrZzp06GC2bt1a6LmsrCyP1wlUZGQ2XJHXcEVeA9Yjr1EUMhuuyGycCxriblTwj2/9+vWmXbt2Zv/+/aV63a5du0zNmjWNzWYzGzdu9GSJsEBB2G7bts2EhoaaCRMmFHr+rbfeMkuWLHHOn48++shUqlTJjB492mRnZ3u9XnjPli1bTERExBm/vD3xxBPmhRdecD7+/PPPzdVXX226dOliNm3a5OUqgYqJzIYr8hrFIa8B65DXKAqZjeKQ2SgtGuJucvonUeHh4SY+Pv6cXv/DDz+Yn3/+2ROlwQekpaWZhg0bmg4dOpi8vDzn8kmTJpnAwEDz3XffFRo/b948Y7PZzJNPPuntUuElJ0+eNJdccomJiooq9E2X5557zlSpUsV89tlnhcZ/8cUXpmvXrubKK6802dnZ3P0cKAMyG8Uhr+GKvAasQ16jJGQ2XJHZOBc0xN1oy5YtpkqVKuaxxx4zxpz61PKPP/4wv//+u0lPT3cug//Jz883d955p+nSpYuZPHmyMcaYqVOnmpo1a5ovvvjCGHPm3Jg3b57ZuXOn12uF9yxbtsxUq1bNDBs2zBhz6pe3GjVqOOeEMYXnxbfffmuSk5O9XidQEZHZKAp5jaKQ14B1yGsUh8xGUchslJbNmL9uu4wySU9PV2xsrBo1aqT169fL4XBo8ODB+vnnn/Xjjz+qXbt2SkhIUFxcnIwxstlsVpcMLym4qUN+fr4efPBBbdy4UVWrVtX333+vhQsX6m9/+1uh8R9//LG6du2qCy64wKKK4U1fffWVrr32WsXGxiotLU3vv/++evXqVejnxHvvvadLLrlErVu3trhaoGIgs1EU8holIa8B7yOvURwyGyUhs1EadqsLqCgiIiI0ZswY7dy5U//617/Up08f/f7777rvvvs0fvx4Va1aVXfccYdWrVpFUPsZu90uh8OhgIAAvfzyy+rQoYM2bNigAQMGqFOnTpJOBbokPfHEE7r77ruVlZVlZcnwoiuuuEJLlizRkSNH1KJFC11xxRWS5Pw58cQTT2jw4MGKiIiwskygQiGzURTyGiUhrwHvI69RHDIbJSGzUSrWfTm9fDv9FIvT/3/q1KnGZrOZHj16mLS0NOfynTt3mp49e5pHH33UeS00+JeC65rl5+ebBx54wHTo0MFMmjTJZGRkGGOMGTdunAkJCTHr1q2zskxY5Ouvvzbh4eFm6NChJjMz0xhjzJNPPmnCwsLM+vXrLa4OKN/IbJwL8holIa8BzyGvca7IbJSEzEZJAq1uyJdHBafnHD9+XA6HQ5mZmc5Tbx5++GHVq1dPOTk5qlGjhvOUjGbNmikoKEg///yz7Ha+mF8R5efnKyAgQOnp6UV+0hgQEOAc869//UsjR47UvHnzFBYWpgMHDujll1/WypUr1bZtWwuqhycU/Kw4nSnmdM6ePXtq0aJFuu666xQWFqZq1app6tSpzAmgjMhsuCKv4Yq8BqxHXqMoZDZckdlwF64hfo4K/vHt2LFDo0eP1v79+xUcHKwbb7xRjz/+uHOMw+FQYGBgoce33nqrWrZsqbFjx1q5C/Cg7du3q1u3bpo4caIeeOCBIscUBHZ+fr4efvhhvf/++8rOztY333zDD+UKpOBnxYEDB7RixQr9/PPP+sc//qHIyMgSX7d8+XLnKV3r169XmzZtvFEuUCGR2SgOeY0C5DVgPfIaJSGzUYDMhjvxDfFzYIyR3W7Xzp079be//U3Dhg3T9ddfr99++02vvfaaLrnkEl177bWy2+2FPrHKysrSc889p5UrV+qZZ56xcA/gaR988IHS09P18MMPK2mtatQAAA8aSURBVD8/Xw899NAZY1w/xa5atapuu+02NW3a1PsFwyMKgnr79u0aMmSIWrZsqYYNGxYK6oI54Kpnz55as2aNatSooYsvvtibZQMVCpmNkpDXkMhrwBeQ1zgbMhsSmQ0PsOhSLeXWH3/8Ya688krz8MMPO5cdOnTIdOvWzTz99NNnjP/yyy/NkCFDTO3atc3GjRu9WSossG7dOtOvXz8zYsQIExAQYCZPnlzs2ILrnaFiKbje4Y4dO0z16tXNE088YQ4fPux8/v333zc7d+40xjAHAE8js1Ec8hrkNeA7yGuUhMwGmQ1P4EJb5+jw4cOqXLmyevXq5VwWGRmpDh06aNeuXZKkvLy8Qq+JjY3Vt99+q9atW3u1VniWKeJqQ82aNdORI0dUrVo1zZkzR2PHjtULL7xQ5OuL+uQS5Z/NZtORI0d0991368Ybb9TTTz+tmjVrSpKee+453X777erZs6e2bt3q/CYDAM8gsyGR1ygaeQ34DvIaBchsFIXMhifQED+Lgn9IWVlZcjgcqlOnjh588EFdddVVkk6dtiGd+geanZ0tSc7rmknSlVdeqcTERE7VqWDy8/Nls9mUnp5eaHl4eLieffZZffHFF7rooov00ksv6fHHH9eUKVMsqhRW+OWXX/THH3/o9ttvdy6bM2eOpkyZoldeeUXdu3fX1Vdf7Qzson7xA3DuyGy4Iq9REvIasAZ5jaKQ2SgJmQ13oyF+FgEBAdqxY4euvfZaLV++XJUrV3ZejP/0u9uGhIQU+hTqkUce0dNPPy1JCg4O9n7h8KiCeVG7dm3dfffdmjFjhvO5Sy+9VFFRUdqxY4fuv/9+TZ06VaNHj9bUqVMtrBjetG3bNqWkpOiSSy5xLqtdu7aWLVume+65R08//bQ6duyoLl266MCBA0XeERvAuSOz4Yq8RknIa8Aa5DWKQmajJGQ23I2GeAmMMXI4HLr77ruVlJSkRx99VCtWrHB+0nT6TT0qV67s/CR77Nixevnll9W7d29L6oZ3zJ8/X7m5udqwYYPmzZunyy67TG+99ZZyc3M1ZMgQjR8/Xn/++adGjhypGTNm6NFHH9X06dOtLhtecMEFF+jo0aPavHmzc9mVV16pVq1aSTp12l/fvn3VvHlzVapUyZoigQqGzEZxyGsUh7wGvI+8RknIbBSHzIa70RAvgc1mk91u16hRo3TllVcqKytLgwYN0sqVK51jCoL7xIkTqlKlil544QVNmTJF33//vTp16mRV6fCCxx9/XI888oi2b9+uUaNG6YYbblBSUpIuu+wybdmyRSdPnlRSUpIk6d5779Xrr7+uuLg4i6uGO51+Gtbp315p3LixWrVqpYkTJ2rPnj2S/v+6hwW/1O/atUsNGjRQWFiYFysGKi4yG8Uhr0FeA76DvEZJyGyQ2fAab9/FszzavHmziYuLM998840ZMmSIiYyMNN9++22hMU888YSx2WymatWqZt26dRZVCm9zOBxm6NChpnbt2iYpKclkZWWZTz75xPTr189Uq1bNfPbZZ1aXCA/Jz883xhjzxx9/FPn8888/b2rUqGFuvPFG5x2vC8Y/9thjpkaNGmbHjh1eqRXwJ2Q2ikJe+y/yGvBN5DWKQ2b7LzIb3mQzhivNF8jPz1dAQIBycnIUFBRU6LmRI0dq7dq1SkpK0m233abvvvtO//3vf9WtWzfZbDbNnTtXY8aM0aeffqoWLVpYtAewyrBhwzRv3jzNmTNHV199tY4eParMzEzVrVvX6tLgQXv27FG7du3Uu3dv/eMf/9All1yimJgY5/OJiYl6++23ZbfbNXjwYKWkpOjYsWNas2aNlixZotatW1tYPVC+kdk4H+S1fyKvAeuQ1zhfZLZ/IrPhLVwy5TQBAQHaunWrrrjiCk2ePLnQaVuPP/64IiIitG3bNs2fP18tW7bUoEGDtGrVKknSFVdcoe+++46grmAKTr3JyMjQyZMnJanIuxW/9dZbuummmzRw4ED973//U7Vq1QhqP/D777+rbt26OnHihObMmaOePXvq3Xff1aZNmyRJkyZN0syZM9WnTx8tWLBAe/bsUdOmTfXtt98S1EAZkdk4HXmNkpDXgHXIa7gis1ESMhteY+n3032Iw+Ew+fn5pmvXrsZms5mePXuaiIgI89hjj5lPPvnEGGPMoEGDzJAhQ5yvue6660ylSpXM6tWrLaoa3nDw4EHTtWtX88Ybb5gTJ04YY07Nl6Lceeedpnr16ubTTz/1ZomwyG+//WbuuOMO89lnn5mcnBwzZcoU06NHD3PFFVeYhIQE8+uvv5rc3FxjjDHp6enGmP8/DQzA+SOzURTyGsUhrwFrkNcoDpmN4pDZ8BYumeIiLS1N3bt3V82aNTVkyBCtWLFCv/zyi6pWraqePXtq4sSJ+uyzz9StWzdJ0qBBgzRx4kQ1btzY4srhSX379lVKSooeeeQR3XjjjQoNDZUxRjab7Yyxt956q7799lvt2bNH4eHhFlQLbxo7dqwWLlyo77//XmFhYUpPT1e3bt20fft2devWTbVr19aDDz6o1q1bKyIioth5A+DckdlwRV6jOOQ1YB3yGkUhs1EcMhve4NeXTCk4Ved0tWvX1vLly/XTTz/pf//7n+Lj47VgwQJdcMEFWrp0qdLT0xUYGOgcP3fuXIK6Aiu4q/HSpUvVuHFjPffcc/r444918uRJ2Wy2QnMoNzdX27Zt07///W+tX7+eoK5AivrcMDc3V5L02GOPKTIyUosWLZIkPfTQQzp+/LjWrFmj4cOH6+jRoxo0aJBzPEENnB8yGyUhryGR14AvIK9xNmQ2JDIb1vPbb4g7HA7Z7XYlJyfru+++U0pKikaMGKGQkBBJ0qFDh9S6dWtdeOGFeu+999SgQQOlpKTo0KFDatmypcXVw5sKbgQjSQMHDtTOnTs1evRoDRgwQGFhYZKknJwc3Xvvvdq2bZuWLVumqlWrWlky3KjgZ8Uff/yhQ4cOKT8/X5deeqmkU3PD4XAoPj5eWVlZMsYoKSlJ8+fPV4cOHZzrSE1NVWRkpFW7AJR7ZDZKg7z2b+Q1YD3yGqVFZvs3Mhu+wC8b4gX/+LZu3ar+/furevXq+vnnnxUdHa2NGzcqNDRU0qnAbtOmjWJjY/Xmm2+qadOmksTpGBVUwbwo6rFrYO/YsUOJiYkaMGCAQkND9cADD2j27Nlavny52rdvb0n9cL+CObB9+3bdeeedSktLkzFGvXv31uuvv+4ct3//fl1yySUKCQnRihUr1KxZM0n8rADcgcyGK/IarshrwHrkNYpCZsMVmQ1f4XeXTCn4x7dlyxZ16tRJt956q5YsWaJ169bp+PHj+uyzz5xjo6KitGHDBv3yyy+67777tHXrVkmcjlFRFXyb4eWXX3Y+LjhdKyAgwHlq13//+19dcsklmjx5sv773//qnnvu0ZtvvqmVK1cS1BWI68+K7t2766233tI111yjd955R6+++qokKS8vT3Xr1tXQoUPVu3dvXXjhhc7Tv/hZAZQNmY2ikNc4HXkNWI+8RnHIbJyOzIZP8cadO33NDz/8YEJCQsy4ceMKLe/atasZO3asGTJkiPnggw/Mjz/+aIwxJiUlxYSEhJirr77aZGdnW1EyvCAvL8+MHj3aNG7c2Dz//PPO5affsbjgbsbGGHPLLbcYm81mqlSpYjZu3OjVWuEdRf2s+Pnnn01QUJB55JFHCo39+OOPTXh4uFmxYoW3ywQqNDIbrshruCKvAeuR1ygKmQ1XZDZ8ReDZW+YVi8Ph0OzZs1WlShXVrFnTuXzy5Mlas2aNYmJi9PPPP+vDDz/Ufffdp/HjxysqKkrJyck6evSogoKCLKwenhQQEKAHHnhAWVlZmjdvnhwOh0aPHu38FNtutyswMNB5atcHH3ygevXqafDgwWrRooXV5cPNivtZMWfOHOXm5uqHH37QtGnTVKNGDQ0cOFADBgzQ+++/r3/+859atGiR7HY7n14DZURmoyjkNU5HXgPWI69RHDIbpyOz4Uv88hriBw8e1PPPP6/vvvtOQ4cOVXp6uqZMmaJ3331Xffr0kc1m0wMPPKB33nlHW7duVWxsrNUlw4tSUlL07LPPat26dfr73/+u0aNHS/r/03tycnL0z3/+UxdffLFuu+02i6uFJ53+s2LIkCHKyMjQ5MmTdf/996tVq1Z6//339euvvyolJUWNGzdWVFSUJk2apAYNGlhdOlBhkNkoDnmNAuQ1YD3yGiUhs1GAzIbPsPor6lb5/fffTXx8vGnSpIkJCAgwSUlJxhhjTpw4YYwxZvHixaZRo0Zm9+7dVpb5f+3dsUojURSA4WNI8AnUPIOFihb2+jRa2FlobARFLH0EOyGNtZXgCFYGBUs7i4idhSCK2WZvzMImu83mhr3fV6Y6xeT+cIaZIZN0fayurvaOjo76v7+9vfU2Nzd7jUaj9/DwkHFCxmXwrKjX6/2zotf7frzv5OSkt7Gx4ZqAf0SzGUavSfQa8tNrRtFsEs1mEhT3ypSk2WzG3t5e1Gq1mJ6ejk6nE2tra/2vX19cXMTMzEzMzs5mnpQcms1mtFqtODw8jPPz85iamort7e1otVpxenoaNzc3MT8/n3tMxmDwrLi8vOyfFRHR/yDM1tZWfHx8RKPRyDkq/Lc0m2H0mkSvIT+9ZhTNJtFsJkGRr0wZ9LtHdw4ODuL4+Diur69jYWEh94hklK6P29vbeH19jcfHx6iqKpaXl3OPxpgNe8zv8/Mz6vVi7y3CWGk2w+g1iV5DfnrNKJpNotnkVPxCPOL7T3h3dxfv7+9xf38fVVXFyspK7tGYAN1uN3Z3d6Oqqmi327G4uJh7JDJJZ0Wn04n19fXY39/PPRIUR7MZRq9J9Bry02tG0WwSzSYXC/Gf0oF8dXUV7XY7lpaWco/EBHl5eYmvr6+Ym5vLPQqZdbvd2NnZiaenpzg7O/vl69jAeGg2w+g1iV5DfnrNKJpNotnkYCE+wIEM/I3n5+eICGcFZKTZwJ/oNeSn18Df0GzGzUIcAAAAAIAi1HIPAAAAAAAA42AhDgAAAABAESzEAQAAAAAogoU4AAAAAABFsBAHAAAAAKAIFuIAAAAAABTBQhwAAAAAgCJYiAMAAAAAUAQLcQAAAAAAimAhDgAAAABAESzEAQAAAAAowg8TTUb7qMjfCQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1800x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualization complete\n",
      "\n",
      "============================================================\n",
      "PHASE 5: EVALUATION SUMMARY\n",
      "============================================================\n",
      "\n",
      "Evaluation Results:\n",
      "\n",
      "1. In-Distribution (TyDi):\n",
      "   Models tested: 3\n",
      "   Languages: 2\n",
      "   Total samples: 100\n",
      "\n",
      "2. Out-of-Distribution (mMARCO):\n",
      "   Models tested: 3\n",
      "   Languages: 2\n",
      "   Total samples: 4\n",
      "\n",
      "3. Zero-Shot (Unseen):\n",
      "   Models tested: 3\n",
      "   Languages: 1\n",
      "   Total samples: 2\n",
      "\n",
      "============================================================\n",
      "PHASE 5 COMPLETE - ALL EVALUATIONS FINISHED\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# PHASE 5: COMPLETE MULTILINGUAL EVALUATION\n",
    "# Testing: In-Distribution + Out-of-Distribution + Zero-Shot\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PHASE 5: COMPLETE MULTILINGUAL EVALUATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Configuration\n",
    "model_configs = {\n",
    "    \"BM25 Baseline\": f\"{MODEL_DIR}/dpr_bm25_baseline_tydi_final\",\n",
    "    \"LLM Enhanced\": f\"{MODEL_DIR}/dpr_llm_enhanced_tydi_final\",\n",
    "    \"RAG Enhanced\": f\"{MODEL_DIR}/dpr_rag_enhanced_tydi_final\"\n",
    "}\n",
    "\n",
    "# ============================================================\n",
    "# 1. IN-DISTRIBUTION: TyDi Test\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"IN-DISTRIBUTION EVALUATION: Mr. TyDi\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "tydi_results = {}\n",
    "\n",
    "for model_name, model_path in model_configs.items():\n",
    "    print(f\"\\nModel: {model_name}\")\n",
    "    \n",
    "    try:\n",
    "        evaluator = RetrievalEvaluator(model_path)\n",
    "    except Exception as e:\n",
    "        print(f\"  Error loading model: {e}\")\n",
    "        continue\n",
    "    \n",
    "    lang_results = {}\n",
    "    \n",
    "    for lang in ['swahili', 'bengali', 'telugu']:\n",
    "        if lang not in tydi_eval_data:\n",
    "            continue\n",
    "        \n",
    "        print(f\"  Language: {lang}...\", end=\" \")\n",
    "        eval_df = tydi_eval_data[lang]\n",
    "        corpus = eval_df['passage'].unique().tolist()\n",
    "        \n",
    "        try:\n",
    "            metrics = evaluator.evaluate_retrieval(eval_df, corpus, top_k=10)\n",
    "            lang_results[lang] = metrics\n",
    "            print(f\"MRR={metrics['MRR@10']:.4f}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "            lang_results[lang] = {'MRR@10': 0.0, 'Recall@10': 0.0, 'nDCG@10': 0.0}\n",
    "    \n",
    "    if lang_results:\n",
    "        avg_mrr = np.mean([m['MRR@10'] for m in lang_results.values()])\n",
    "        avg_recall = np.mean([m['Recall@10'] for m in lang_results.values()])\n",
    "        avg_ndcg = np.mean([m['nDCG@10'] for m in lang_results.values()])\n",
    "        \n",
    "        tydi_results[model_name] = {\n",
    "            'by_language': lang_results,\n",
    "            'avg_MRR@10': avg_mrr,\n",
    "            'avg_Recall@10': avg_recall,\n",
    "            'avg_nDCG@10': avg_ndcg\n",
    "        }\n",
    "        \n",
    "        print(f\"  Average: MRR={avg_mrr:.4f}, Recall={avg_recall:.4f}\")\n",
    "    \n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "print(f\"\\nIn-Distribution: {len(tydi_results)} models evaluated\")\n",
    "\n",
    "# ============================================================\n",
    "# 2. OUT-OF-DISTRIBUTION: mMARCO Test\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"OUT-OF-DISTRIBUTION EVALUATION: mMARCO\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "mmarco_results = {}\n",
    "\n",
    "if len(ood_eval_data) > 0:\n",
    "    for model_name, model_path in model_configs.items():\n",
    "        print(f\"\\nModel: {model_name}\")\n",
    "        \n",
    "        try:\n",
    "            evaluator = RetrievalEvaluator(model_path)\n",
    "        except Exception as e:\n",
    "            print(f\"  Error loading model: {e}\")\n",
    "            continue\n",
    "        \n",
    "        lang_results = {}\n",
    "        \n",
    "        for lang in ood_eval_data.keys():\n",
    "            print(f\"  Language: {lang}...\", end=\" \")\n",
    "            eval_df = ood_eval_data[lang]\n",
    "            corpus = eval_df['passage'].unique().tolist()\n",
    "            \n",
    "            try:\n",
    "                metrics = evaluator.evaluate_retrieval(eval_df, corpus, top_k=10)\n",
    "                lang_results[lang] = metrics\n",
    "                print(f\"MRR={metrics['MRR@10']:.4f}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error: {e}\")\n",
    "                lang_results[lang] = {'MRR@10': 0.0, 'Recall@10': 0.0, 'nDCG@10': 0.0}\n",
    "        \n",
    "        if lang_results:\n",
    "            avg_mrr = np.mean([m['MRR@10'] for m in lang_results.values()])\n",
    "            avg_recall = np.mean([m['Recall@10'] for m in lang_results.values()])\n",
    "            avg_ndcg = np.mean([m['nDCG@10'] for m in lang_results.values()])\n",
    "            \n",
    "            mmarco_results[model_name] = {\n",
    "                'by_language': lang_results,\n",
    "                'avg_MRR@10': avg_mrr,\n",
    "                'avg_Recall@10': avg_recall,\n",
    "                'avg_nDCG@10': avg_ndcg\n",
    "            }\n",
    "            \n",
    "            print(f\"  Average: MRR={avg_mrr:.4f}, Recall={avg_recall:.4f}\")\n",
    "        \n",
    "        gc.collect()\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    print(f\"\\nOut-of-Distribution: {len(mmarco_results)} models evaluated\")\n",
    "else:\n",
    "    print(\"Warning: mMARCO data not loaded\")\n",
    "    mmarco_results = {}\n",
    "\n",
    "# ============================================================\n",
    "# 3. ZERO-SHOT: Unseen Languages\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ZERO-SHOT EVALUATION: Unseen Languages\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "zeroshot_results = {}\n",
    "\n",
    "if len(zeroshot_eval_data) > 0:\n",
    "    for model_name, model_path in model_configs.items():\n",
    "        print(f\"\\nModel: {model_name}\")\n",
    "        \n",
    "        try:\n",
    "            evaluator = RetrievalEvaluator(model_path)\n",
    "        except Exception as e:\n",
    "            print(f\"  Error loading model: {e}\")\n",
    "            continue\n",
    "        \n",
    "        lang_results = {}\n",
    "        \n",
    "        for lang in zeroshot_eval_data.keys():\n",
    "            print(f\"  Language: {lang} (unseen)...\", end=\" \")\n",
    "            eval_df = zeroshot_eval_data[lang]\n",
    "            corpus = eval_df['passage'].unique().tolist()\n",
    "            \n",
    "            try:\n",
    "                metrics = evaluator.evaluate_retrieval(eval_df, corpus, top_k=10)\n",
    "                lang_results[lang] = metrics\n",
    "                print(f\"MRR={metrics['MRR@10']:.4f}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error: {e}\")\n",
    "                lang_results[lang] = {'MRR@10': 0.0, 'Recall@10': 0.0, 'nDCG@10': 0.0}\n",
    "        \n",
    "        if lang_results:\n",
    "            avg_mrr = np.mean([m['MRR@10'] for m in lang_results.values()])\n",
    "            avg_recall = np.mean([m['Recall@10'] for m in lang_results.values()])\n",
    "            avg_ndcg = np.mean([m['nDCG@10'] for m in lang_results.values()])\n",
    "            \n",
    "            zeroshot_results[model_name] = {\n",
    "                'by_language': lang_results,\n",
    "                'avg_MRR@10': avg_mrr,\n",
    "                'avg_Recall@10': avg_recall,\n",
    "                'avg_nDCG@10': avg_ndcg\n",
    "            }\n",
    "            \n",
    "            print(f\"  Average: MRR={avg_mrr:.4f}, Recall={avg_recall:.4f}\")\n",
    "        \n",
    "        gc.collect()\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    print(f\"\\nZero-Shot: {len(zeroshot_results)} models evaluated\")\n",
    "else:\n",
    "    print(\"Warning: Zero-shot data not loaded\")\n",
    "    zeroshot_results = {}\n",
    "\n",
    "# ============================================================\n",
    "# COMPREHENSIVE COMPARISON TABLE\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"COMPLETE EVALUATION RESULTS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "eval_summary = []\n",
    "\n",
    "for model_name in model_configs.keys():\n",
    "    row = {'Model': model_name}\n",
    "    \n",
    "    if model_name in tydi_results:\n",
    "        row['TyDi MRR'] = f\"{tydi_results[model_name]['avg_MRR@10']:.4f}\"\n",
    "        row['TyDi Recall'] = f\"{tydi_results[model_name]['avg_Recall@10']:.4f}\"\n",
    "    else:\n",
    "        row['TyDi MRR'] = 'N/A'\n",
    "        row['TyDi Recall'] = 'N/A'\n",
    "    \n",
    "    if model_name in mmarco_results:\n",
    "        row['OOD MRR'] = f\"{mmarco_results[model_name]['avg_MRR@10']:.4f}\"\n",
    "        row['OOD Recall'] = f\"{mmarco_results[model_name]['avg_Recall@10']:.4f}\"\n",
    "    else:\n",
    "        row['OOD MRR'] = 'N/A'\n",
    "        row['OOD Recall'] = 'N/A'\n",
    "    \n",
    "    if model_name in zeroshot_results:\n",
    "        row['Zero-Shot MRR'] = f\"{zeroshot_results[model_name]['avg_MRR@10']:.4f}\"\n",
    "        row['Zero-Shot Recall'] = f\"{zeroshot_results[model_name]['avg_Recall@10']:.4f}\"\n",
    "    else:\n",
    "        row['Zero-Shot MRR'] = 'N/A'\n",
    "        row['Zero-Shot Recall'] = 'N/A'\n",
    "    \n",
    "    eval_summary.append(row)\n",
    "\n",
    "summary_df = pd.DataFrame(eval_summary)\n",
    "print(\"\\n\" + summary_df.to_string(index=False))\n",
    "\n",
    "# ============================================================\n",
    "# VISUALIZATION\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"GENERATING VISUALIZATIONS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "fig.suptitle('Phase 5: Multilingual Evaluation Comparison', fontsize=14, fontweight='bold')\n",
    "\n",
    "models = list(model_configs.keys())\n",
    "colors = ['#FF6B6B', '#4ECDC4', '#45B7D1']\n",
    "\n",
    "settings = [\n",
    "    ('In-Distribution (TyDi)', tydi_results, 0),\n",
    "    ('Out-of-Distribution (mMARCO)', mmarco_results, 1),\n",
    "    ('Zero-Shot (Unseen)', zeroshot_results, 2)\n",
    "]\n",
    "\n",
    "for setting_name, results_dict, ax_idx in settings:\n",
    "    ax = axes[ax_idx]\n",
    "    \n",
    "    if len(results_dict) > 0:\n",
    "        mrr_values = [results_dict[m]['avg_MRR@10'] for m in models if m in results_dict]\n",
    "        \n",
    "        bars = ax.bar(\n",
    "            range(len(mrr_values)), \n",
    "            mrr_values, \n",
    "            color=colors[:len(mrr_values)],\n",
    "            alpha=0.8, \n",
    "            edgecolor='black', \n",
    "            linewidth=2\n",
    "        )\n",
    "        \n",
    "        for i, v in enumerate(mrr_values):\n",
    "            ax.text(i, v + 0.005, f'{v:.4f}', ha='center', fontweight='bold')\n",
    "        \n",
    "        ax.set_ylabel('MRR@10', fontsize=11, fontweight='bold')\n",
    "        ax.set_title(setting_name, fontsize=12, fontweight='bold')\n",
    "        ax.set_ylim([0, 0.15])\n",
    "        ax.set_xticks(range(len(mrr_values)))\n",
    "        ax.set_xticklabels(models, rotation=45, ha='right')\n",
    "        ax.grid(axis='y', alpha=0.3)\n",
    "    else:\n",
    "        ax.text(0.5, 0.5, 'No Data', ha='center', va='center', \n",
    "               transform=ax.transAxes, fontsize=14)\n",
    "        ax.set_title(setting_name, fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Visualization complete\")\n",
    "\n",
    "# ============================================================\n",
    "# FINAL SUMMARY\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PHASE 5: EVALUATION SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nEvaluation Results:\")\n",
    "print(f\"\\n1. In-Distribution (TyDi):\")\n",
    "print(f\"   Models tested: {len(tydi_results)}\")\n",
    "print(f\"   Languages: {len(tydi_eval_data)}\")\n",
    "print(f\"   Total samples: {sum(len(df) for df in tydi_eval_data.values())}\")\n",
    "\n",
    "print(f\"\\n2. Out-of-Distribution (mMARCO):\")\n",
    "print(f\"   Models tested: {len(mmarco_results)}\")\n",
    "print(f\"   Languages: {len(ood_eval_data)}\")\n",
    "print(f\"   Total samples: {sum(len(df) for df in ood_eval_data.values())}\")\n",
    "\n",
    "print(f\"\\n3. Zero-Shot (Unseen):\")\n",
    "print(f\"   Models tested: {len(zeroshot_results)}\")\n",
    "print(f\"   Languages: {len(zeroshot_eval_data)}\")\n",
    "print(f\"   Total samples: {sum(len(df) for df in zeroshot_eval_data.values())}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PHASE 5 COMPLETE - ALL EVALUATIONS FINISHED\")\n",
    "print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34577859",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Batch Evaluation Script - Phase 5 Multilingual Evaluation\n",
    "Evaluates all negative sampling models on multiple datasets\n",
    "\"\"\"\n",
    "\n",
    "import subprocess\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def run_batch_multilingual_evaluation():\n",
    "    \"\"\"Run evaluation on all trained models across multiple datasets/languages\"\"\"\n",
    "    \n",
    "    models = [\n",
    "        (\"BM25 Baseline\", \"./models/dpr_bm25_baseline_tydi_final\", 0),\n",
    "        (\"LLM Enhanced\", \"./models/dpr_llm_enhanced_tydi_final\", 1),\n",
    "        (\"RAG Enhanced\", \"./models/dpr_rag_enhanced_tydi_final\", 2),\n",
    "    ]\n",
    "    \n",
    "    datasets = [\n",
    "        # In-Distribution\n",
    "        (\"TyDi\", \"in-distribution\", 0, [\"swahili\", \"bengali\", \"telugu\"]),\n",
    "        # Out-of-Distribution\n",
    "        (\"mMARCO\", \"out-of-distribution\", 1, [\"arabic\", \"indonesian\"]),\n",
    "        # Zero-Shot\n",
    "        (\"mMARCO-Zero\", \"zero-shot\", 2, [\"spanish\", \"hindi\", \"vietnamese\"]),\n",
    "    ]\n",
    "    \n",
    "    results = {\n",
    "        'timestamp': datetime.now().isoformat(),\n",
    "        'models': len(models),\n",
    "        'datasets': len(datasets),\n",
    "        'results': {}\n",
    "    }\n",
    "    \n",
    "    print(\"=\" * 70)\n",
    "    print(\"ðŸš€ PHASE 5: BATCH MULTILINGUAL EVALUATION\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"\\nðŸ“Š Configuration:\")\n",
    "    print(f\"   Models: {len(models)}\")\n",
    "    print(f\"   Datasets: {len(datasets)}\")\n",
    "    print(f\"   Total evaluations: {len(models) * len(datasets)}\\n\")\n",
    "    \n",
    "    total_evaluations = 0\n",
    "    successful = 0\n",
    "    failed = 0\n",
    "    \n",
    "    # Evaluate each dataset\n",
    "    for dataset_name, dataset_type, dataset_id, languages in datasets:\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"ðŸ“‚ Dataset: {dataset_name} ({dataset_type})\")\n",
    "        print(f\"   Languages: {', '.join(languages)}\")\n",
    "        print(f\"{'='*70}\")\n",
    "        \n",
    "        dataset_results = {}\n",
    "        \n",
    "        # Evaluate each model\n",
    "        for model_name, model_path, model_id in models:\n",
    "            print(f\"\\n   ðŸ” Model: {model_name}\")\n",
    "            print(f\"      Path: {model_path}\")\n",
    "            \n",
    "            try:\n",
    "                # Call evaluation adapter\n",
    "                result = subprocess.run([\n",
    "                    sys.executable, \n",
    "                    \"evaluate_adapter.py\",\n",
    "                    str(model_id),\n",
    "                    str(dataset_id),\n",
    "                    dataset_name,\n",
    "                    dataset_type,\n",
    "                    model_path\n",
    "                ], \n",
    "                capture_output=True, \n",
    "                text=True, \n",
    "                timeout=600  # 10 minutes timeout\n",
    "                )\n",
    "                \n",
    "                total_evaluations += 1\n",
    "                \n",
    "                if result.returncode == 0:\n",
    "                    # Parse results\n",
    "                    try:\n",
    "                        model_results = json.loads(result.stdout)\n",
    "                        dataset_results[model_name] = model_results\n",
    "                        successful += 1\n",
    "                        \n",
    "                        # Display metrics\n",
    "                        mrr = model_results.get('avg_MRR@10', 0)\n",
    "                        recall = model_results.get('avg_Recall@10', 0)\n",
    "                        ndcg = model_results.get('avg_nDCG@10', 0)\n",
    "                        \n",
    "                        print(f\"      âœ… Success\")\n",
    "                        print(f\"         MRR@10:    {mrr:.4f}\")\n",
    "                        print(f\"         Recall@10: {recall:.4f}\")\n",
    "                        print(f\"         nDCG@10:   {ndcg:.4f}\")\n",
    "                        \n",
    "                    except json.JSONDecodeError:\n",
    "                        print(f\"      âš ï¸  Parse error\")\n",
    "                        failed += 1\n",
    "                else:\n",
    "                    print(f\"      âŒ Evaluation failed\")\n",
    "                    print(f\"         Error: {result.stderr[:100]}\")\n",
    "                    failed += 1\n",
    "                    \n",
    "            except subprocess.TimeoutExpired:\n",
    "                print(f\"      â° Timeout (10min exceeded)\")\n",
    "                failed += 1\n",
    "                total_evaluations += 1\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"      âŒ Exception: {str(e)[:80]}\")\n",
    "                failed += 1\n",
    "                total_evaluations += 1\n",
    "        \n",
    "        results['results'][dataset_name] = dataset_results\n",
    "    \n",
    "    # Summary\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"ðŸ“Š BATCH EVALUATION SUMMARY\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"\\n   Total Evaluations: {total_evaluations}\")\n",
    "    print(f\"   Successful:       {successful} âœ…\")\n",
    "    print(f\"   Failed:           {failed} âŒ\")\n",
    "    print(f\"   Success Rate:     {(successful/total_evaluations*100):.1f}%\")\n",
    "    \n",
    "    # Save results\n",
    "    output_file = f\"batch_evaluation_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
    "    with open(output_file, 'w') as f:\n",
    "        json.dump(results, f, indent=2)\n",
    "    \n",
    "    print(f\"\\n   ðŸ“ Results saved: {output_file}\")\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"âœ… Batch evaluation complete!\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_batch_multilingual_evaluation()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mltorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
